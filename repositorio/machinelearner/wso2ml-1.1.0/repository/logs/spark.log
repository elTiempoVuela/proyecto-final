[2016-04-29 15:11:11,999]  INFO {org.apache.spark.SparkContext} -  Running Spark version 1.4.1 {org.apache.spark.SparkContext}
[2016-04-29 15:11:12,275]  WARN {org.apache.hadoop.util.NativeCodeLoader} -  Unable to load native-hadoop library for your platform... using builtin-java classes where applicable {org.apache.hadoop.util.NativeCodeLoader}
[2016-04-29 15:11:12,465]  INFO {org.apache.spark.SecurityManager} -  Changing view acls to: root {org.apache.spark.SecurityManager}
[2016-04-29 15:11:12,466]  INFO {org.apache.spark.SecurityManager} -  Changing modify acls to: root {org.apache.spark.SecurityManager}
[2016-04-29 15:11:12,468]  INFO {org.apache.spark.SecurityManager} -  SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root) {org.apache.spark.SecurityManager}
[2016-04-29 15:11:13,395]  INFO {akka.event.slf4j.Slf4jLogger} -  Slf4jLogger started {akka.event.slf4j.Slf4jLogger}
[2016-04-29 15:11:13,484]  INFO {Remoting} -  Starting remoting {Remoting}
[2016-04-29 15:11:13,889]  INFO {Remoting} -  Remoting started; listening on addresses :[akka.tcp://sparkDriver@172.17.0.2:55169] {Remoting}
[2016-04-29 15:11:13,899]  INFO {org.apache.spark.util.Utils} -  Successfully started service 'sparkDriver' on port 55169. {org.apache.spark.util.Utils}
[2016-04-29 15:11:13,950]  INFO {org.apache.spark.SparkEnv} -  Registering MapOutputTracker {org.apache.spark.SparkEnv}
[2016-04-29 15:11:13,976]  INFO {org.apache.spark.SparkEnv} -  Registering BlockManagerMaster {org.apache.spark.SparkEnv}
[2016-04-29 15:11:14,021]  INFO {org.apache.spark.storage.DiskBlockManager} -  Created local directory at /home/ml/wso2ml-1.1.0/tmp/spark-bea678b5-62ad-430a-a305-d7b66f3df60f/blockmgr-5b3052c6-645a-4be0-a5c8-fd7f1b43a01f {org.apache.spark.storage.DiskBlockManager}
[2016-04-29 15:11:14,030]  INFO {org.apache.spark.storage.MemoryStore} -  MemoryStore started with capacity 983.1 MB {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:11:14,119]  INFO {org.apache.spark.HttpFileServer} -  HTTP File server directory is /home/ml/wso2ml-1.1.0/tmp/spark-bea678b5-62ad-430a-a305-d7b66f3df60f/httpd-b6ebc599-2f77-4c4a-9be2-e49867fef833 {org.apache.spark.HttpFileServer}
[2016-04-29 15:11:14,124]  INFO {org.apache.spark.HttpServer} -  Starting HTTP Server {org.apache.spark.HttpServer}
[2016-04-29 15:11:14,186]  INFO {org.spark-project.jetty.server.Server} -  jetty-8.y.z-SNAPSHOT {org.spark-project.jetty.server.Server}
[2016-04-29 15:11:14,206]  INFO {org.spark-project.jetty.server.AbstractConnector} -  Started SocketConnector@0.0.0.0:34987 {org.spark-project.jetty.server.AbstractConnector}
[2016-04-29 15:11:14,207]  INFO {org.apache.spark.util.Utils} -  Successfully started service 'HTTP file server' on port 34987. {org.apache.spark.util.Utils}
[2016-04-29 15:11:14,227]  INFO {org.apache.spark.SparkEnv} -  Registering OutputCommitCoordinator {org.apache.spark.SparkEnv}
[2016-04-29 15:11:14,442]  INFO {org.spark-project.jetty.server.Server} -  jetty-8.y.z-SNAPSHOT {org.spark-project.jetty.server.Server}
[2016-04-29 15:11:14,456]  INFO {org.spark-project.jetty.server.AbstractConnector} -  Started SelectChannelConnector@0.0.0.0:4040 {org.spark-project.jetty.server.AbstractConnector}
[2016-04-29 15:11:14,457]  INFO {org.apache.spark.util.Utils} -  Successfully started service 'SparkUI' on port 4040. {org.apache.spark.util.Utils}
[2016-04-29 15:11:14,460]  INFO {org.apache.spark.ui.SparkUI} -  Started SparkUI at http://172.17.0.2:4040 {org.apache.spark.ui.SparkUI}
[2016-04-29 15:11:14,598]  INFO {org.apache.spark.executor.Executor} -  Starting executor ID driver on host localhost {org.apache.spark.executor.Executor}
[2016-04-29 15:11:15,107]  INFO {org.apache.spark.util.Utils} -  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56403. {org.apache.spark.util.Utils}
[2016-04-29 15:11:15,108]  INFO {org.apache.spark.network.netty.NettyBlockTransferService} -  Server created on 56403 {org.apache.spark.network.netty.NettyBlockTransferService}
[2016-04-29 15:11:15,109]  INFO {org.apache.spark.storage.BlockManagerMaster} -  Trying to register BlockManager {org.apache.spark.storage.BlockManagerMaster}
[2016-04-29 15:11:15,117]  INFO {org.apache.spark.storage.BlockManagerMasterEndpoint} -  Registering block manager localhost:56403 with 983.1 MB RAM, BlockManagerId(driver, localhost, 56403) {org.apache.spark.storage.BlockManagerMasterEndpoint}
[2016-04-29 15:11:15,123]  INFO {org.apache.spark.storage.BlockManagerMaster} -  Registered BlockManager {org.apache.spark.storage.BlockManagerMaster}
[2016-04-29 15:15:23,843]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(38464) called with curMem=0, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:15:23,847]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_0 stored as values in memory (estimated size 37.6 KB, free 983.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:15:24,112]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4089) called with curMem=38464, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:15:24,112]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 983.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:15:24,118]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_0_piece0 in memory on localhost:56403 (size: 4.0 KB, free: 983.1 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:15:24,124]  INFO {org.apache.spark.SparkContext} -  Created broadcast 0 from textFile at MLUtils.java:91 {org.apache.spark.SparkContext}
[2016-04-29 15:15:24,257]  INFO {org.apache.hadoop.mapred.FileInputFormat} -  Total input paths to process : 1 {org.apache.hadoop.mapred.FileInputFormat}
[2016-04-29 15:15:24,319]  INFO {org.apache.spark.SparkContext} -  Starting job: first at MLUtils.java:91 {org.apache.spark.SparkContext}
[2016-04-29 15:15:24,348]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 0 (first at MLUtils.java:91) with 1 output partitions (allowLocal=true) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:15:24,349]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 0(first at MLUtils.java:91) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:15:24,350]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:15:24,358]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:15:24,372]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 0 (MapPartitionsRDD[1] at textFile at MLUtils.java:91), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:15:24,378]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(3176) called with curMem=42553, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:15:24,379]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_1 stored as values in memory (estimated size 3.1 KB, free 983.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:15:24,394]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(1830) called with curMem=45729, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:15:24,395]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_1_piece0 stored as bytes in memory (estimated size 1830.0 B, free 983.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:15:24,397]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_1_piece0 in memory on localhost:56403 (size: 1830.0 B, free: 983.1 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:15:24,399]  INFO {org.apache.spark.SparkContext} -  Created broadcast 1 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:15:24,408]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at textFile at MLUtils.java:91) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:15:24,411]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 0.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:15:24,454]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 1436 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:15:24,464]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 0.0 (TID 0) {org.apache.spark.executor.Executor}
[2016-04-29 15:15:24,499]  INFO {org.apache.spark.rdd.HadoopRDD} -  Input split: file:/home/ml/wso2ml-1.1.0/datasets/banking.-1234.1461942923269:0+4882918 {org.apache.spark.rdd.HadoopRDD}
[2016-04-29 15:15:24,511]  INFO {org.apache.hadoop.conf.Configuration.deprecation} -  mapred.tip.id is deprecated. Instead, use mapreduce.task.id {org.apache.hadoop.conf.Configuration.deprecation}
[2016-04-29 15:15:24,511]  INFO {org.apache.hadoop.conf.Configuration.deprecation} -  mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id {org.apache.hadoop.conf.Configuration.deprecation}
[2016-04-29 15:15:24,511]  INFO {org.apache.hadoop.conf.Configuration.deprecation} -  mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap {org.apache.hadoop.conf.Configuration.deprecation}
[2016-04-29 15:15:24,512]  INFO {org.apache.hadoop.conf.Configuration.deprecation} -  mapred.task.partition is deprecated. Instead, use mapreduce.task.partition {org.apache.hadoop.conf.Configuration.deprecation}
[2016-04-29 15:15:24,512]  INFO {org.apache.hadoop.conf.Configuration.deprecation} -  mapred.job.id is deprecated. Instead, use mapreduce.job.id {org.apache.hadoop.conf.Configuration.deprecation}
[2016-04-29 15:15:24,581]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 0.0 (TID 0). 1954 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:15:24,601]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 0.0 (TID 0) in 157 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:15:24,605]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 0 (first at MLUtils.java:91) finished in 0.179 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:15:24,603]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 0.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:15:24,617]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 0 finished: first at MLUtils.java:91, took 0.297794 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:15:24,727]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(38520) called with curMem=47559, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:15:24,728]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_2 stored as values in memory (estimated size 37.6 KB, free 983.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:15:24,772]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4089) called with curMem=86079, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:15:24,773]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.0 KB, free 983.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:15:24,777]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_2_piece0 in memory on localhost:56403 (size: 4.0 KB, free: 983.1 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:15:24,779]  INFO {org.apache.spark.SparkContext} -  Created broadcast 2 from textFile at MLUtils.java:73 {org.apache.spark.SparkContext}
[2016-04-29 15:15:24,794]  INFO {org.apache.hadoop.mapred.FileInputFormat} -  Total input paths to process : 1 {org.apache.hadoop.mapred.FileInputFormat}
[2016-04-29 15:15:24,805]  INFO {org.apache.spark.SparkContext} -  Starting job: first at MLUtils.java:75 {org.apache.spark.SparkContext}
[2016-04-29 15:15:24,806]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 1 (first at MLUtils.java:75) with 1 output partitions (allowLocal=true) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:15:24,806]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 1(first at MLUtils.java:75) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:15:24,806]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:15:24,808]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:15:24,808]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 1 (MapPartitionsRDD[3] at textFile at MLUtils.java:73), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:15:24,810]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(3176) called with curMem=90168, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:15:24,811]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_3 stored as values in memory (estimated size 3.1 KB, free 983.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:15:24,854]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(1841) called with curMem=93344, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:15:24,855]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_3_piece0 stored as bytes in memory (estimated size 1841.0 B, free 983.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:15:24,858]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_3_piece0 in memory on localhost:56403 (size: 1841.0 B, free: 983.1 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:15:24,859]  INFO {org.apache.spark.SparkContext} -  Created broadcast 3 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:15:24,860]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[3] at textFile at MLUtils.java:73) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:15:24,860]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 1.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:15:24,863]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 1436 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:15:24,864]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 1.0 (TID 1) {org.apache.spark.executor.Executor}
[2016-04-29 15:15:24,872]  INFO {org.apache.spark.rdd.HadoopRDD} -  Input split: file:/home/ml/wso2ml-1.1.0/datasets/banking.-1234.1461942923269:0+4882918 {org.apache.spark.rdd.HadoopRDD}
[2016-04-29 15:15:24,931]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 1.0 (TID 1). 1954 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:15:24,969]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 1.0 (TID 1) in 106 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:15:24,972]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 1 (first at MLUtils.java:75) finished in 0.108 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:15:24,974]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 1 finished: first at MLUtils.java:75, took 0.168596 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:15:24,973]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 1.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:15:24,993]  INFO {org.apache.spark.SparkContext} -  Starting job: first at MLUtils.java:153 {org.apache.spark.SparkContext}
[2016-04-29 15:15:24,995]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 2 (first at MLUtils.java:153) with 1 output partitions (allowLocal=true) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:15:24,996]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 2(first at MLUtils.java:153) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:15:24,996]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:15:24,998]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:15:24,999]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 2 (MapPartitionsRDD[3] at textFile at MLUtils.java:73), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:15:25,003]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(3176) called with curMem=95185, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:15:25,006]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_4 stored as values in memory (estimated size 3.1 KB, free 983.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:15:25,049]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(1841) called with curMem=98361, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:15:25,049]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_4_piece0 stored as bytes in memory (estimated size 1841.0 B, free 983.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:15:25,054]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_4_piece0 in memory on localhost:56403 (size: 1841.0 B, free: 983.1 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:15:25,056]  INFO {org.apache.spark.SparkContext} -  Created broadcast 4 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:15:25,056]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[3] at textFile at MLUtils.java:73) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:15:25,057]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 2.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:15:25,060]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 2.0 (TID 2, localhost, PROCESS_LOCAL, 1436 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:15:25,060]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 2.0 (TID 2) {org.apache.spark.executor.Executor}
[2016-04-29 15:15:25,070]  INFO {org.apache.spark.rdd.HadoopRDD} -  Input split: file:/home/ml/wso2ml-1.1.0/datasets/banking.-1234.1461942923269:0+4882918 {org.apache.spark.rdd.HadoopRDD}
[2016-04-29 15:15:25,160]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 2.0 (TID 2). 1954 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:15:25,189]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 2 (first at MLUtils.java:153) finished in 0.131 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:15:25,190]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 2 finished: first at MLUtils.java:153, took 0.196749 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:15:25,191]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 2.0 (TID 2) in 130 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:15:25,201]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 2.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:15:25,203]  INFO {org.apache.spark.SparkContext} -  Starting job: first at MLUtils.java:163 {org.apache.spark.SparkContext}
[2016-04-29 15:15:25,204]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 3 (first at MLUtils.java:163) with 1 output partitions (allowLocal=true) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:15:25,205]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 3(first at MLUtils.java:163) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:15:25,205]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:15:25,207]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:15:25,208]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 3 (MapPartitionsRDD[3] at textFile at MLUtils.java:73), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:15:25,211]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(3176) called with curMem=100202, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:15:25,211]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_5 stored as values in memory (estimated size 3.1 KB, free 983.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:15:25,223]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(1841) called with curMem=103378, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:15:25,224]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_5_piece0 stored as bytes in memory (estimated size 1841.0 B, free 983.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:15:25,230]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_5_piece0 in memory on localhost:56403 (size: 1841.0 B, free: 983.1 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:15:25,231]  INFO {org.apache.spark.SparkContext} -  Created broadcast 5 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:15:25,232]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[3] at textFile at MLUtils.java:73) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:15:25,232]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 3.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:15:25,234]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 3.0 (TID 3, localhost, PROCESS_LOCAL, 1436 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:15:25,235]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 3.0 (TID 3) {org.apache.spark.executor.Executor}
[2016-04-29 15:15:25,239]  INFO {org.apache.spark.rdd.HadoopRDD} -  Input split: file:/home/ml/wso2ml-1.1.0/datasets/banking.-1234.1461942923269:0+4882918 {org.apache.spark.rdd.HadoopRDD}
[2016-04-29 15:15:25,261]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 3.0 (TID 3). 1954 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:15:25,277]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 3 (first at MLUtils.java:163) finished in 0.034 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:15:25,278]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 3 finished: first at MLUtils.java:163, took 0.074629 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:15:25,294]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 3.0 (TID 3) in 44 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:15:25,297]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 3.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:15:25,326]  INFO {org.apache.spark.rdd.MapPartitionsRDD} -  Removing RDD 4 from persistence list {org.apache.spark.rdd.MapPartitionsRDD}
[2016-04-29 15:15:25,357]  INFO {org.apache.spark.storage.BlockManager} -  Removing RDD 4 {org.apache.spark.storage.BlockManager}
[2016-04-29 15:15:25,425]  INFO {org.apache.spark.SparkContext} -  Starting job: first at MLUtils.java:187 {org.apache.spark.SparkContext}
[2016-04-29 15:15:25,426]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 4 (first at MLUtils.java:187) with 1 output partitions (allowLocal=true) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:15:25,426]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 4(first at MLUtils.java:187) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:15:25,427]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:15:25,429]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:15:25,431]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 4 (MapPartitionsRDD[3] at textFile at MLUtils.java:73), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:15:25,445]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(3176) called with curMem=105219, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:15:25,449]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_6 stored as values in memory (estimated size 3.1 KB, free 983.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:15:25,487]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(1841) called with curMem=108395, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:15:25,490]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_6_piece0 stored as bytes in memory (estimated size 1841.0 B, free 983.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:15:25,497]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_6_piece0 in memory on localhost:56403 (size: 1841.0 B, free: 983.1 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:15:25,499]  INFO {org.apache.spark.SparkContext} -  Created broadcast 6 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:15:25,500]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[3] at textFile at MLUtils.java:73) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:15:25,500]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 4.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:15:25,502]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 4.0 (TID 4, localhost, PROCESS_LOCAL, 1436 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:15:25,503]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 4.0 (TID 4) {org.apache.spark.executor.Executor}
[2016-04-29 15:15:25,509]  INFO {org.apache.spark.rdd.HadoopRDD} -  Input split: file:/home/ml/wso2ml-1.1.0/datasets/banking.-1234.1461942923269:0+4882918 {org.apache.spark.rdd.HadoopRDD}
[2016-04-29 15:15:25,565]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 4.0 (TID 4). 1954 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:15:25,595]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 4 (first at MLUtils.java:187) finished in 0.094 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:15:25,596]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 4 finished: first at MLUtils.java:187, took 0.170423 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:15:25,597]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 4.0 (TID 4) in 90 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:15:25,598]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 4.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:15:25,603]  INFO {org.apache.spark.SparkContext} -  Starting job: takeSample at MLUtils.java:194 {org.apache.spark.SparkContext}
[2016-04-29 15:15:25,605]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 5 (takeSample at MLUtils.java:194) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:15:25,606]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 5(takeSample at MLUtils.java:194) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:15:25,606]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:15:25,610]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:15:25,611]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 5 (MapPartitionsRDD[5] at map at MLUtils.java:167), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:15:25,618]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4232) called with curMem=110236, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:15:25,619]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_7 stored as values in memory (estimated size 4.1 KB, free 983.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:15:25,646]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(2506) called with curMem=114468, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:15:25,648]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.4 KB, free 983.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:15:25,655]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_7_piece0 in memory on localhost:56403 (size: 2.4 KB, free: 983.1 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:15:25,657]  INFO {org.apache.spark.SparkContext} -  Created broadcast 7 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:15:25,658]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[5] at map at MLUtils.java:167) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:15:25,659]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 5.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:15:25,662]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 5.0 (TID 5, localhost, PROCESS_LOCAL, 1436 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:15:25,664]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 5.0 (TID 5) {org.apache.spark.executor.Executor}
[2016-04-29 15:15:25,693]  INFO {org.apache.spark.CacheManager} -  Partition rdd_5_0 not found, computing it {org.apache.spark.CacheManager}
[2016-04-29 15:15:25,693]  INFO {org.apache.spark.rdd.HadoopRDD} -  Input split: file:/home/ml/wso2ml-1.1.0/datasets/banking.-1234.1461942923269:0+4882918 {org.apache.spark.rdd.HadoopRDD}
[2016-04-29 15:15:27,648]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_6_piece0 on localhost:56403 in memory (size: 1841.0 B, free: 983.1 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:15:27,656]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_5_piece0 on localhost:56403 in memory (size: 1841.0 B, free: 983.1 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:15:27,663]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_4_piece0 on localhost:56403 in memory (size: 1841.0 B, free: 983.1 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:15:27,667]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_3_piece0 on localhost:56403 in memory (size: 1841.0 B, free: 983.1 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:15:27,673]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_1_piece0 on localhost:56403 in memory (size: 1830.0 B, free: 983.1 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:15:27,679]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_0_piece0 on localhost:56403 in memory (size: 4.0 KB, free: 983.1 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:15:30,042]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(49830048) called with curMem=49347, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:15:30,043]  INFO {org.apache.spark.storage.MemoryStore} -  Block rdd_5_0 stored as values in memory (estimated size 47.5 MB, free 935.5 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:15:30,044]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added rdd_5_0 in memory on localhost:56403 (size: 47.5 MB, free: 935.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:15:30,069]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 5.0 (TID 5). 2332 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:15:30,080]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 5 (takeSample at MLUtils.java:194) finished in 4.420 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:15:30,081]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 5 finished: takeSample at MLUtils.java:194, took 4.477609 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:15:30,092]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 5.0 (TID 5) in 4418 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:15:30,093]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 5.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:15:30,136]  INFO {org.apache.spark.SparkContext} -  Starting job: takeSample at MLUtils.java:194 {org.apache.spark.SparkContext}
[2016-04-29 15:15:30,138]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 6 (takeSample at MLUtils.java:194) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:15:30,138]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 6(takeSample at MLUtils.java:194) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:15:30,138]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:15:30,143]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:15:30,145]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 6 (PartitionwiseSampledRDD[6] at takeSample at MLUtils.java:194), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:15:30,149]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4968) called with curMem=49879395, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:15:30,150]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_8 stored as values in memory (estimated size 4.9 KB, free 935.5 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:15:30,167]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(2852) called with curMem=49884363, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:15:30,168]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_8_piece0 stored as bytes in memory (estimated size 2.8 KB, free 935.5 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:15:30,173]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_8_piece0 in memory on localhost:56403 (size: 2.8 KB, free: 935.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:15:30,174]  INFO {org.apache.spark.SparkContext} -  Created broadcast 8 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:15:30,174]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 6 (PartitionwiseSampledRDD[6] at takeSample at MLUtils.java:194) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:15:30,175]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 6.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:15:30,183]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 6.0 (TID 6, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:15:30,184]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 6.0 (TID 6) {org.apache.spark.executor.Executor}
[2016-04-29 15:15:30,192]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_5_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:15:30,281]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 6.0 (TID 6). 73605 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:15:30,333]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 6.0 (TID 6) in 154 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:15:30,334]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 6 (takeSample at MLUtils.java:194) finished in 0.154 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:15:30,334]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 6.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:15:30,335]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 6 finished: takeSample at MLUtils.java:194, took 0.197892 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:15:30,340]  INFO {org.apache.spark.rdd.MapPartitionsRDD} -  Removing RDD 5 from persistence list {org.apache.spark.rdd.MapPartitionsRDD}
[2016-04-29 15:15:30,343]  INFO {org.apache.spark.storage.BlockManager} -  Removing RDD 5 {org.apache.spark.storage.BlockManager}
[2016-04-29 15:17:28,697]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(38520) called with curMem=57167, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:17:28,698]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_9 stored as values in memory (estimated size 37.6 KB, free 983.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:17:28,715]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4089) called with curMem=95687, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:17:28,716]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_9_piece0 stored as bytes in memory (estimated size 4.0 KB, free 983.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:17:28,720]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_9_piece0 in memory on localhost:56403 (size: 4.0 KB, free: 983.1 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:17:28,722]  INFO {org.apache.spark.SparkContext} -  Created broadcast 9 from textFile at MLModelHandler.java:953 {org.apache.spark.SparkContext}
[2016-04-29 15:18:04,703]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_9_piece0 on localhost:56403 in memory (size: 4.0 KB, free: 983.1 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:18:04,714]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_8_piece0 on localhost:56403 in memory (size: 2.8 KB, free: 983.1 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:08,072]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(38520) called with curMem=49347, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:08,072]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_10 stored as values in memory (estimated size 37.6 KB, free 983.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:08,118]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4089) called with curMem=87867, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:08,119]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_10_piece0 stored as bytes in memory (estimated size 4.0 KB, free 983.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:08,123]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_10_piece0 in memory on localhost:56403 (size: 4.0 KB, free: 983.1 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:08,125]  INFO {org.apache.spark.SparkContext} -  Created broadcast 10 from textFile at MLModelHandler.java:953 {org.apache.spark.SparkContext}
[2016-04-29 15:19:08,139]  INFO {org.apache.hadoop.mapred.FileInputFormat} -  Total input paths to process : 1 {org.apache.hadoop.mapred.FileInputFormat}
[2016-04-29 15:19:08,143]  INFO {org.apache.spark.SparkContext} -  Starting job: count at MLModelHandler.java:909 {org.apache.spark.SparkContext}
[2016-04-29 15:19:08,144]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 7 (count at MLModelHandler.java:909) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:08,145]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 7(count at MLModelHandler.java:909) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:08,145]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:08,146]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:08,147]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 7 (MapPartitionsRDD[10] at textFile at MLModelHandler.java:953), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:08,149]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(3008) called with curMem=91956, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:08,150]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_11 stored as values in memory (estimated size 2.9 KB, free 983.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:08,160]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(1762) called with curMem=94964, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:08,161]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_11_piece0 stored as bytes in memory (estimated size 1762.0 B, free 983.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:08,165]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_11_piece0 in memory on localhost:56403 (size: 1762.0 B, free: 983.1 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:08,166]  INFO {org.apache.spark.SparkContext} -  Created broadcast 11 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:08,166]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[10] at textFile at MLModelHandler.java:953) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:08,167]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 7.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:08,168]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 7.0 (TID 7, localhost, PROCESS_LOCAL, 1436 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:08,169]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 7.0 (TID 7) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:08,173]  INFO {org.apache.spark.rdd.HadoopRDD} -  Input split: file:/home/ml/wso2ml-1.1.0/datasets/banking.-1234.1461942923269:0+4882918 {org.apache.spark.rdd.HadoopRDD}
[2016-04-29 15:19:08,287]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 7.0 (TID 7). 1752 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:08,296]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 7 (count at MLModelHandler.java:909) finished in 0.129 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:08,296]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 7.0 (TID 7) in 127 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:08,297]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 7 finished: count at MLModelHandler.java:909, took 0.153979 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:08,297]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 7.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:08,326]  WARN {org.apache.spark.mllib.clustering.KMeans} -  The input data is not directly cached, which may hurt performance if its parent RDDs are also uncached. {org.apache.spark.mllib.clustering.KMeans}
[2016-04-29 15:19:08,370]  INFO {org.apache.spark.SparkContext} -  Starting job: takeSample at KMeans.scala:325 {org.apache.spark.SparkContext}
[2016-04-29 15:19:08,372]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 8 (takeSample at KMeans.scala:325) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:08,373]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 8(takeSample at KMeans.scala:325) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:08,373]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:08,379]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:08,380]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 8 (MapPartitionsRDD[18] at map at KMeans.scala:173), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:08,386]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(6152) called with curMem=96726, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:08,387]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_12 stored as values in memory (estimated size 6.0 KB, free 983.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:08,397]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(3393) called with curMem=102878, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:08,398]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_12_piece0 stored as bytes in memory (estimated size 3.3 KB, free 983.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:08,402]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_12_piece0 in memory on localhost:56403 (size: 3.3 KB, free: 983.1 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:08,402]  INFO {org.apache.spark.SparkContext} -  Created broadcast 12 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:08,404]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[18] at map at KMeans.scala:173) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:08,404]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 8.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:08,408]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 8.0 (TID 8, localhost, PROCESS_LOCAL, 1953 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:08,409]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 8.0 (TID 8) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:08,417]  INFO {org.apache.spark.rdd.HadoopRDD} -  Input split: file:/home/ml/wso2ml-1.1.0/datasets/banking.-1234.1461942923269:0+4882918 {org.apache.spark.rdd.HadoopRDD}
[2016-04-29 15:19:08,430]  INFO {org.apache.spark.CacheManager} -  Partition rdd_16_0 not found, computing it {org.apache.spark.CacheManager}
[2016-04-29 15:19:08,430]  INFO {org.apache.spark.rdd.HadoopRDD} -  Input split: file:/home/ml/wso2ml-1.1.0/datasets/banking.-1234.1461942923269:0+4882918 {org.apache.spark.rdd.HadoopRDD}
[2016-04-29 15:19:09,283]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(280288) called with curMem=106271, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:09,284]  INFO {org.apache.spark.storage.MemoryStore} -  Block rdd_16_0 stored as values in memory (estimated size 273.7 KB, free 982.7 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:09,285]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added rdd_16_0 in memory on localhost:56403 (size: 273.7 KB, free: 982.8 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:09,977]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 8.0 (TID 8). 2332 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:09,987]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 8 (takeSample at KMeans.scala:325) finished in 1.582 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:09,988]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 8 finished: takeSample at KMeans.scala:325, took 1.617773 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:09,992]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 8.0 (TID 8) in 1582 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:09,994]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 8.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:10,023]  INFO {org.apache.spark.SparkContext} -  Starting job: takeSample at KMeans.scala:325 {org.apache.spark.SparkContext}
[2016-04-29 15:19:10,025]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 9 (takeSample at KMeans.scala:325) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:10,025]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 9(takeSample at KMeans.scala:325) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:10,026]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:10,035]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:10,038]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 9 (PartitionwiseSampledRDD[20] at takeSample at KMeans.scala:325), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:10,042]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(23224) called with curMem=386559, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:10,042]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_13 stored as values in memory (estimated size 22.7 KB, free 982.7 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:10,054]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(11004) called with curMem=409783, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:10,055]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_13_piece0 stored as bytes in memory (estimated size 10.7 KB, free 982.7 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:10,060]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_13_piece0 in memory on localhost:56403 (size: 10.7 KB, free: 982.8 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:10,061]  INFO {org.apache.spark.SparkContext} -  Created broadcast 13 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:10,062]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 9 (PartitionwiseSampledRDD[20] at takeSample at KMeans.scala:325) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:10,062]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 9.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:10,064]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 9.0 (TID 9, localhost, PROCESS_LOCAL, 1971 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:10,064]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 9.0 (TID 9) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:10,075]  INFO {org.apache.spark.rdd.HadoopRDD} -  Input split: file:/home/ml/wso2ml-1.1.0/datasets/banking.-1234.1461942923269:0+4882918 {org.apache.spark.rdd.HadoopRDD}
[2016-04-29 15:19:10,084]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_16_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:10,850]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 9.0 (TID 9). 2279 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:10,876]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 9 (takeSample at KMeans.scala:325) finished in 0.801 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:10,876]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 9.0 (TID 9) in 812 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:10,876]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 9 finished: takeSample at KMeans.scala:325, took 0.853243 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:10,877]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 9.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:10,879]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(224) called with curMem=420787, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:10,880]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_14 stored as values in memory (estimated size 224.0 B, free 982.7 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:10,890]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(159) called with curMem=421011, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:10,890]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_14_piece0 stored as bytes in memory (estimated size 159.0 B, free 982.7 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:10,892]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_14_piece0 in memory on localhost:56403 (size: 159.0 B, free: 982.8 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:10,893]  INFO {org.apache.spark.SparkContext} -  Created broadcast 14 from broadcast at KMeans.scala:343 {org.apache.spark.SparkContext}
[2016-04-29 15:19:10,930]  INFO {org.apache.spark.SparkContext} -  Starting job: aggregate at KMeans.scala:352 {org.apache.spark.SparkContext}
[2016-04-29 15:19:10,933]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 10 (aggregate at KMeans.scala:352) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:10,934]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 10(aggregate at KMeans.scala:352) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:10,934]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:10,945]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:10,949]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 10 (MapPartitionsRDD[22] at map at KMeans.scala:345), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:10,953]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(7720) called with curMem=421170, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:10,954]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_15 stored as values in memory (estimated size 7.5 KB, free 982.7 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:10,962]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4042) called with curMem=428890, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:10,963]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.9 KB, free 982.7 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:10,965]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_15_piece0 in memory on localhost:56403 (size: 3.9 KB, free: 982.8 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:10,966]  INFO {org.apache.spark.SparkContext} -  Created broadcast 15 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:10,967]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[22] at map at KMeans.scala:345) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:10,967]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 10.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:10,969]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 10.0 (TID 10, localhost, PROCESS_LOCAL, 1985 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:10,969]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 10.0 (TID 10) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:10,980]  INFO {org.apache.spark.CacheManager} -  Partition rdd_22_0 not found, computing it {org.apache.spark.CacheManager}
[2016-04-29 15:19:10,980]  INFO {org.apache.spark.rdd.HadoopRDD} -  Input split: file:/home/ml/wso2ml-1.1.0/datasets/banking.-1234.1461942923269:0+4882918 {org.apache.spark.rdd.HadoopRDD}
[2016-04-29 15:19:10,990]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_16_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:10,991]  INFO {org.apache.spark.CacheManager} -  Partition rdd_19_0 not found, computing it {org.apache.spark.CacheManager}
[2016-04-29 15:19:10,991]  INFO {org.apache.spark.rdd.HadoopRDD} -  Input split: file:/home/ml/wso2ml-1.1.0/datasets/banking.-1234.1461942923269:0+4882918 {org.apache.spark.rdd.HadoopRDD}
[2016-04-29 15:19:11,001]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_16_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:11,892]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(440288) called with curMem=432932, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:11,892]  INFO {org.apache.spark.storage.MemoryStore} -  Block rdd_19_0 stored as values in memory (estimated size 430.0 KB, free 982.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:11,893]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added rdd_19_0 in memory on localhost:56403 (size: 430.0 KB, free: 982.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:12,501]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_13_piece0 on localhost:56403 in memory (size: 10.7 KB, free: 982.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:12,510]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_12_piece0 on localhost:56403 in memory (size: 3.3 KB, free: 982.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:12,514]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_11_piece0 on localhost:56403 in memory (size: 1762.0 B, free: 982.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:12,779]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(440288) called with curMem=824677, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:12,779]  INFO {org.apache.spark.storage.MemoryStore} -  Block rdd_22_0 stored as values in memory (estimated size 430.0 KB, free 981.9 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:12,780]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added rdd_22_0 in memory on localhost:56403 (size: 430.0 KB, free: 981.9 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:12,810]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 10.0 (TID 10). 2437 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:12,819]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 10 (aggregate at KMeans.scala:352) finished in 1.850 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:12,822]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 10 finished: aggregate at KMeans.scala:352, took 1.890823 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:12,822]  INFO {org.apache.spark.rdd.MapPartitionsRDD} -  Removing RDD 19 from persistence list {org.apache.spark.rdd.MapPartitionsRDD}
[2016-04-29 15:19:12,823]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 10.0 (TID 10) in 1851 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:12,823]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 10.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:12,825]  INFO {org.apache.spark.storage.BlockManager} -  Removing RDD 19 {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:12,859]  INFO {org.apache.spark.SparkContext} -  Starting job: collect at KMeans.scala:373 {org.apache.spark.SparkContext}
[2016-04-29 15:19:12,861]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 11 (collect at KMeans.scala:373) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:12,861]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 11(collect at KMeans.scala:373) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:12,861]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:12,868]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:12,869]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 11 (MapPartitionsRDD[24] at mapPartitionsWithIndex at KMeans.scala:365), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:12,872]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(7920) called with curMem=824677, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:12,872]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_16 stored as values in memory (estimated size 7.7 KB, free 982.3 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:12,881]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4159) called with curMem=832597, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:12,882]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_16_piece0 stored as bytes in memory (estimated size 4.1 KB, free 982.3 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:12,883]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_16_piece0 in memory on localhost:56403 (size: 4.1 KB, free: 982.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:12,884]  INFO {org.apache.spark.SparkContext} -  Created broadcast 16 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:12,885]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[24] at mapPartitionsWithIndex at KMeans.scala:365) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:12,886]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 11.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:12,888]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 11.0 (TID 11, localhost, PROCESS_LOCAL, 2017 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:12,888]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 11.0 (TID 11) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:12,896]  INFO {org.apache.spark.rdd.HadoopRDD} -  Input split: file:/home/ml/wso2ml-1.1.0/datasets/banking.-1234.1461942923269:0+4882918 {org.apache.spark.rdd.HadoopRDD}
[2016-04-29 15:19:12,906]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_16_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:12,907]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_22_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:14,241]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 11.0 (TID 11). 2132 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:14,260]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 11 (collect at KMeans.scala:373) finished in 1.372 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:14,260]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 11.0 (TID 11) in 1372 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:14,260]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 11 finished: collect at KMeans.scala:373, took 1.401430 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:14,260]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 11.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:14,264]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(656) called with curMem=836756, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:14,266]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_17 stored as values in memory (estimated size 656.0 B, free 982.3 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:14,284]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(289) called with curMem=837412, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:14,285]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_17_piece0 stored as bytes in memory (estimated size 289.0 B, free 982.3 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:14,287]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_17_piece0 in memory on localhost:56403 (size: 289.0 B, free: 982.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:14,289]  INFO {org.apache.spark.SparkContext} -  Created broadcast 17 from broadcast at KMeans.scala:343 {org.apache.spark.SparkContext}
[2016-04-29 15:19:14,336]  INFO {org.apache.spark.SparkContext} -  Starting job: aggregate at KMeans.scala:352 {org.apache.spark.SparkContext}
[2016-04-29 15:19:14,343]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 12 (aggregate at KMeans.scala:352) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:14,343]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 12(aggregate at KMeans.scala:352) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:14,344]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:14,361]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:14,365]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 12 (MapPartitionsRDD[26] at map at KMeans.scala:345), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:14,370]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(7952) called with curMem=837701, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:14,375]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_18 stored as values in memory (estimated size 7.8 KB, free 982.3 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:14,396]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4130) called with curMem=845653, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:14,399]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_18_piece0 stored as bytes in memory (estimated size 4.0 KB, free 982.3 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:14,404]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_18_piece0 in memory on localhost:56403 (size: 4.0 KB, free: 982.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:14,404]  INFO {org.apache.spark.SparkContext} -  Created broadcast 18 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:14,406]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[26] at map at KMeans.scala:345) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:14,406]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 12.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:14,408]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 12.0 (TID 12, localhost, PROCESS_LOCAL, 2017 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:14,409]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 12.0 (TID 12) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:14,430]  INFO {org.apache.spark.CacheManager} -  Partition rdd_26_0 not found, computing it {org.apache.spark.CacheManager}
[2016-04-29 15:19:14,434]  INFO {org.apache.spark.rdd.HadoopRDD} -  Input split: file:/home/ml/wso2ml-1.1.0/datasets/banking.-1234.1461942923269:0+4882918 {org.apache.spark.rdd.HadoopRDD}
[2016-04-29 15:19:14,445]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_16_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:14,446]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_22_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:15,557]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(440288) called with curMem=849783, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:15,558]  INFO {org.apache.spark.storage.MemoryStore} -  Block rdd_26_0 stored as values in memory (estimated size 430.0 KB, free 981.8 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:15,558]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added rdd_26_0 in memory on localhost:56403 (size: 430.0 KB, free: 981.9 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:15,567]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 12.0 (TID 12). 2382 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:15,579]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 12.0 (TID 12) in 1171 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:15,579]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 12 (aggregate at KMeans.scala:352) finished in 1.170 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:15,583]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 12 finished: aggregate at KMeans.scala:352, took 1.242017 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:15,583]  INFO {org.apache.spark.rdd.MapPartitionsRDD} -  Removing RDD 22 from persistence list {org.apache.spark.rdd.MapPartitionsRDD}
[2016-04-29 15:19:15,583]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 12.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:15,585]  INFO {org.apache.spark.storage.BlockManager} -  Removing RDD 22 {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:15,613]  INFO {org.apache.spark.SparkContext} -  Starting job: collect at KMeans.scala:373 {org.apache.spark.SparkContext}
[2016-04-29 15:19:15,624]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 13 (collect at KMeans.scala:373) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:15,624]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 13(collect at KMeans.scala:373) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:15,624]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:15,647]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:15,648]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 13 (MapPartitionsRDD[28] at mapPartitionsWithIndex at KMeans.scala:365), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:15,656]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8152) called with curMem=849783, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:15,657]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_19 stored as values in memory (estimated size 8.0 KB, free 982.3 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:15,671]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4236) called with curMem=857935, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:15,672]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_19_piece0 stored as bytes in memory (estimated size 4.1 KB, free 982.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:15,676]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_19_piece0 in memory on localhost:56403 (size: 4.1 KB, free: 982.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:15,677]  INFO {org.apache.spark.SparkContext} -  Created broadcast 19 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:15,678]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[28] at mapPartitionsWithIndex at KMeans.scala:365) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:15,678]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 13.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:15,680]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 13.0 (TID 13, localhost, PROCESS_LOCAL, 2049 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:15,681]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 13.0 (TID 13) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:15,691]  INFO {org.apache.spark.rdd.HadoopRDD} -  Input split: file:/home/ml/wso2ml-1.1.0/datasets/banking.-1234.1461942923269:0+4882918 {org.apache.spark.rdd.HadoopRDD}
[2016-04-29 15:19:15,702]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_16_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:15,702]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_26_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:16,517]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 13.0 (TID 13). 1973 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:16,526]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 13.0 (TID 13) in 845 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:16,526]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 13 (collect at KMeans.scala:373) finished in 0.847 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:16,526]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 13 finished: collect at KMeans.scala:373, took 0.912360 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:16,527]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(368) called with curMem=862171, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:16,527]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 13.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:16,528]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_20 stored as values in memory (estimated size 368.0 B, free 982.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:16,536]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(210) called with curMem=862539, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:16,536]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_20_piece0 stored as bytes in memory (estimated size 210.0 B, free 982.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:16,540]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_20_piece0 in memory on localhost:56403 (size: 210.0 B, free: 982.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:16,541]  INFO {org.apache.spark.SparkContext} -  Created broadcast 20 from broadcast at KMeans.scala:343 {org.apache.spark.SparkContext}
[2016-04-29 15:19:16,563]  INFO {org.apache.spark.SparkContext} -  Starting job: aggregate at KMeans.scala:352 {org.apache.spark.SparkContext}
[2016-04-29 15:19:16,565]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 14 (aggregate at KMeans.scala:352) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:16,565]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 14(aggregate at KMeans.scala:352) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:16,565]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:16,573]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:16,573]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 14 (MapPartitionsRDD[30] at map at KMeans.scala:345), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:16,577]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8192) called with curMem=862749, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:16,577]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_21 stored as values in memory (estimated size 8.0 KB, free 982.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:16,583]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4197) called with curMem=870941, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:16,583]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_21_piece0 stored as bytes in memory (estimated size 4.1 KB, free 982.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:16,589]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_21_piece0 in memory on localhost:56403 (size: 4.1 KB, free: 982.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:16,590]  INFO {org.apache.spark.SparkContext} -  Created broadcast 21 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:16,591]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[30] at map at KMeans.scala:345) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:16,594]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 14.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:16,596]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 14.0 (TID 14, localhost, PROCESS_LOCAL, 2049 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:16,596]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 14.0 (TID 14) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:16,602]  INFO {org.apache.spark.CacheManager} -  Partition rdd_30_0 not found, computing it {org.apache.spark.CacheManager}
[2016-04-29 15:19:16,603]  INFO {org.apache.spark.rdd.HadoopRDD} -  Input split: file:/home/ml/wso2ml-1.1.0/datasets/banking.-1234.1461942923269:0+4882918 {org.apache.spark.rdd.HadoopRDD}
[2016-04-29 15:19:16,610]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_16_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:16,610]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_26_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:17,333]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(440288) called with curMem=875138, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:17,334]  INFO {org.apache.spark.storage.MemoryStore} -  Block rdd_30_0 stored as values in memory (estimated size 430.0 KB, free 981.8 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:17,335]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added rdd_30_0 in memory on localhost:56403 (size: 430.0 KB, free: 981.9 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:17,342]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 14.0 (TID 14). 2382 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:17,349]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 14.0 (TID 14) in 754 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:17,349]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 14.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:17,349]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 14 (aggregate at KMeans.scala:352) finished in 0.755 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:17,351]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 14 finished: aggregate at KMeans.scala:352, took 0.787625 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:17,351]  INFO {org.apache.spark.rdd.MapPartitionsRDD} -  Removing RDD 26 from persistence list {org.apache.spark.rdd.MapPartitionsRDD}
[2016-04-29 15:19:17,352]  INFO {org.apache.spark.storage.BlockManager} -  Removing RDD 26 {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:17,374]  INFO {org.apache.spark.SparkContext} -  Starting job: collect at KMeans.scala:373 {org.apache.spark.SparkContext}
[2016-04-29 15:19:17,376]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 15 (collect at KMeans.scala:373) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:17,376]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 15(collect at KMeans.scala:373) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:17,376]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:17,384]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:17,385]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 15 (MapPartitionsRDD[32] at mapPartitionsWithIndex at KMeans.scala:365), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:17,388]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8384) called with curMem=875138, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:17,389]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_22 stored as values in memory (estimated size 8.2 KB, free 982.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:17,397]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4289) called with curMem=883522, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:17,397]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_22_piece0 stored as bytes in memory (estimated size 4.2 KB, free 982.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:17,399]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_22_piece0 in memory on localhost:56403 (size: 4.2 KB, free: 982.3 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:17,400]  INFO {org.apache.spark.SparkContext} -  Created broadcast 22 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:17,401]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[32] at mapPartitionsWithIndex at KMeans.scala:365) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:17,401]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 15.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:17,403]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 15.0 (TID 15, localhost, PROCESS_LOCAL, 2081 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:17,404]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 15.0 (TID 15) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:17,411]  INFO {org.apache.spark.rdd.HadoopRDD} -  Input split: file:/home/ml/wso2ml-1.1.0/datasets/banking.-1234.1461942923269:0+4882918 {org.apache.spark.rdd.HadoopRDD}
[2016-04-29 15:19:17,418]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_16_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:17,419]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_30_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:18,209]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 15.0 (TID 15). 2015 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:18,221]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 15.0 (TID 15) in 819 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:18,222]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 15.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:18,221]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 15 (collect at KMeans.scala:373) finished in 0.820 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:18,223]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 15 finished: collect at KMeans.scala:373, took 0.848626 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:18,224]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(440) called with curMem=887811, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:18,225]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_23 stored as values in memory (estimated size 440.0 B, free 982.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:18,233]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(232) called with curMem=888251, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:18,234]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_23_piece0 stored as bytes in memory (estimated size 232.0 B, free 982.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:18,239]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_23_piece0 in memory on localhost:56403 (size: 232.0 B, free: 982.3 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:18,240]  INFO {org.apache.spark.SparkContext} -  Created broadcast 23 from broadcast at KMeans.scala:343 {org.apache.spark.SparkContext}
[2016-04-29 15:19:18,262]  INFO {org.apache.spark.SparkContext} -  Starting job: aggregate at KMeans.scala:352 {org.apache.spark.SparkContext}
[2016-04-29 15:19:18,265]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 16 (aggregate at KMeans.scala:352) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:18,265]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 16(aggregate at KMeans.scala:352) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:18,265]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:18,275]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:18,276]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 16 (MapPartitionsRDD[34] at map at KMeans.scala:345), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:18,279]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8424) called with curMem=888483, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:18,280]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_24 stored as values in memory (estimated size 8.2 KB, free 982.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:18,290]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4248) called with curMem=896907, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:18,290]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_24_piece0 stored as bytes in memory (estimated size 4.1 KB, free 982.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:18,292]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_24_piece0 in memory on localhost:56403 (size: 4.1 KB, free: 982.3 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:18,293]  INFO {org.apache.spark.SparkContext} -  Created broadcast 24 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:18,295]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[34] at map at KMeans.scala:345) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:18,295]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 16.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:18,297]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 16.0 (TID 16, localhost, PROCESS_LOCAL, 2081 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:18,297]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 16.0 (TID 16) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:18,311]  INFO {org.apache.spark.CacheManager} -  Partition rdd_34_0 not found, computing it {org.apache.spark.CacheManager}
[2016-04-29 15:19:18,311]  INFO {org.apache.spark.rdd.HadoopRDD} -  Input split: file:/home/ml/wso2ml-1.1.0/datasets/banking.-1234.1461942923269:0+4882918 {org.apache.spark.rdd.HadoopRDD}
[2016-04-29 15:19:18,324]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_16_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:18,324]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_30_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:18,420]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_19_piece0 on localhost:56403 in memory (size: 4.1 KB, free: 982.3 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:18,428]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_18_piece0 on localhost:56403 in memory (size: 4.0 KB, free: 982.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:18,436]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_16_piece0 on localhost:56403 in memory (size: 4.1 KB, free: 982.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:18,446]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_22_piece0 on localhost:56403 in memory (size: 4.2 KB, free: 982.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:18,456]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_21_piece0 on localhost:56403 in memory (size: 4.1 KB, free: 982.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:19,103]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(440288) called with curMem=839544, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:19,104]  INFO {org.apache.spark.storage.MemoryStore} -  Block rdd_34_0 stored as values in memory (estimated size 430.0 KB, free 981.8 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:19,105]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added rdd_34_0 in memory on localhost:56403 (size: 430.0 KB, free: 981.9 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:19,114]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 16.0 (TID 16). 2382 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:19,122]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 16.0 (TID 16) in 826 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:19,123]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 16.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:19,122]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 16 (aggregate at KMeans.scala:352) finished in 0.826 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:19,124]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 16 finished: aggregate at KMeans.scala:352, took 0.861448 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:19,125]  INFO {org.apache.spark.rdd.MapPartitionsRDD} -  Removing RDD 30 from persistence list {org.apache.spark.rdd.MapPartitionsRDD}
[2016-04-29 15:19:19,128]  INFO {org.apache.spark.storage.BlockManager} -  Removing RDD 30 {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:19,151]  INFO {org.apache.spark.SparkContext} -  Starting job: collect at KMeans.scala:373 {org.apache.spark.SparkContext}
[2016-04-29 15:19:19,154]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 17 (collect at KMeans.scala:373) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:19,154]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 17(collect at KMeans.scala:373) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:19,154]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:19,163]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:19,164]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 17 (MapPartitionsRDD[36] at mapPartitionsWithIndex at KMeans.scala:365), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:19,169]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8624) called with curMem=839544, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:19,169]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_25 stored as values in memory (estimated size 8.4 KB, free 982.3 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:19,189]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4346) called with curMem=848168, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:19,190]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_25_piece0 stored as bytes in memory (estimated size 4.2 KB, free 982.3 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:19,192]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_25_piece0 in memory on localhost:56403 (size: 4.2 KB, free: 982.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:19,193]  INFO {org.apache.spark.SparkContext} -  Created broadcast 25 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:19,195]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[36] at mapPartitionsWithIndex at KMeans.scala:365) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:19,195]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 17.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:19,197]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 17.0 (TID 17, localhost, PROCESS_LOCAL, 2113 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:19,197]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 17.0 (TID 17) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:19,207]  INFO {org.apache.spark.rdd.HadoopRDD} -  Input split: file:/home/ml/wso2ml-1.1.0/datasets/banking.-1234.1461942923269:0+4882918 {org.apache.spark.rdd.HadoopRDD}
[2016-04-29 15:19:19,221]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_16_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:19,221]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_34_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:20,055]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 17.0 (TID 17). 2171 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:20,065]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 17.0 (TID 17) in 869 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:20,065]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 17 (collect at KMeans.scala:373) finished in 0.869 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:20,065]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 17.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:20,067]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 17 finished: collect at KMeans.scala:373, took 0.913943 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:20,068]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(728) called with curMem=852514, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:20,069]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_26 stored as values in memory (estimated size 728.0 B, free 982.3 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:20,075]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(320) called with curMem=853242, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:20,076]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_26_piece0 stored as bytes in memory (estimated size 320.0 B, free 982.3 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:20,079]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_26_piece0 in memory on localhost:56403 (size: 320.0 B, free: 982.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:20,079]  INFO {org.apache.spark.SparkContext} -  Created broadcast 26 from broadcast at KMeans.scala:343 {org.apache.spark.SparkContext}
[2016-04-29 15:19:20,103]  INFO {org.apache.spark.SparkContext} -  Starting job: aggregate at KMeans.scala:352 {org.apache.spark.SparkContext}
[2016-04-29 15:19:20,105]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 18 (aggregate at KMeans.scala:352) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:20,106]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 18(aggregate at KMeans.scala:352) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:20,106]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:20,114]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:20,114]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 18 (MapPartitionsRDD[38] at map at KMeans.scala:345), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:20,117]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8656) called with curMem=853562, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:20,117]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_27 stored as values in memory (estimated size 8.5 KB, free 982.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:20,127]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4299) called with curMem=862218, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:20,127]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_27_piece0 stored as bytes in memory (estimated size 4.2 KB, free 982.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:20,130]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_27_piece0 in memory on localhost:56403 (size: 4.2 KB, free: 982.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:20,131]  INFO {org.apache.spark.SparkContext} -  Created broadcast 27 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:20,132]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[38] at map at KMeans.scala:345) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:20,132]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 18.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:20,133]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 18.0 (TID 18, localhost, PROCESS_LOCAL, 2113 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:20,134]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 18.0 (TID 18) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:20,140]  INFO {org.apache.spark.CacheManager} -  Partition rdd_38_0 not found, computing it {org.apache.spark.CacheManager}
[2016-04-29 15:19:20,141]  INFO {org.apache.spark.rdd.HadoopRDD} -  Input split: file:/home/ml/wso2ml-1.1.0/datasets/banking.-1234.1461942923269:0+4882918 {org.apache.spark.rdd.HadoopRDD}
[2016-04-29 15:19:20,150]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_16_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:20,150]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_34_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:21,075]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(440288) called with curMem=866517, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:21,075]  INFO {org.apache.spark.storage.MemoryStore} -  Block rdd_38_0 stored as values in memory (estimated size 430.0 KB, free 981.8 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:21,076]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added rdd_38_0 in memory on localhost:56403 (size: 430.0 KB, free: 981.9 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:21,084]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 18.0 (TID 18). 2382 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:21,090]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 18 (aggregate at KMeans.scala:352) finished in 0.949 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:21,091]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 18 finished: aggregate at KMeans.scala:352, took 0.987074 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:21,091]  INFO {org.apache.spark.rdd.MapPartitionsRDD} -  Removing RDD 34 from persistence list {org.apache.spark.rdd.MapPartitionsRDD}
[2016-04-29 15:19:21,092]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 18.0 (TID 18) in 957 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:21,092]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 18.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:21,092]  INFO {org.apache.spark.storage.BlockManager} -  Removing RDD 34 {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:21,118]  INFO {org.apache.spark.SparkContext} -  Starting job: collect at KMeans.scala:373 {org.apache.spark.SparkContext}
[2016-04-29 15:19:21,120]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 19 (collect at KMeans.scala:373) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:21,121]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 19(collect at KMeans.scala:373) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:21,123]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:21,139]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:21,140]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 19 (MapPartitionsRDD[40] at mapPartitionsWithIndex at KMeans.scala:365), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:21,143]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8856) called with curMem=866517, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:21,144]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_28 stored as values in memory (estimated size 8.6 KB, free 982.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:21,150]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4402) called with curMem=875373, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:21,150]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_28_piece0 stored as bytes in memory (estimated size 4.3 KB, free 982.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:21,152]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_28_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 982.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:21,153]  INFO {org.apache.spark.SparkContext} -  Created broadcast 28 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:21,153]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[40] at mapPartitionsWithIndex at KMeans.scala:365) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:21,153]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 19.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:21,155]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 19.0 (TID 19, localhost, PROCESS_LOCAL, 2145 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:21,155]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 19.0 (TID 19) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:21,159]  INFO {org.apache.spark.rdd.HadoopRDD} -  Input split: file:/home/ml/wso2ml-1.1.0/datasets/banking.-1234.1461942923269:0+4882918 {org.apache.spark.rdd.HadoopRDD}
[2016-04-29 15:19:21,167]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_16_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:21,167]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_38_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:21,929]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 19.0 (TID 19). 2210 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:21,937]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 19.0 (TID 19) in 782 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:21,937]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 19.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:21,937]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 19 (collect at KMeans.scala:373) finished in 0.783 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:21,938]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 19 finished: collect at KMeans.scala:373, took 0.819424 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:21,938]  INFO {org.apache.spark.rdd.MapPartitionsRDD} -  Removing RDD 38 from persistence list {org.apache.spark.rdd.MapPartitionsRDD}
[2016-04-29 15:19:21,940]  INFO {org.apache.spark.storage.BlockManager} -  Removing RDD 38 {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:21,940]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(2520) called with curMem=439487, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:21,943]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_29 stored as values in memory (estimated size 2.5 KB, free 982.6 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:21,949]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(769) called with curMem=442007, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:21,950]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_29_piece0 stored as bytes in memory (estimated size 769.0 B, free 982.6 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:21,952]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_29_piece0 in memory on localhost:56403 (size: 769.0 B, free: 982.8 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:21,953]  INFO {org.apache.spark.SparkContext} -  Created broadcast 29 from broadcast at KMeans.scala:387 {org.apache.spark.SparkContext}
[2016-04-29 15:19:22,005]  INFO {org.apache.spark.SparkContext} -  Starting job: collectAsMap at KMeans.scala:392 {org.apache.spark.SparkContext}
[2016-04-29 15:19:22,010]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Registering RDD 41 (flatMap at KMeans.scala:388) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:22,011]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 20 (collectAsMap at KMeans.scala:392) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:22,011]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 21(collectAsMap at KMeans.scala:392) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:22,011]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List(ShuffleMapStage 20) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:22,012]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List(ShuffleMapStage 20) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:22,020]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ShuffleMapStage 20 (MapPartitionsRDD[41] at flatMap at KMeans.scala:388), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:22,025]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(7680) called with curMem=442776, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:22,026]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_30 stored as values in memory (estimated size 7.5 KB, free 982.6 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:22,032]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4109) called with curMem=450456, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:22,032]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_30_piece0 stored as bytes in memory (estimated size 4.0 KB, free 982.6 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:22,036]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_30_piece0 in memory on localhost:56403 (size: 4.0 KB, free: 982.8 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:22,037]  INFO {org.apache.spark.SparkContext} -  Created broadcast 30 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:22,040]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[41] at flatMap at KMeans.scala:388) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:22,041]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 20.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:22,043]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 20.0 (TID 20, localhost, PROCESS_LOCAL, 1942 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:22,044]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 20.0 (TID 20) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:22,051]  INFO {org.apache.spark.rdd.HadoopRDD} -  Input split: file:/home/ml/wso2ml-1.1.0/datasets/banking.-1234.1461942923269:0+4882918 {org.apache.spark.rdd.HadoopRDD}
[2016-04-29 15:19:22,067]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_16_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:22,111]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(38520) called with curMem=454565, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:22,112]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_31 stored as values in memory (estimated size 37.6 KB, free 982.6 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:22,161]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4089) called with curMem=493085, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:22,162]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_31_piece0 stored as bytes in memory (estimated size 4.0 KB, free 982.6 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:22,164]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_31_piece0 in memory on localhost:56403 (size: 4.0 KB, free: 982.8 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:22,165]  INFO {org.apache.spark.SparkContext} -  Created broadcast 31 from textFile at MLModelHandler.java:953 {org.apache.spark.SparkContext}
[2016-04-29 15:19:22,263]  INFO {org.apache.spark.rdd.MapPartitionsRDD} -  Removing RDD 44 from persistence list {org.apache.spark.rdd.MapPartitionsRDD}
[2016-04-29 15:19:22,273]  INFO {org.apache.spark.storage.BlockManager} -  Removing RDD 44 {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:22,340]  INFO {org.apache.spark.rdd.MapPartitionsRDD} -  Removing RDD 52 from persistence list {org.apache.spark.rdd.MapPartitionsRDD}
[2016-04-29 15:19:22,355]  INFO {org.apache.spark.storage.BlockManager} -  Removing RDD 52 {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:22,419]  INFO {org.apache.hadoop.mapred.FileInputFormat} -  Total input paths to process : 1 {org.apache.hadoop.mapred.FileInputFormat}
[2016-04-29 15:19:22,437]  INFO {org.apache.spark.SparkContext} -  Starting job: first at GeneralizedLinearAlgorithm.scala:182 {org.apache.spark.SparkContext}
[2016-04-29 15:19:22,439]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 21 (first at GeneralizedLinearAlgorithm.scala:182) with 1 output partitions (allowLocal=true) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:22,440]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 22(first at GeneralizedLinearAlgorithm.scala:182) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:22,440]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:22,449]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:22,450]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 22 (MapPartitionsRDD[55] at map at GeneralizedLinearAlgorithm.scala:182), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:22,461]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(6424) called with curMem=497174, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:22,463]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_32 stored as values in memory (estimated size 6.3 KB, free 982.6 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:22,478]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(3409) called with curMem=503598, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:22,483]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_32_piece0 stored as bytes in memory (estimated size 3.3 KB, free 982.6 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:22,487]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_32_piece0 in memory on localhost:56403 (size: 3.3 KB, free: 982.8 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:22,487]  INFO {org.apache.spark.SparkContext} -  Created broadcast 32 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:22,488]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[55] at map at GeneralizedLinearAlgorithm.scala:182) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:22,489]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 22.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:23,222]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 20.0 (TID 20). 1930 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:23,223]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 22.0 (TID 21, localhost, PROCESS_LOCAL, 1436 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:23,235]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 22.0 (TID 21) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:23,241]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ShuffleMapStage 20 (flatMap at KMeans.scala:388) finished in 1.199 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:23,243]  INFO {org.apache.spark.scheduler.DAGScheduler} -  looking for newly runnable stages {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:23,243]  INFO {org.apache.spark.scheduler.DAGScheduler} -  running: Set(ResultStage 22) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:23,244]  INFO {org.apache.spark.scheduler.DAGScheduler} -  waiting: Set(ResultStage 21) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:23,245]  INFO {org.apache.spark.scheduler.DAGScheduler} -  failed: Set() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:23,246]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 20.0 (TID 20) in 1197 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:23,247]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 20.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:23,249]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents for ResultStage 21: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:23,252]  INFO {org.apache.spark.CacheManager} -  Partition rdd_53_0 not found, computing it {org.apache.spark.CacheManager}
[2016-04-29 15:19:23,253]  INFO {org.apache.spark.rdd.HadoopRDD} -  Input split: file:/home/ml/wso2ml-1.1.0/datasets/banking.-1234.1461942923269:0+4882918 {org.apache.spark.rdd.HadoopRDD}
[2016-04-29 15:19:23,254]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 21 (ShuffledRDD[42] at reduceByKey at KMeans.scala:392), which is now runnable {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:23,256]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(2280) called with curMem=507007, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:23,257]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_33 stored as values in memory (estimated size 2.2 KB, free 982.6 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:23,266]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(1367) called with curMem=509287, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:23,266]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_33_piece0 stored as bytes in memory (estimated size 1367.0 B, free 982.6 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:23,268]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_33_piece0 in memory on localhost:56403 (size: 1367.0 B, free: 982.8 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:23,269]  INFO {org.apache.spark.SparkContext} -  Created broadcast 33 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:23,269]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 21 (ShuffledRDD[42] at reduceByKey at KMeans.scala:392) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:23,269]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 21.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:23,370]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_30_piece0 on localhost:56403 in memory (size: 4.0 KB, free: 982.8 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:23,376]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_28_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 982.8 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:23,380]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_27_piece0 on localhost:56403 in memory (size: 4.2 KB, free: 982.8 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:23,385]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_25_piece0 on localhost:56403 in memory (size: 4.2 KB, free: 982.8 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:25,918]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(2640528) called with curMem=459682, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:25,919]  INFO {org.apache.spark.storage.MemoryStore} -  Block rdd_53_0 stored as values in memory (estimated size 2.5 MB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:25,919]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added rdd_53_0 in memory on localhost:56403 (size: 2.5 MB, free: 980.3 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:25,924]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 22.0 (TID 21). 2335 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:25,926]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 21.0 (TID 22, localhost, PROCESS_LOCAL, 1165 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:25,927]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 21.0 (TID 22) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:25,932]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 22 (first at GeneralizedLinearAlgorithm.scala:182) finished in 3.442 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:25,932]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 22.0 (TID 21) in 2709 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:25,934]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 21 finished: first at GeneralizedLinearAlgorithm.scala:182, took 3.495881 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:25,934]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 22.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:25,945]  INFO {org.apache.spark.SparkContext} -  Starting job: count at GradientDescent.scala:161 {org.apache.spark.SparkContext}
[2016-04-29 15:19:25,947]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 22 (count at GradientDescent.scala:161) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:25,947]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 23(count at GradientDescent.scala:161) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:25,947]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:25,949]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:25,950]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 23 (MapPartitionsRDD[56] at map at GeneralizedLinearAlgorithm.scala:266), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:25,952]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(6128) called with curMem=3100210, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:25,953]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_34 stored as values in memory (estimated size 6.0 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:25,959]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(3269) called with curMem=3106338, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:25,960]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_34_piece0 stored as bytes in memory (estimated size 3.2 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:25,962]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_34_piece0 in memory on localhost:56403 (size: 3.2 KB, free: 980.3 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:25,963]  INFO {org.apache.spark.SparkContext} -  Created broadcast 34 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:25,963]  INFO {org.apache.spark.storage.ShuffleBlockFetcherIterator} -  Getting 1 non-empty blocks out of 1 blocks {org.apache.spark.storage.ShuffleBlockFetcherIterator}
[2016-04-29 15:19:25,963]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[56] at map at GeneralizedLinearAlgorithm.scala:266) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:25,964]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 23.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:25,965]  INFO {org.apache.spark.storage.ShuffleBlockFetcherIterator} -  Started 0 remote fetches in 21 ms {org.apache.spark.storage.ShuffleBlockFetcherIterator}
[2016-04-29 15:19:26,012]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 21.0 (TID 22). 1536 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:26,013]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 23.0 (TID 23, localhost, PROCESS_LOCAL, 1436 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:26,014]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 23.0 (TID 23) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:26,018]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:26,018]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 21.0 (TID 22) in 93 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:26,018]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 21.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:26,019]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 21 (collectAsMap at KMeans.scala:392) finished in 2.749 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:26,021]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 20 finished: collectAsMap at KMeans.scala:392, took 4.015181 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:26,048]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 23.0 (TID 23). 1752 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:26,055]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 23 (count at GradientDescent.scala:161) finished in 0.091 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:26,056]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 22 finished: count at GradientDescent.scala:161, took 0.110348 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:26,059]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 23.0 (TID 23) in 42 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:26,059]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 23.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:26,158]  INFO {org.apache.spark.mllib.clustering.LocalKMeans} -  Local KMeans++ converged in 3 iterations. {org.apache.spark.mllib.clustering.LocalKMeans}
[2016-04-29 15:19:26,168]  INFO {org.apache.spark.mllib.clustering.KMeans} -  Initialization with k-means|| took 17.817 seconds. {org.apache.spark.mllib.clustering.KMeans}
[2016-04-29 15:19:26,180]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(296) called with curMem=3109607, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:26,181]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_35 stored as values in memory (estimated size 296.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:26,187]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(183) called with curMem=3109903, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:26,188]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_35_piece0 stored as bytes in memory (estimated size 183.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:26,190]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_35_piece0 in memory on localhost:56403 (size: 183.0 B, free: 980.3 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:26,191]  INFO {org.apache.spark.SparkContext} -  Created broadcast 35 from broadcast at KMeans.scala:225 {org.apache.spark.SparkContext}
[2016-04-29 15:19:26,249]  INFO {org.apache.spark.SparkContext} -  Starting job: collectAsMap at KMeans.scala:251 {org.apache.spark.SparkContext}
[2016-04-29 15:19:26,251]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Registering RDD 57 (mapPartitions at KMeans.scala:228) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:26,251]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 23 (collectAsMap at KMeans.scala:251) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:26,251]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 25(collectAsMap at KMeans.scala:251) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:26,252]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List(ShuffleMapStage 24) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:26,252]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List(ShuffleMapStage 24) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:26,260]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ShuffleMapStage 24 (MapPartitionsRDD[57] at mapPartitions at KMeans.scala:228), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:26,264]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8264) called with curMem=3110086, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:26,264]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_36 stored as values in memory (estimated size 8.1 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:26,270]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4415) called with curMem=3118350, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:26,271]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_36_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:26,273]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_36_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:26,274]  INFO {org.apache.spark.SparkContext} -  Created broadcast 36 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:26,275]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ShuffleMapStage 24 (MapPartitionsRDD[57] at mapPartitions at KMeans.scala:228) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:26,275]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 24.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:26,276]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 24.0 (TID 24, localhost, PROCESS_LOCAL, 1942 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:26,277]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 24.0 (TID 24) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:26,284]  INFO {org.apache.spark.rdd.HadoopRDD} -  Input split: file:/home/ml/wso2ml-1.1.0/datasets/banking.-1234.1461942923269:0+4882918 {org.apache.spark.rdd.HadoopRDD}
[2016-04-29 15:19:26,303]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_16_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:26,622]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3122765, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:26,623]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_37 stored as values in memory (estimated size 88.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:26,632]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(62) called with curMem=3122853, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:26,632]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_37_piece0 stored as bytes in memory (estimated size 62.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:26,634]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_37_piece0 in memory on localhost:56403 (size: 62.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:26,634]  INFO {org.apache.spark.SparkContext} -  Created broadcast 37 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:26,698]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:26,700]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 24 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:26,700]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 26(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:26,700]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:26,704]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:26,705]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 26 (MapPartitionsRDD[60] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:26,708]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3122915, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:26,708]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_38 stored as values in memory (estimated size 8.5 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:26,714]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4428) called with curMem=3131667, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:26,715]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_38_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:26,717]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_38_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:26,718]  INFO {org.apache.spark.SparkContext} -  Created broadcast 38 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:26,718]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[60] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:26,718]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 26.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:27,138]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 24.0 (TID 24). 1991 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:27,140]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 26.0 (TID 25, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:27,141]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 26.0 (TID 25) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:27,156]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ShuffleMapStage 24 (mapPartitions at KMeans.scala:228) finished in 0.880 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:27,157]  INFO {org.apache.spark.scheduler.DAGScheduler} -  looking for newly runnable stages {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:27,157]  INFO {org.apache.spark.scheduler.DAGScheduler} -  running: Set(ResultStage 26) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:27,157]  INFO {org.apache.spark.scheduler.DAGScheduler} -  waiting: Set(ResultStage 25) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:27,157]  INFO {org.apache.spark.scheduler.DAGScheduler} -  failed: Set() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:27,158]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents for ResultStage 25: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:27,159]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 25 (ShuffledRDD[58] at reduceByKey at KMeans.scala:251), which is now runnable {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:27,160]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(2752) called with curMem=3136095, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:27,162]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_39 stored as values in memory (estimated size 2.7 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:27,161]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 24.0 (TID 24) in 877 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:27,165]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 24.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:27,165]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:27,176]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(1568) called with curMem=3138847, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:27,177]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_39_piece0 stored as bytes in memory (estimated size 1568.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:27,184]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_39_piece0 in memory on localhost:56403 (size: 1568.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:27,185]  INFO {org.apache.spark.SparkContext} -  Created broadcast 39 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:27,187]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 25 (ShuffledRDD[58] at reduceByKey at KMeans.scala:251) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:27,187]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 25.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:27,282]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 26.0 (TID 25). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:27,284]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 25.0 (TID 26, localhost, PROCESS_LOCAL, 1165 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:27,285]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 25.0 (TID 26) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:27,296]  INFO {org.apache.spark.storage.ShuffleBlockFetcherIterator} -  Getting 1 non-empty blocks out of 1 blocks {org.apache.spark.storage.ShuffleBlockFetcherIterator}
[2016-04-29 15:19:27,298]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 26.0 (TID 25) in 158 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:27,297]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 26 (treeAggregate at GradientDescent.scala:189) finished in 0.578 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:27,302]  INFO {org.apache.spark.storage.ShuffleBlockFetcherIterator} -  Started 0 remote fetches in 10 ms {org.apache.spark.storage.ShuffleBlockFetcherIterator}
[2016-04-29 15:19:27,305]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 24 finished: treeAggregate at GradientDescent.scala:189, took 0.606892 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:27,308]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3140415, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:27,309]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_40 stored as values in memory (estimated size 88.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:27,309]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 26.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:27,320]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3140503, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:27,323]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_40_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:27,328]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_40_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:27,329]  INFO {org.apache.spark.SparkContext} -  Created broadcast 40 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:27,337]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 25.0 (TID 26). 1016 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:27,343]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 25 (collectAsMap at KMeans.scala:251) finished in 0.156 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:27,344]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 23 finished: collectAsMap at KMeans.scala:251, took 1.094310 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:27,345]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 25.0 (TID 26) in 60 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:27,346]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 25.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:27,350]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(296) called with curMem=3140586, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:27,351]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_41 stored as values in memory (estimated size 296.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:27,356]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(183) called with curMem=3140882, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:27,357]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_41_piece0 stored as bytes in memory (estimated size 183.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:27,365]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_41_piece0 in memory on localhost:56403 (size: 183.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:27,370]  INFO {org.apache.spark.SparkContext} -  Created broadcast 41 from broadcast at KMeans.scala:225 {org.apache.spark.SparkContext}
[2016-04-29 15:19:27,387]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:27,390]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 25 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:27,390]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 27(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:27,390]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:27,393]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:27,396]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 27 (MapPartitionsRDD[62] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:27,398]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3141065, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:27,398]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_42 stored as values in memory (estimated size 8.5 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:27,410]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4432) called with curMem=3149817, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:27,411]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_42_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:27,416]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_42_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:27,417]  INFO {org.apache.spark.SparkContext} -  Created broadcast 42 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:27,418]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[62] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:27,419]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 27.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:27,421]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 27.0 (TID 27, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:27,421]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 27.0 (TID 27) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:27,420]  INFO {org.apache.spark.SparkContext} -  Starting job: collectAsMap at KMeans.scala:251 {org.apache.spark.SparkContext}
[2016-04-29 15:19:27,423]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Registering RDD 63 (mapPartitions at KMeans.scala:228) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:27,423]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 26 (collectAsMap at KMeans.scala:251) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:27,423]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 29(collectAsMap at KMeans.scala:251) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:27,423]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List(ShuffleMapStage 28) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:27,424]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List(ShuffleMapStage 28) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:27,426]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:27,442]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ShuffleMapStage 28 (MapPartitionsRDD[63] at mapPartitions at KMeans.scala:228), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:27,445]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8264) called with curMem=3154249, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:27,448]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_43 stored as values in memory (estimated size 8.1 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:27,461]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 27.0 (TID 27). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:27,462]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4417) called with curMem=3162513, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:27,464]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_43_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:27,470]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_43_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:27,471]  INFO {org.apache.spark.SparkContext} -  Created broadcast 43 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:27,472]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ShuffleMapStage 28 (MapPartitionsRDD[63] at mapPartitions at KMeans.scala:228) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:27,472]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 28.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:27,475]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 28.0 (TID 28, localhost, PROCESS_LOCAL, 1942 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:27,476]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 28.0 (TID 28) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:27,482]  INFO {org.apache.spark.rdd.HadoopRDD} -  Input split: file:/home/ml/wso2ml-1.1.0/datasets/banking.-1234.1461942923269:0+4882918 {org.apache.spark.rdd.HadoopRDD}
[2016-04-29 15:19:27,486]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 27 (treeAggregate at GradientDescent.scala:189) finished in 0.065 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:27,487]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 27.0 (TID 27) in 57 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:27,487]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 25 finished: treeAggregate at GradientDescent.scala:189, took 0.099439 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:27,487]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 27.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:27,488]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3166930, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:27,489]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_44 stored as values in memory (estimated size 88.0 B, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:27,496]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3167018, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:27,500]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_44_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:27,505]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_44_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:27,506]  INFO {org.apache.spark.SparkContext} -  Created broadcast 44 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:27,516]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_16_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:27,563]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:27,564]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 27 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:27,565]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 30(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:27,565]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:27,569]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:27,570]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 30 (MapPartitionsRDD[66] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:27,572]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3167101, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:27,573]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_45 stored as values in memory (estimated size 8.5 KB, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:27,580]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4426) called with curMem=3175853, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:27,590]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_45_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:27,594]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_45_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:27,595]  INFO {org.apache.spark.SparkContext} -  Created broadcast 45 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:27,595]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[66] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:27,595]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 30.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:28,382]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 28.0 (TID 28). 1991 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:28,383]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 30.0 (TID 29, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:28,384]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 30.0 (TID 29) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:28,388]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ShuffleMapStage 28 (mapPartitions at KMeans.scala:228) finished in 0.914 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:28,388]  INFO {org.apache.spark.scheduler.DAGScheduler} -  looking for newly runnable stages {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:28,388]  INFO {org.apache.spark.scheduler.DAGScheduler} -  running: Set(ResultStage 30) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:28,389]  INFO {org.apache.spark.scheduler.DAGScheduler} -  waiting: Set(ResultStage 29) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:28,389]  INFO {org.apache.spark.scheduler.DAGScheduler} -  failed: Set() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:28,389]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:28,388]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 28.0 (TID 28) in 912 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:28,389]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 28.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:28,390]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents for ResultStage 29: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:28,390]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 29 (ShuffledRDD[64] at reduceByKey at KMeans.scala:251), which is now runnable {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:28,391]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(2752) called with curMem=3180279, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:28,391]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_46 stored as values in memory (estimated size 2.7 KB, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:28,397]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(1571) called with curMem=3183031, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:28,397]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_46_piece0 stored as bytes in memory (estimated size 1571.0 B, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:28,399]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_46_piece0 in memory on localhost:56403 (size: 1571.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:28,400]  INFO {org.apache.spark.SparkContext} -  Created broadcast 46 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:28,400]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 29 (ShuffledRDD[64] at reduceByKey at KMeans.scala:251) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:28,400]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 29.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:28,402]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 30.0 (TID 29). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:28,402]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 29.0 (TID 30, localhost, PROCESS_LOCAL, 1165 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:28,406]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 29.0 (TID 30) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:28,409]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 30.0 (TID 29) in 25 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:28,409]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 30.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:28,411]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 30 (treeAggregate at GradientDescent.scala:189) finished in 0.815 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:28,415]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 27 finished: treeAggregate at GradientDescent.scala:189, took 0.852168 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:28,416]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3184602, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:28,417]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_47 stored as values in memory (estimated size 88.0 B, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:28,438]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3184690, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:28,439]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_47_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:28,442]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_47_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:28,444]  INFO {org.apache.spark.SparkContext} -  Created broadcast 47 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:28,447]  INFO {org.apache.spark.storage.ShuffleBlockFetcherIterator} -  Getting 1 non-empty blocks out of 1 blocks {org.apache.spark.storage.ShuffleBlockFetcherIterator}
[2016-04-29 15:19:28,450]  INFO {org.apache.spark.storage.ShuffleBlockFetcherIterator} -  Started 0 remote fetches in 37 ms {org.apache.spark.storage.ShuffleBlockFetcherIterator}
[2016-04-29 15:19:28,450]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_45_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:28,460]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_44_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:28,468]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_43_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:28,475]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_42_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:28,477]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 29.0 (TID 30). 1016 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:28,480]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_40_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:28,485]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 29 (collectAsMap at KMeans.scala:251) finished in 0.084 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:28,486]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 26 finished: collectAsMap at KMeans.scala:251, took 1.064802 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:28,488]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(296) called with curMem=3143820, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:28,489]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_48 stored as values in memory (estimated size 296.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:28,489]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 29.0 (TID 30) in 82 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:28,490]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_39_piece0 on localhost:56403 in memory (size: 1568.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:28,491]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 29.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:28,494]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:28,499]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 28 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:28,499]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 31(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:28,499]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:28,500]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_38_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:28,509]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_37_piece0 on localhost:56403 in memory (size: 62.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:28,509]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:28,512]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 31 (MapPartitionsRDD[68] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:28,514]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3128034, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:28,515]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_49 stored as values in memory (estimated size 8.5 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:28,516]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(183) called with curMem=3132371, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:28,516]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_48_piece0 stored as bytes in memory (estimated size 183.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:28,519]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_36_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.3 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:28,522]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_48_piece0 in memory on localhost:56403 (size: 183.0 B, free: 980.3 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:28,524]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4427) called with curMem=3124290, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:28,525]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_49_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:28,527]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_49_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:28,528]  INFO {org.apache.spark.SparkContext} -  Created broadcast 49 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:28,524]  INFO {org.apache.spark.SparkContext} -  Created broadcast 48 from broadcast at KMeans.scala:225 {org.apache.spark.SparkContext}
[2016-04-29 15:19:28,528]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[68] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:28,529]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 31.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:28,529]  INFO {org.apache.spark.ContextCleaner} -  Cleaned shuffle 1 {org.apache.spark.ContextCleaner}
[2016-04-29 15:19:28,533]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 31.0 (TID 31, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:28,533]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 31.0 (TID 31) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:28,541]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:28,541]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_35_piece0 on localhost:56403 in memory (size: 183.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:28,545]  INFO {org.apache.spark.ContextCleaner} -  Cleaned accumulator 1 {org.apache.spark.ContextCleaner}
[2016-04-29 15:19:28,551]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_34_piece0 on localhost:56403 in memory (size: 3.2 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:28,555]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 31.0 (TID 31). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:28,562]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 31 (treeAggregate at GradientDescent.scala:189) finished in 0.030 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:28,562]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 28 finished: treeAggregate at GradientDescent.scala:189, took 0.065868 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:28,563]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 31.0 (TID 31) in 29 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:28,563]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 31.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:28,563]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3118841, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:28,562]  INFO {org.apache.spark.SparkContext} -  Starting job: collectAsMap at KMeans.scala:251 {org.apache.spark.SparkContext}
[2016-04-29 15:19:28,564]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_50 stored as values in memory (estimated size 88.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:28,565]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Registering RDD 69 (mapPartitions at KMeans.scala:228) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:28,565]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 29 (collectAsMap at KMeans.scala:251) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:28,566]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 33(collectAsMap at KMeans.scala:251) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:28,566]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List(ShuffleMapStage 32) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:28,567]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List(ShuffleMapStage 32) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:28,569]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3118929, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:28,571]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_50_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:28,574]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_50_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:28,575]  INFO {org.apache.spark.SparkContext} -  Created broadcast 50 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:28,580]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ShuffleMapStage 32 (MapPartitionsRDD[69] at mapPartitions at KMeans.scala:228), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:28,582]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8264) called with curMem=3119012, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:28,582]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_51 stored as values in memory (estimated size 8.1 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:28,589]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4419) called with curMem=3127276, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:28,589]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_51_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:28,591]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_51_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:28,591]  INFO {org.apache.spark.SparkContext} -  Created broadcast 51 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:28,592]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ShuffleMapStage 32 (MapPartitionsRDD[69] at mapPartitions at KMeans.scala:228) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:28,592]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 32.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:28,593]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 32.0 (TID 32, localhost, PROCESS_LOCAL, 1942 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:28,594]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 32.0 (TID 32) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:28,598]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:28,598]  INFO {org.apache.spark.rdd.HadoopRDD} -  Input split: file:/home/ml/wso2ml-1.1.0/datasets/banking.-1234.1461942923269:0+4882918 {org.apache.spark.rdd.HadoopRDD}
[2016-04-29 15:19:28,600]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 30 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:28,600]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 34(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:28,601]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:28,604]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:28,606]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 34 (MapPartitionsRDD[72] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:28,610]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3131695, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:28,611]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_52 stored as values in memory (estimated size 8.5 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:28,611]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_16_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:28,627]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4433) called with curMem=3140447, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:28,628]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_52_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:28,629]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_52_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:28,630]  INFO {org.apache.spark.SparkContext} -  Created broadcast 52 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:28,630]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[72] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:28,632]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 34.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:29,302]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 32.0 (TID 32). 1991 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:29,303]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 34.0 (TID 33, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:29,305]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 34.0 (TID 33) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:29,308]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 32.0 (TID 32) in 714 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:29,308]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ShuffleMapStage 32 (mapPartitions at KMeans.scala:228) finished in 0.714 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:29,309]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 32.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:29,311]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:29,309]  INFO {org.apache.spark.scheduler.DAGScheduler} -  looking for newly runnable stages {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:29,312]  INFO {org.apache.spark.scheduler.DAGScheduler} -  running: Set(ResultStage 34) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:29,313]  INFO {org.apache.spark.scheduler.DAGScheduler} -  waiting: Set(ResultStage 33) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:29,313]  INFO {org.apache.spark.scheduler.DAGScheduler} -  failed: Set() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:29,314]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents for ResultStage 33: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:29,315]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 33 (ShuffledRDD[70] at reduceByKey at KMeans.scala:251), which is now runnable {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:29,316]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(2752) called with curMem=3144880, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:29,317]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_53 stored as values in memory (estimated size 2.7 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:29,320]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 34.0 (TID 33). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:29,326]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 34.0 (TID 33) in 23 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:29,327]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 34.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:29,331]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(1570) called with curMem=3147632, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:29,332]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_53_piece0 stored as bytes in memory (estimated size 1570.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:29,333]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_53_piece0 in memory on localhost:56403 (size: 1570.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:29,334]  INFO {org.apache.spark.SparkContext} -  Created broadcast 53 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:29,334]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 33 (ShuffledRDD[70] at reduceByKey at KMeans.scala:251) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:29,334]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 33.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:29,335]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 34 (treeAggregate at GradientDescent.scala:189) finished in 0.702 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:29,336]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 33.0 (TID 34, localhost, PROCESS_LOCAL, 1165 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:29,336]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 30 finished: treeAggregate at GradientDescent.scala:189, took 0.737071 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:29,336]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 33.0 (TID 34) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:29,337]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3149202, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:29,337]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_54 stored as values in memory (estimated size 88.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:29,341]  INFO {org.apache.spark.storage.ShuffleBlockFetcherIterator} -  Getting 1 non-empty blocks out of 1 blocks {org.apache.spark.storage.ShuffleBlockFetcherIterator}
[2016-04-29 15:19:29,342]  INFO {org.apache.spark.storage.ShuffleBlockFetcherIterator} -  Started 0 remote fetches in 4 ms {org.apache.spark.storage.ShuffleBlockFetcherIterator}
[2016-04-29 15:19:29,342]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3149290, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:29,343]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_54_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:29,345]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_54_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:29,346]  INFO {org.apache.spark.SparkContext} -  Created broadcast 54 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:29,360]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 33.0 (TID 34). 1016 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:29,366]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 33 (collectAsMap at KMeans.scala:251) finished in 0.031 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:29,366]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 29 finished: collectAsMap at KMeans.scala:251, took 0.802809 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:29,367]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 33.0 (TID 34) in 31 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:29,367]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 33.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:29,368]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(296) called with curMem=3149373, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:29,368]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_55 stored as values in memory (estimated size 296.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:29,372]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:29,373]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(183) called with curMem=3149669, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:29,373]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_55_piece0 stored as bytes in memory (estimated size 183.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:29,379]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_55_piece0 in memory on localhost:56403 (size: 183.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:29,380]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 31 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:29,380]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 35(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:29,380]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:29,382]  INFO {org.apache.spark.SparkContext} -  Created broadcast 55 from broadcast at KMeans.scala:225 {org.apache.spark.SparkContext}
[2016-04-29 15:19:29,382]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:29,383]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 35 (MapPartitionsRDD[74] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:29,385]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3149852, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:29,386]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_56 stored as values in memory (estimated size 8.5 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:29,390]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4433) called with curMem=3158604, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:29,391]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_56_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:29,393]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_56_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:29,393]  INFO {org.apache.spark.SparkContext} -  Created broadcast 56 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:29,394]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[74] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:29,394]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 35.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:29,395]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 35.0 (TID 35, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:29,395]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 35.0 (TID 35) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:29,400]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:29,406]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 35.0 (TID 35). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:29,411]  INFO {org.apache.spark.SparkContext} -  Starting job: collectAsMap at KMeans.scala:251 {org.apache.spark.SparkContext}
[2016-04-29 15:19:29,412]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 35 (treeAggregate at GradientDescent.scala:189) finished in 0.017 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:29,412]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 31 finished: treeAggregate at GradientDescent.scala:189, took 0.039523 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:29,414]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3163037, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:29,415]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_57 stored as values in memory (estimated size 88.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:29,415]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Registering RDD 75 (mapPartitions at KMeans.scala:228) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:29,411]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 35.0 (TID 35) in 16 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:29,416]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 32 (collectAsMap at KMeans.scala:251) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:29,416]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 37(collectAsMap at KMeans.scala:251) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:29,416]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List(ShuffleMapStage 36) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:29,417]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List(ShuffleMapStage 36) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:29,416]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 35.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:29,421]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3163125, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:29,422]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_57_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:29,424]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ShuffleMapStage 36 (MapPartitionsRDD[75] at mapPartitions at KMeans.scala:228), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:29,424]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_57_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:29,425]  INFO {org.apache.spark.SparkContext} -  Created broadcast 57 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:29,425]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8264) called with curMem=3163208, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:29,428]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_58 stored as values in memory (estimated size 8.1 KB, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:29,433]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4419) called with curMem=3171472, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:29,433]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_58_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:29,435]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_58_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:29,438]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:29,443]  INFO {org.apache.spark.SparkContext} -  Created broadcast 58 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:29,444]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ShuffleMapStage 36 (MapPartitionsRDD[75] at mapPartitions at KMeans.scala:228) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:29,444]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 36.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:29,446]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 36.0 (TID 36, localhost, PROCESS_LOCAL, 1942 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:29,446]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 33 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:29,446]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 36.0 (TID 36) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:29,452]  INFO {org.apache.spark.rdd.HadoopRDD} -  Input split: file:/home/ml/wso2ml-1.1.0/datasets/banking.-1234.1461942923269:0+4882918 {org.apache.spark.rdd.HadoopRDD}
[2016-04-29 15:19:29,446]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 38(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:29,454]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:29,464]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_16_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:29,466]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:29,467]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 38 (MapPartitionsRDD[78] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:29,469]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3175891, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:29,474]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_59 stored as values in memory (estimated size 8.5 KB, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:29,487]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4433) called with curMem=3184643, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:29,494]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_59_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:29,505]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_59_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:29,505]  INFO {org.apache.spark.SparkContext} -  Created broadcast 59 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:29,506]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 38 (MapPartitionsRDD[78] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:29,506]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 38.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:30,148]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 36.0 (TID 36). 1991 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:30,149]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 38.0 (TID 37, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:30,150]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 38.0 (TID 37) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:30,154]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 36.0 (TID 36) in 709 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:30,155]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ShuffleMapStage 36 (mapPartitions at KMeans.scala:228) finished in 0.710 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:30,155]  INFO {org.apache.spark.scheduler.DAGScheduler} -  looking for newly runnable stages {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:30,156]  INFO {org.apache.spark.scheduler.DAGScheduler} -  running: Set(ResultStage 38) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:30,156]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:30,156]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 36.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:30,156]  INFO {org.apache.spark.scheduler.DAGScheduler} -  waiting: Set(ResultStage 37) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:30,157]  INFO {org.apache.spark.scheduler.DAGScheduler} -  failed: Set() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:30,158]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents for ResultStage 37: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:30,159]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 37 (ShuffledRDD[76] at reduceByKey at KMeans.scala:251), which is now runnable {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:30,160]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(2752) called with curMem=3189076, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:30,160]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_60 stored as values in memory (estimated size 2.7 KB, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:30,163]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 38.0 (TID 37). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:30,169]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 38.0 (TID 37) in 19 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:30,170]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 38.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:30,170]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(1570) called with curMem=3191828, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:30,170]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_60_piece0 stored as bytes in memory (estimated size 1570.0 B, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:30,172]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_60_piece0 in memory on localhost:56403 (size: 1570.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:30,173]  INFO {org.apache.spark.SparkContext} -  Created broadcast 60 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:30,173]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 37 (ShuffledRDD[76] at reduceByKey at KMeans.scala:251) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:30,173]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 37.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:30,174]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 38 (treeAggregate at GradientDescent.scala:189) finished in 0.668 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:30,174]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 37.0 (TID 38, localhost, PROCESS_LOCAL, 1165 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:30,175]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 37.0 (TID 38) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:30,178]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 33 finished: treeAggregate at GradientDescent.scala:189, took 0.735522 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:30,179]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3193398, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:30,180]  INFO {org.apache.spark.storage.ShuffleBlockFetcherIterator} -  Getting 1 non-empty blocks out of 1 blocks {org.apache.spark.storage.ShuffleBlockFetcherIterator}
[2016-04-29 15:19:30,180]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_61 stored as values in memory (estimated size 88.0 B, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:30,180]  INFO {org.apache.spark.storage.ShuffleBlockFetcherIterator} -  Started 0 remote fetches in 3 ms {org.apache.spark.storage.ShuffleBlockFetcherIterator}
[2016-04-29 15:19:30,189]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3193486, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:30,189]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_61_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:30,191]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_61_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:30,192]  INFO {org.apache.spark.SparkContext} -  Created broadcast 61 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:30,197]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 37.0 (TID 38). 1016 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:30,203]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 37 (collectAsMap at KMeans.scala:251) finished in 0.029 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:30,203]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 32 finished: collectAsMap at KMeans.scala:251, took 0.791510 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:30,204]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 37.0 (TID 38) in 29 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:30,204]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 37.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:30,205]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(296) called with curMem=3193569, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:30,205]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_62 stored as values in memory (estimated size 296.0 B, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:30,212]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(183) called with curMem=3193865, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:30,212]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_62_piece0 stored as bytes in memory (estimated size 183.0 B, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:30,215]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_62_piece0 in memory on localhost:56403 (size: 183.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:30,215]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:30,216]  INFO {org.apache.spark.SparkContext} -  Created broadcast 62 from broadcast at KMeans.scala:225 {org.apache.spark.SparkContext}
[2016-04-29 15:19:30,217]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 34 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:30,217]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 39(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:30,218]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:30,220]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:30,222]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 39 (MapPartitionsRDD[80] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:30,227]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3194048, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:30,228]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_63 stored as values in memory (estimated size 8.5 KB, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:30,236]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4433) called with curMem=3202800, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:30,236]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_63_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:30,238]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_63_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:30,239]  INFO {org.apache.spark.SparkContext} -  Created broadcast 63 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:30,242]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 39 (MapPartitionsRDD[80] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:30,242]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 39.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:30,243]  INFO {org.apache.spark.SparkContext} -  Starting job: collectAsMap at KMeans.scala:251 {org.apache.spark.SparkContext}
[2016-04-29 15:19:30,244]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 39.0 (TID 39, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:30,244]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 39.0 (TID 39) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:30,245]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Registering RDD 81 (mapPartitions at KMeans.scala:228) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:30,246]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 35 (collectAsMap at KMeans.scala:251) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:30,246]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 41(collectAsMap at KMeans.scala:251) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:30,246]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List(ShuffleMapStage 40) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:30,247]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List(ShuffleMapStage 40) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:30,249]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:30,260]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ShuffleMapStage 40 (MapPartitionsRDD[81] at mapPartitions at KMeans.scala:228), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:30,260]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 39.0 (TID 39). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:30,263]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8264) called with curMem=3207233, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:30,263]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_64 stored as values in memory (estimated size 8.1 KB, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:30,268]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4419) called with curMem=3215497, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:30,269]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 39.0 (TID 39) in 24 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:30,269]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 39.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:30,269]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_64_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:30,271]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_64_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:30,272]  INFO {org.apache.spark.SparkContext} -  Created broadcast 64 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:30,272]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ShuffleMapStage 40 (MapPartitionsRDD[81] at mapPartitions at KMeans.scala:228) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:30,273]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 40.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:30,274]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 40.0 (TID 40, localhost, PROCESS_LOCAL, 1942 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:30,274]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 39 (treeAggregate at GradientDescent.scala:189) finished in 0.030 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:30,274]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 40.0 (TID 40) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:30,277]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 34 finished: treeAggregate at GradientDescent.scala:189, took 0.061127 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:30,278]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3219916, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:30,278]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_65 stored as values in memory (estimated size 88.0 B, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:30,281]  INFO {org.apache.spark.rdd.HadoopRDD} -  Input split: file:/home/ml/wso2ml-1.1.0/datasets/banking.-1234.1461942923269:0+4882918 {org.apache.spark.rdd.HadoopRDD}
[2016-04-29 15:19:30,285]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3220004, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:30,285]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_65_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:30,288]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_65_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:30,289]  INFO {org.apache.spark.SparkContext} -  Created broadcast 65 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:30,293]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_16_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:30,307]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:30,309]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 36 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:30,309]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 42(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:30,309]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:30,313]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:30,314]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 42 (MapPartitionsRDD[84] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:30,316]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3220087, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:30,317]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_66 stored as values in memory (estimated size 8.5 KB, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:30,322]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4428) called with curMem=3228839, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:30,323]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_66_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:30,324]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_66_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:30,325]  INFO {org.apache.spark.SparkContext} -  Created broadcast 66 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:30,326]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 42 (MapPartitionsRDD[84] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:30,326]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 42.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:31,157]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 40.0 (TID 40). 1991 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:31,158]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 42.0 (TID 41, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:31,158]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 42.0 (TID 41) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:31,164]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ShuffleMapStage 40 (mapPartitions at KMeans.scala:228) finished in 0.891 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:31,165]  INFO {org.apache.spark.scheduler.DAGScheduler} -  looking for newly runnable stages {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:31,165]  INFO {org.apache.spark.scheduler.DAGScheduler} -  running: Set(ResultStage 42) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:31,165]  INFO {org.apache.spark.scheduler.DAGScheduler} -  waiting: Set(ResultStage 41) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:31,165]  INFO {org.apache.spark.scheduler.DAGScheduler} -  failed: Set() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:31,166]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:31,165]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 40.0 (TID 40) in 890 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:31,166]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents for ResultStage 41: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:31,167]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 41 (ShuffledRDD[82] at reduceByKey at KMeans.scala:251), which is now runnable {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:31,168]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(2752) called with curMem=3233267, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:31,168]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_67 stored as values in memory (estimated size 2.7 KB, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:31,168]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 40.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:31,173]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(1568) called with curMem=3236019, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:31,174]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_67_piece0 stored as bytes in memory (estimated size 1568.0 B, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:31,174]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 42.0 (TID 41). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:31,179]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_67_piece0 in memory on localhost:56403 (size: 1568.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:31,180]  INFO {org.apache.spark.SparkContext} -  Created broadcast 67 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:31,181]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 41 (ShuffledRDD[82] at reduceByKey at KMeans.scala:251) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:31,183]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 41.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:31,183]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 42.0 (TID 41) in 26 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:31,183]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 42.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:31,184]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 42 (treeAggregate at GradientDescent.scala:189) finished in 0.857 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:31,185]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 41.0 (TID 42, localhost, PROCESS_LOCAL, 1165 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:31,185]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 36 finished: treeAggregate at GradientDescent.scala:189, took 0.877335 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:31,185]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 41.0 (TID 42) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:31,186]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3237587, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:31,187]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_68 stored as values in memory (estimated size 88.0 B, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:31,191]  INFO {org.apache.spark.storage.ShuffleBlockFetcherIterator} -  Getting 1 non-empty blocks out of 1 blocks {org.apache.spark.storage.ShuffleBlockFetcherIterator}
[2016-04-29 15:19:31,192]  INFO {org.apache.spark.storage.ShuffleBlockFetcherIterator} -  Started 0 remote fetches in 4 ms {org.apache.spark.storage.ShuffleBlockFetcherIterator}
[2016-04-29 15:19:31,192]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3237675, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:31,193]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_68_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:31,195]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_68_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:31,195]  INFO {org.apache.spark.SparkContext} -  Created broadcast 68 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:31,215]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:31,216]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 37 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:31,217]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 43(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:31,217]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:31,218]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 41.0 (TID 42). 1016 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:31,224]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 41.0 (TID 42) in 40 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:31,224]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 41.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:31,227]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:31,227]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 43 (MapPartitionsRDD[86] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:31,229]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3237758, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:31,229]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_69 stored as values in memory (estimated size 8.5 KB, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:31,236]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4425) called with curMem=3246510, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:31,236]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_69_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:31,239]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_69_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:31,239]  INFO {org.apache.spark.SparkContext} -  Created broadcast 69 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:31,240]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 43 (MapPartitionsRDD[86] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:31,240]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 43.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:31,241]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 41 (collectAsMap at KMeans.scala:251) finished in 0.057 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:31,242]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 43.0 (TID 43, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:31,242]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 35 finished: collectAsMap at KMeans.scala:251, took 0.998667 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:31,243]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 43.0 (TID 43) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:31,244]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(296) called with curMem=3250935, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:31,244]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_70 stored as values in memory (estimated size 296.0 B, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:31,248]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:31,265]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 43.0 (TID 43). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:31,269]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(183) called with curMem=3251231, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:31,269]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_70_piece0 stored as bytes in memory (estimated size 183.0 B, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:31,272]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 43 (treeAggregate at GradientDescent.scala:189) finished in 0.031 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:31,273]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 37 finished: treeAggregate at GradientDescent.scala:189, took 0.057906 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:31,274]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3251414, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:31,275]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_71 stored as values in memory (estimated size 88.0 B, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:31,272]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 43.0 (TID 43) in 31 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:31,276]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_70_piece0 in memory on localhost:56403 (size: 183.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:31,278]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 43.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:31,280]  INFO {org.apache.spark.SparkContext} -  Created broadcast 70 from broadcast at KMeans.scala:225 {org.apache.spark.SparkContext}
[2016-04-29 15:19:31,283]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3251502, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:31,283]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_71_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:31,286]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_71_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:31,288]  INFO {org.apache.spark.SparkContext} -  Created broadcast 71 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:31,314]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:31,316]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 38 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:31,316]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 44(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:31,316]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:31,319]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:31,322]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 44 (MapPartitionsRDD[89] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:31,322]  INFO {org.apache.spark.SparkContext} -  Starting job: collectAsMap at KMeans.scala:251 {org.apache.spark.SparkContext}
[2016-04-29 15:19:31,325]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3251585, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:31,325]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_72 stored as values in memory (estimated size 8.5 KB, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:31,334]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4429) called with curMem=3260337, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:31,335]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_72_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:31,337]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_72_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:31,338]  INFO {org.apache.spark.SparkContext} -  Created broadcast 72 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:31,339]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 44 (MapPartitionsRDD[89] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:31,339]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 44.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:31,340]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 44.0 (TID 44, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:31,341]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Registering RDD 88 (mapPartitions at KMeans.scala:228) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:31,341]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 44.0 (TID 44) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:31,341]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 39 (collectAsMap at KMeans.scala:251) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:31,342]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 46(collectAsMap at KMeans.scala:251) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:31,342]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List(ShuffleMapStage 45) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:31,345]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:31,346]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List(ShuffleMapStage 45) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:31,352]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 44.0 (TID 44). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:31,376]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 44.0 (TID 44) in 36 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:31,377]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 44.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:31,381]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ShuffleMapStage 45 (MapPartitionsRDD[88] at mapPartitions at KMeans.scala:228), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:31,382]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8264) called with curMem=3251589, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:31,383]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_73 stored as values in memory (estimated size 8.1 KB, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:31,383]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_69_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:31,389]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_68_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:31,394]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_67_piece0 on localhost:56403 in memory (size: 1568.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:31,396]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4419) called with curMem=3255362, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:31,398]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_73_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:31,399]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_66_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:31,404]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_73_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:31,405]  INFO {org.apache.spark.SparkContext} -  Created broadcast 73 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:31,406]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ShuffleMapStage 45 (MapPartitionsRDD[88] at mapPartitions at KMeans.scala:228) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:31,406]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 45.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:31,407]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_65_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:31,409]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 44 (treeAggregate at GradientDescent.scala:189) finished in 0.069 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:31,408]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 45.0 (TID 45, localhost, PROCESS_LOCAL, 1942 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:31,411]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 45.0 (TID 45) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:31,419]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_64_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:31,422]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 38 finished: treeAggregate at GradientDescent.scala:189, took 0.107912 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:31,424]  INFO {org.apache.spark.rdd.HadoopRDD} -  Input split: file:/home/ml/wso2ml-1.1.0/datasets/banking.-1234.1461942923269:0+4882918 {org.apache.spark.rdd.HadoopRDD}
[2016-04-29 15:19:31,426]  INFO {org.apache.spark.ContextCleaner} -  Cleaned shuffle 5 {org.apache.spark.ContextCleaner}
[2016-04-29 15:19:31,424]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3233747, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:31,427]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_74 stored as values in memory (estimated size 88.0 B, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:31,435]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_63_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:31,446]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_62_piece0 on localhost:56403 in memory (size: 183.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:31,447]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3220171, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:31,448]  INFO {org.apache.spark.ContextCleaner} -  Cleaned accumulator 5 {org.apache.spark.ContextCleaner}
[2016-04-29 15:19:31,449]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_74_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:31,452]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_16_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:31,460]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_74_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:31,460]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_61_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:31,462]  INFO {org.apache.spark.SparkContext} -  Created broadcast 74 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:31,470]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_60_piece0 on localhost:56403 in memory (size: 1570.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:31,475]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_59_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:31,483]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_58_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:31,491]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_57_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:31,493]  INFO {org.apache.spark.ContextCleaner} -  Cleaned shuffle 4 {org.apache.spark.ContextCleaner}
[2016-04-29 15:19:31,499]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_56_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:31,510]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_55_piece0 on localhost:56403 in memory (size: 183.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:31,520]  INFO {org.apache.spark.ContextCleaner} -  Cleaned accumulator 4 {org.apache.spark.ContextCleaner}
[2016-04-29 15:19:31,523]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:31,525]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_54_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:31,530]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_53_piece0 on localhost:56403 in memory (size: 1570.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:31,536]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 40 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:31,536]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 47(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:31,536]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:31,537]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_52_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:31,542]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:31,543]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 47 (MapPartitionsRDD[92] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:31,544]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3150116, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:31,547]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_51_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:31,548]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_75 stored as values in memory (estimated size 8.5 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:31,553]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4428) called with curMem=3154449, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:31,559]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_75_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:31,559]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_50_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:31,562]  INFO {org.apache.spark.ContextCleaner} -  Cleaned shuffle 3 {org.apache.spark.ContextCleaner}
[2016-04-29 15:19:31,564]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_75_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:31,567]  INFO {org.apache.spark.SparkContext} -  Created broadcast 75 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:31,569]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 47 (MapPartitionsRDD[92] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:31,570]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_48_piece0 on localhost:56403 in memory (size: 183.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:31,569]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 47.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:31,578]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_49_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:31,582]  INFO {org.apache.spark.ContextCleaner} -  Cleaned accumulator 3 {org.apache.spark.ContextCleaner}
[2016-04-29 15:19:31,588]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_47_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:32,379]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 45.0 (TID 45). 1991 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:32,380]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 47.0 (TID 46, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:32,381]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 47.0 (TID 46) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:32,392]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:32,394]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ShuffleMapStage 45 (mapPartitions at KMeans.scala:228) finished in 0.986 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:32,395]  INFO {org.apache.spark.scheduler.DAGScheduler} -  looking for newly runnable stages {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:32,395]  INFO {org.apache.spark.scheduler.DAGScheduler} -  running: Set(ResultStage 47) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:32,395]  INFO {org.apache.spark.scheduler.DAGScheduler} -  waiting: Set(ResultStage 46) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:32,395]  INFO {org.apache.spark.scheduler.DAGScheduler} -  failed: Set() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:32,396]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 45.0 (TID 45) in 985 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:32,397]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents for ResultStage 46: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:32,397]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 46 (ShuffledRDD[90] at reduceByKey at KMeans.scala:251), which is now runnable {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:32,398]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(2752) called with curMem=3144877, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:32,399]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_76 stored as values in memory (estimated size 2.7 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:32,397]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 45.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:32,410]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(1570) called with curMem=3147629, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:32,411]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_76_piece0 stored as bytes in memory (estimated size 1570.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:32,413]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_76_piece0 in memory on localhost:56403 (size: 1570.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:32,414]  INFO {org.apache.spark.SparkContext} -  Created broadcast 76 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:32,415]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 46 (ShuffledRDD[90] at reduceByKey at KMeans.scala:251) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:32,416]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 46.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:32,420]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 47.0 (TID 46). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:32,421]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 46.0 (TID 47, localhost, PROCESS_LOCAL, 1165 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:32,422]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 46.0 (TID 47) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:32,429]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 47.0 (TID 46) in 48 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:32,431]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 47.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:32,432]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 47 (treeAggregate at GradientDescent.scala:189) finished in 0.852 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:32,432]  INFO {org.apache.spark.storage.ShuffleBlockFetcherIterator} -  Getting 1 non-empty blocks out of 1 blocks {org.apache.spark.storage.ShuffleBlockFetcherIterator}
[2016-04-29 15:19:32,433]  INFO {org.apache.spark.storage.ShuffleBlockFetcherIterator} -  Started 0 remote fetches in 8 ms {org.apache.spark.storage.ShuffleBlockFetcherIterator}
[2016-04-29 15:19:32,434]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 40 finished: treeAggregate at GradientDescent.scala:189, took 0.907760 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:32,435]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3149199, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:32,436]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_77 stored as values in memory (estimated size 88.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:32,441]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3149287, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:32,443]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_77_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:32,446]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_77_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:32,447]  INFO {org.apache.spark.SparkContext} -  Created broadcast 77 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:32,462]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 46.0 (TID 47). 1016 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:32,466]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:32,467]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 41 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:32,467]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 48(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:32,467]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:32,469]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 46.0 (TID 47) in 48 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:32,469]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 46.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:32,470]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:32,470]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 48 (MapPartitionsRDD[94] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:32,472]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3149370, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:32,472]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_78 stored as values in memory (estimated size 8.5 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:32,479]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4433) called with curMem=3158122, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:32,480]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_78_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:32,482]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_78_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:32,483]  INFO {org.apache.spark.SparkContext} -  Created broadcast 78 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:32,483]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 48 (MapPartitionsRDD[94] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:32,484]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 48.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:32,485]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 46 (collectAsMap at KMeans.scala:251) finished in 0.067 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:32,485]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 48.0 (TID 48, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:32,485]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 48.0 (TID 48) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:32,485]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 39 finished: collectAsMap at KMeans.scala:251, took 1.163110 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:32,486]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(296) called with curMem=3162555, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:32,487]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_79 stored as values in memory (estimated size 296.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:32,489]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:32,498]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(183) called with curMem=3162851, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:32,498]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_79_piece0 stored as bytes in memory (estimated size 183.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:32,501]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_79_piece0 in memory on localhost:56403 (size: 183.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:32,502]  INFO {org.apache.spark.SparkContext} -  Created broadcast 79 from broadcast at KMeans.scala:225 {org.apache.spark.SparkContext}
[2016-04-29 15:19:32,506]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 48.0 (TID 48). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:32,520]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 48 (treeAggregate at GradientDescent.scala:189) finished in 0.036 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:32,521]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 41 finished: treeAggregate at GradientDescent.scala:189, took 0.054425 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:32,522]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3163034, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:32,523]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 48.0 (TID 48) in 32 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:32,523]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_80 stored as values in memory (estimated size 88.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:32,525]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 48.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:32,535]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3163122, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:32,536]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_80_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:32,539]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_80_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:32,540]  INFO {org.apache.spark.SparkContext} -  Created broadcast 80 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:32,555]  INFO {org.apache.spark.SparkContext} -  Starting job: collectAsMap at KMeans.scala:251 {org.apache.spark.SparkContext}
[2016-04-29 15:19:32,557]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Registering RDD 95 (mapPartitions at KMeans.scala:228) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:32,557]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 42 (collectAsMap at KMeans.scala:251) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:32,558]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 50(collectAsMap at KMeans.scala:251) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:32,558]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List(ShuffleMapStage 49) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:32,559]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List(ShuffleMapStage 49) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:32,569]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ShuffleMapStage 49 (MapPartitionsRDD[95] at mapPartitions at KMeans.scala:228), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:32,571]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8264) called with curMem=3163205, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:32,572]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:32,572]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_81 stored as values in memory (estimated size 8.1 KB, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:32,578]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4419) called with curMem=3171469, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:32,578]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_81_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:32,580]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_81_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:32,580]  INFO {org.apache.spark.SparkContext} -  Created broadcast 81 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:32,581]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ShuffleMapStage 49 (MapPartitionsRDD[95] at mapPartitions at KMeans.scala:228) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:32,581]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 49.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:32,582]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 49.0 (TID 49, localhost, PROCESS_LOCAL, 1942 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:32,583]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 49.0 (TID 49) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:32,583]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 43 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:32,583]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 51(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:32,583]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:32,585]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:32,585]  INFO {org.apache.spark.rdd.HadoopRDD} -  Input split: file:/home/ml/wso2ml-1.1.0/datasets/banking.-1234.1461942923269:0+4882918 {org.apache.spark.rdd.HadoopRDD}
[2016-04-29 15:19:32,587]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 51 (MapPartitionsRDD[98] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:32,589]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3175888, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:32,590]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_82 stored as values in memory (estimated size 8.5 KB, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:32,596]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_16_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:32,597]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4426) called with curMem=3184640, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:32,598]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_82_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:32,599]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_82_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:32,600]  INFO {org.apache.spark.SparkContext} -  Created broadcast 82 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:32,600]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 51 (MapPartitionsRDD[98] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:32,600]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 51.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:33,290]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 49.0 (TID 49). 1991 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:33,292]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 51.0 (TID 50, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:33,292]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 51.0 (TID 50) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:33,296]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ShuffleMapStage 49 (mapPartitions at KMeans.scala:228) finished in 0.713 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:33,296]  INFO {org.apache.spark.scheduler.DAGScheduler} -  looking for newly runnable stages {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:33,297]  INFO {org.apache.spark.scheduler.DAGScheduler} -  running: Set(ResultStage 51) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:33,297]  INFO {org.apache.spark.scheduler.DAGScheduler} -  waiting: Set(ResultStage 50) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:33,297]  INFO {org.apache.spark.scheduler.DAGScheduler} -  failed: Set() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:33,297]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:33,297]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 49.0 (TID 49) in 713 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:33,299]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents for ResultStage 50: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:33,299]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 50 (ShuffledRDD[96] at reduceByKey at KMeans.scala:251), which is now runnable {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:33,300]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(2752) called with curMem=3189066, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:33,300]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_83 stored as values in memory (estimated size 2.7 KB, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:33,299]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 49.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:33,305]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(1570) called with curMem=3191818, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:33,305]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_83_piece0 stored as bytes in memory (estimated size 1570.0 B, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:33,307]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_83_piece0 in memory on localhost:56403 (size: 1570.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:33,308]  INFO {org.apache.spark.SparkContext} -  Created broadcast 83 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:33,308]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 50 (ShuffledRDD[96] at reduceByKey at KMeans.scala:251) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:33,309]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 50.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:33,311]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 51.0 (TID 50). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:33,312]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 50.0 (TID 51, localhost, PROCESS_LOCAL, 1165 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:33,313]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 50.0 (TID 51) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:33,317]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 51.0 (TID 50) in 26 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:33,317]  INFO {org.apache.spark.storage.ShuffleBlockFetcherIterator} -  Getting 1 non-empty blocks out of 1 blocks {org.apache.spark.storage.ShuffleBlockFetcherIterator}
[2016-04-29 15:19:33,318]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 51 (treeAggregate at GradientDescent.scala:189) finished in 0.715 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:33,318]  INFO {org.apache.spark.storage.ShuffleBlockFetcherIterator} -  Started 0 remote fetches in 4 ms {org.apache.spark.storage.ShuffleBlockFetcherIterator}
[2016-04-29 15:19:33,318]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 51.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:33,321]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 43 finished: treeAggregate at GradientDescent.scala:189, took 0.749347 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:33,323]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3193388, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:33,323]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_84 stored as values in memory (estimated size 88.0 B, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:33,328]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3193476, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:33,328]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_84_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:33,330]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_84_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:33,331]  INFO {org.apache.spark.SparkContext} -  Created broadcast 84 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:33,332]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 50.0 (TID 51). 1016 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:33,337]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 50 (collectAsMap at KMeans.scala:251) finished in 0.028 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:33,338]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 42 finished: collectAsMap at KMeans.scala:251, took 0.782184 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:33,339]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(296) called with curMem=3193559, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:33,339]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_85 stored as values in memory (estimated size 296.0 B, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:33,340]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 50.0 (TID 51) in 25 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:33,347]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 50.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:33,353]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:33,354]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 44 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:33,347]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(183) called with curMem=3193855, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:33,355]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_85_piece0 stored as bytes in memory (estimated size 183.0 B, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:33,354]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 52(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:33,355]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:33,360]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_85_piece0 in memory on localhost:56403 (size: 183.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:33,362]  INFO {org.apache.spark.SparkContext} -  Created broadcast 85 from broadcast at KMeans.scala:225 {org.apache.spark.SparkContext}
[2016-04-29 15:19:33,361]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:33,367]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 52 (MapPartitionsRDD[100] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:33,368]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3194038, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:33,369]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_86 stored as values in memory (estimated size 8.5 KB, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:33,377]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4433) called with curMem=3202790, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:33,377]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_86_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:33,379]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_86_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:33,379]  INFO {org.apache.spark.SparkContext} -  Created broadcast 86 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:33,380]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 52 (MapPartitionsRDD[100] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:33,380]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 52.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:33,385]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 52.0 (TID 52, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:33,386]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 52.0 (TID 52) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:33,390]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:33,398]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 52.0 (TID 52). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:33,403]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 52.0 (TID 52) in 17 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:33,403]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 52 (treeAggregate at GradientDescent.scala:189) finished in 0.017 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:33,404]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 44 finished: treeAggregate at GradientDescent.scala:189, took 0.051100 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:33,405]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3207223, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:33,406]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_87 stored as values in memory (estimated size 88.0 B, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:33,403]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 52.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:33,411]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3207311, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:33,411]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_87_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:33,412]  INFO {org.apache.spark.SparkContext} -  Starting job: collectAsMap at KMeans.scala:251 {org.apache.spark.SparkContext}
[2016-04-29 15:19:33,413]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Registering RDD 101 (mapPartitions at KMeans.scala:228) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:33,414]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 45 (collectAsMap at KMeans.scala:251) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:33,414]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 54(collectAsMap at KMeans.scala:251) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:33,414]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List(ShuffleMapStage 53) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:33,415]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_87_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:33,416]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List(ShuffleMapStage 53) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:33,423]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ShuffleMapStage 53 (MapPartitionsRDD[101] at mapPartitions at KMeans.scala:228), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:33,424]  INFO {org.apache.spark.SparkContext} -  Created broadcast 87 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:33,426]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8264) called with curMem=3207394, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:33,427]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_88 stored as values in memory (estimated size 8.1 KB, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:33,433]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4417) called with curMem=3215658, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:33,434]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_88_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:33,437]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_88_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:33,439]  INFO {org.apache.spark.SparkContext} -  Created broadcast 88 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:33,439]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ShuffleMapStage 53 (MapPartitionsRDD[101] at mapPartitions at KMeans.scala:228) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:33,440]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 53.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:33,444]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 53.0 (TID 53, localhost, PROCESS_LOCAL, 1942 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:33,444]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 53.0 (TID 53) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:33,447]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:33,447]  INFO {org.apache.spark.rdd.HadoopRDD} -  Input split: file:/home/ml/wso2ml-1.1.0/datasets/banking.-1234.1461942923269:0+4882918 {org.apache.spark.rdd.HadoopRDD}
[2016-04-29 15:19:33,448]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 46 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:33,448]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 55(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:33,448]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:33,450]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:33,452]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 55 (MapPartitionsRDD[104] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:33,453]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3220075, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:33,454]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_89 stored as values in memory (estimated size 8.5 KB, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:33,461]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4429) called with curMem=3228827, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:33,461]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_89_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:33,464]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_89_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:33,464]  INFO {org.apache.spark.SparkContext} -  Created broadcast 89 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:33,465]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_16_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:33,473]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 55 (MapPartitionsRDD[104] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:33,475]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 55.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:34,213]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 53.0 (TID 53). 1991 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:34,216]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 55.0 (TID 54, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:34,219]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 53.0 (TID 53) in 776 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:34,219]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 53.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:34,219]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ShuffleMapStage 53 (mapPartitions at KMeans.scala:228) finished in 0.775 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:34,220]  INFO {org.apache.spark.scheduler.DAGScheduler} -  looking for newly runnable stages {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:34,220]  INFO {org.apache.spark.scheduler.DAGScheduler} -  running: Set(ResultStage 55) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:34,220]  INFO {org.apache.spark.scheduler.DAGScheduler} -  waiting: Set(ResultStage 54) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:34,220]  INFO {org.apache.spark.scheduler.DAGScheduler} -  failed: Set() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:34,221]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents for ResultStage 54: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:34,221]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 54 (ShuffledRDD[102] at reduceByKey at KMeans.scala:251), which is now runnable {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:34,222]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(2752) called with curMem=3233256, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:34,222]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_90 stored as values in memory (estimated size 2.7 KB, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:34,227]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(1570) called with curMem=3236008, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:34,227]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_90_piece0 stored as bytes in memory (estimated size 1570.0 B, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:34,219]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 55.0 (TID 54) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:34,233]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_90_piece0 in memory on localhost:56403 (size: 1570.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:34,238]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:34,238]  INFO {org.apache.spark.SparkContext} -  Created broadcast 90 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:34,244]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 54 (ShuffledRDD[102] at reduceByKey at KMeans.scala:251) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:34,244]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 54.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:34,247]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 55.0 (TID 54). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:34,248]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 54.0 (TID 55, localhost, PROCESS_LOCAL, 1165 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:34,249]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 54.0 (TID 55) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:34,252]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 55.0 (TID 54) in 37 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:34,258]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 55.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:34,253]  INFO {org.apache.spark.storage.ShuffleBlockFetcherIterator} -  Getting 1 non-empty blocks out of 1 blocks {org.apache.spark.storage.ShuffleBlockFetcherIterator}
[2016-04-29 15:19:34,252]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 55 (treeAggregate at GradientDescent.scala:189) finished in 0.776 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:34,261]  INFO {org.apache.spark.storage.ShuffleBlockFetcherIterator} -  Started 0 remote fetches in 11 ms {org.apache.spark.storage.ShuffleBlockFetcherIterator}
[2016-04-29 15:19:34,261]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 46 finished: treeAggregate at GradientDescent.scala:189, took 0.814312 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:34,262]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3237578, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:34,263]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_91 stored as values in memory (estimated size 88.0 B, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:34,269]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3237666, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:34,271]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_91_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:34,277]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_91_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:34,278]  INFO {org.apache.spark.SparkContext} -  Created broadcast 91 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:34,281]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 54.0 (TID 55). 1016 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:34,289]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 54 (collectAsMap at KMeans.scala:251) finished in 0.044 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:34,290]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 45 finished: collectAsMap at KMeans.scala:251, took 0.877555 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:34,291]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(296) called with curMem=3237749, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:34,292]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_92 stored as values in memory (estimated size 296.0 B, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:34,290]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 54.0 (TID 55) in 41 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:34,293]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 54.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:34,299]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(183) called with curMem=3238045, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:34,307]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_92_piece0 stored as bytes in memory (estimated size 183.0 B, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:34,312]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_92_piece0 in memory on localhost:56403 (size: 183.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:34,313]  INFO {org.apache.spark.SparkContext} -  Created broadcast 92 from broadcast at KMeans.scala:225 {org.apache.spark.SparkContext}
[2016-04-29 15:19:34,316]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:34,318]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 47 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:34,318]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 56(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:34,318]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:34,321]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:34,322]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 56 (MapPartitionsRDD[106] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:34,323]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3238228, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:34,324]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_93 stored as values in memory (estimated size 8.5 KB, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:34,344]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4428) called with curMem=3246980, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:34,345]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_93_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:34,350]  INFO {org.apache.spark.SparkContext} -  Starting job: collectAsMap at KMeans.scala:251 {org.apache.spark.SparkContext}
[2016-04-29 15:19:34,356]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_93_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:34,357]  INFO {org.apache.spark.SparkContext} -  Created broadcast 93 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:34,358]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 56 (MapPartitionsRDD[106] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:34,358]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 56.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:34,360]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 56.0 (TID 56, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:34,360]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 56.0 (TID 56) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:34,361]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Registering RDD 107 (mapPartitions at KMeans.scala:228) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:34,362]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 48 (collectAsMap at KMeans.scala:251) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:34,362]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 58(collectAsMap at KMeans.scala:251) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:34,363]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List(ShuffleMapStage 57) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:34,364]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List(ShuffleMapStage 57) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:34,368]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:34,381]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ShuffleMapStage 57 (MapPartitionsRDD[107] at mapPartitions at KMeans.scala:228), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:34,382]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8264) called with curMem=3251408, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:34,385]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 56.0 (TID 56). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:34,389]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_94 stored as values in memory (estimated size 8.1 KB, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:34,393]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 56.0 (TID 56) in 34 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:34,393]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 56.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:34,399]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4419) called with curMem=3259672, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:34,400]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_94_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:34,402]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_94_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:34,402]  INFO {org.apache.spark.SparkContext} -  Created broadcast 94 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:34,403]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ShuffleMapStage 57 (MapPartitionsRDD[107] at mapPartitions at KMeans.scala:228) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:34,403]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 57.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:34,404]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 57.0 (TID 57, localhost, PROCESS_LOCAL, 1942 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:34,405]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 57.0 (TID 57) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:34,408]  INFO {org.apache.spark.rdd.HadoopRDD} -  Input split: file:/home/ml/wso2ml-1.1.0/datasets/banking.-1234.1461942923269:0+4882918 {org.apache.spark.rdd.HadoopRDD}
[2016-04-29 15:19:34,409]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 56 (treeAggregate at GradientDescent.scala:189) finished in 0.049 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:34,410]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 47 finished: treeAggregate at GradientDescent.scala:189, took 0.093769 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:34,412]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3264091, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:34,412]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_95 stored as values in memory (estimated size 88.0 B, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:34,417]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3264179, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:34,417]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_95_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:34,419]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_95_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:34,421]  INFO {org.apache.spark.SparkContext} -  Created broadcast 95 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:34,428]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_16_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:34,434]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:34,435]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 49 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:34,435]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 59(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:34,436]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:34,438]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:34,439]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 59 (MapPartitionsRDD[110] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:34,441]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3264262, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:34,441]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_96 stored as values in memory (estimated size 8.5 KB, free 979.9 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:34,446]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4431) called with curMem=3273014, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:34,446]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_96_piece0 stored as bytes in memory (estimated size 4.3 KB, free 979.9 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:34,448]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_96_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:34,448]  INFO {org.apache.spark.SparkContext} -  Created broadcast 96 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:34,449]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 59 (MapPartitionsRDD[110] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:34,449]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 59.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:34,517]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_93_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:34,522]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_91_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:34,528]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_90_piece0 on localhost:56403 in memory (size: 1570.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:34,532]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_88_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:34,538]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_87_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:34,544]  INFO {org.apache.spark.ContextCleaner} -  Cleaned shuffle 8 {org.apache.spark.ContextCleaner}
[2016-04-29 15:19:34,548]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_86_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:34,556]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_85_piece0 on localhost:56403 in memory (size: 183.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:34,557]  INFO {org.apache.spark.ContextCleaner} -  Cleaned accumulator 8 {org.apache.spark.ContextCleaner}
[2016-04-29 15:19:34,561]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_84_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:34,565]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_83_piece0 on localhost:56403 in memory (size: 1570.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:34,571]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_82_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:34,575]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_81_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:34,577]  INFO {org.apache.spark.ContextCleaner} -  Cleaned shuffle 7 {org.apache.spark.ContextCleaner}
[2016-04-29 15:19:34,582]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_80_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:34,587]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_79_piece0 on localhost:56403 in memory (size: 183.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:34,588]  INFO {org.apache.spark.ContextCleaner} -  Cleaned accumulator 7 {org.apache.spark.ContextCleaner}
[2016-04-29 15:19:34,592]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_78_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:34,596]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_77_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:34,601]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_76_piece0 on localhost:56403 in memory (size: 1570.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:34,606]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_75_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:34,610]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_74_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:34,616]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_73_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:35,136]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 57.0 (TID 57). 1991 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:35,137]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 59.0 (TID 58, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:35,138]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 59.0 (TID 58) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:35,141]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:35,142]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ShuffleMapStage 57 (mapPartitions at KMeans.scala:228) finished in 0.737 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:35,143]  INFO {org.apache.spark.scheduler.DAGScheduler} -  looking for newly runnable stages {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:35,143]  INFO {org.apache.spark.scheduler.DAGScheduler} -  running: Set(ResultStage 59) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:35,143]  INFO {org.apache.spark.scheduler.DAGScheduler} -  waiting: Set(ResultStage 58) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:35,143]  INFO {org.apache.spark.scheduler.DAGScheduler} -  failed: Set() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:35,144]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents for ResultStage 58: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:35,145]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 58 (ShuffledRDD[108] at reduceByKey at KMeans.scala:251), which is now runnable {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:35,146]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(2752) called with curMem=3158540, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:35,147]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_97 stored as values in memory (estimated size 2.7 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:35,141]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 57.0 (TID 57) in 737 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:35,148]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 57.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:35,149]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 59.0 (TID 58). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:35,153]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 59.0 (TID 58) in 16 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:35,153]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 59.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:35,156]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(1570) called with curMem=3161292, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:35,157]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_97_piece0 stored as bytes in memory (estimated size 1570.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:35,158]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_97_piece0 in memory on localhost:56403 (size: 1570.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:35,158]  INFO {org.apache.spark.SparkContext} -  Created broadcast 97 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:35,159]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 58 (ShuffledRDD[108] at reduceByKey at KMeans.scala:251) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:35,159]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 58.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:35,160]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 59 (treeAggregate at GradientDescent.scala:189) finished in 0.710 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:35,160]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 58.0 (TID 59, localhost, PROCESS_LOCAL, 1165 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:35,160]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 58.0 (TID 59) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:35,161]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 49 finished: treeAggregate at GradientDescent.scala:189, took 0.726613 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:35,162]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3162862, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:35,162]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_98 stored as values in memory (estimated size 88.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:35,165]  INFO {org.apache.spark.storage.ShuffleBlockFetcherIterator} -  Getting 1 non-empty blocks out of 1 blocks {org.apache.spark.storage.ShuffleBlockFetcherIterator}
[2016-04-29 15:19:35,166]  INFO {org.apache.spark.storage.ShuffleBlockFetcherIterator} -  Started 0 remote fetches in 4 ms {org.apache.spark.storage.ShuffleBlockFetcherIterator}
[2016-04-29 15:19:35,167]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3162950, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:35,167]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_98_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:35,169]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_98_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:35,173]  INFO {org.apache.spark.SparkContext} -  Created broadcast 98 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:35,182]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 58.0 (TID 59). 1016 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:35,186]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 58.0 (TID 59) in 26 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:35,187]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 58 (collectAsMap at KMeans.scala:251) finished in 0.027 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:35,188]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 58.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:35,189]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 48 finished: collectAsMap at KMeans.scala:251, took 0.834242 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:35,190]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(296) called with curMem=3163033, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:35,190]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_99 stored as values in memory (estimated size 296.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:35,190]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:35,192]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 50 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:35,192]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 60(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:35,192]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:35,196]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(183) called with curMem=3163329, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:35,196]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_99_piece0 stored as bytes in memory (estimated size 183.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:35,197]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:35,197]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 60 (MapPartitionsRDD[112] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:35,199]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3163512, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:35,199]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_100 stored as values in memory (estimated size 8.5 KB, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:35,200]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_99_piece0 in memory on localhost:56403 (size: 183.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:35,201]  INFO {org.apache.spark.SparkContext} -  Created broadcast 99 from broadcast at KMeans.scala:225 {org.apache.spark.SparkContext}
[2016-04-29 15:19:35,207]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4432) called with curMem=3172264, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:35,207]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_100_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:35,209]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_100_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:35,211]  INFO {org.apache.spark.SparkContext} -  Created broadcast 100 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:35,211]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 60 (MapPartitionsRDD[112] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:35,212]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 60.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:35,213]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 60.0 (TID 60, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:35,214]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 60.0 (TID 60) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:35,216]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:35,225]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 60.0 (TID 60). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:35,229]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 60.0 (TID 60) in 16 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:35,229]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 60 (treeAggregate at GradientDescent.scala:189) finished in 0.016 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:35,229]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 60.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:35,230]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 50 finished: treeAggregate at GradientDescent.scala:189, took 0.039736 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:35,231]  INFO {org.apache.spark.SparkContext} -  Starting job: collectAsMap at KMeans.scala:251 {org.apache.spark.SparkContext}
[2016-04-29 15:19:35,231]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3176696, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:35,234]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_101 stored as values in memory (estimated size 88.0 B, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:35,235]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Registering RDD 113 (mapPartitions at KMeans.scala:228) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:35,235]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 51 (collectAsMap at KMeans.scala:251) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:35,235]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 62(collectAsMap at KMeans.scala:251) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:35,236]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List(ShuffleMapStage 61) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:35,236]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List(ShuffleMapStage 61) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:35,239]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3176784, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:35,239]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_101_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:35,246]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_101_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:35,247]  INFO {org.apache.spark.SparkContext} -  Created broadcast 101 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:35,250]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ShuffleMapStage 61 (MapPartitionsRDD[113] at mapPartitions at KMeans.scala:228), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:35,251]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8264) called with curMem=3176867, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:35,252]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_102 stored as values in memory (estimated size 8.1 KB, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:35,257]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4419) called with curMem=3185131, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:35,257]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_102_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:35,262]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_102_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:35,263]  INFO {org.apache.spark.SparkContext} -  Created broadcast 102 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:35,263]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:35,263]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ShuffleMapStage 61 (MapPartitionsRDD[113] at mapPartitions at KMeans.scala:228) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:35,264]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 61.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:35,265]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 61.0 (TID 61, localhost, PROCESS_LOCAL, 1942 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:35,265]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 61.0 (TID 61) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:35,268]  INFO {org.apache.spark.rdd.HadoopRDD} -  Input split: file:/home/ml/wso2ml-1.1.0/datasets/banking.-1234.1461942923269:0+4882918 {org.apache.spark.rdd.HadoopRDD}
[2016-04-29 15:19:35,270]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 52 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:35,270]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 63(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:35,270]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:35,273]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:35,273]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 63 (MapPartitionsRDD[116] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:35,276]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3189550, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:35,277]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_103 stored as values in memory (estimated size 8.5 KB, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:35,281]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4426) called with curMem=3198302, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:35,282]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_103_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:35,284]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_103_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:35,286]  INFO {org.apache.spark.SparkContext} -  Created broadcast 103 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:35,286]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 63 (MapPartitionsRDD[116] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:35,287]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 63.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:35,293]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_16_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:35,971]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 61.0 (TID 61). 1991 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:35,973]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 63.0 (TID 62, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:35,974]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 63.0 (TID 62) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:35,976]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 61.0 (TID 61) in 711 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:35,977]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ShuffleMapStage 61 (mapPartitions at KMeans.scala:228) finished in 0.709 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:35,978]  INFO {org.apache.spark.scheduler.DAGScheduler} -  looking for newly runnable stages {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:35,978]  INFO {org.apache.spark.scheduler.DAGScheduler} -  running: Set(ResultStage 63) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:35,978]  INFO {org.apache.spark.scheduler.DAGScheduler} -  waiting: Set(ResultStage 62) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:35,978]  INFO {org.apache.spark.scheduler.DAGScheduler} -  failed: Set() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:35,976]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:35,979]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents for ResultStage 62: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:35,977]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 61.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:35,980]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 62 (ShuffledRDD[114] at reduceByKey at KMeans.scala:251), which is now runnable {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:35,981]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(2752) called with curMem=3202728, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:35,982]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_104 stored as values in memory (estimated size 2.7 KB, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:35,985]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 63.0 (TID 62). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:35,987]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(1570) called with curMem=3205480, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:35,987]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_104_piece0 stored as bytes in memory (estimated size 1570.0 B, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:35,988]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_104_piece0 in memory on localhost:56403 (size: 1570.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:35,989]  INFO {org.apache.spark.SparkContext} -  Created broadcast 104 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:35,989]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 62 (ShuffledRDD[114] at reduceByKey at KMeans.scala:251) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:35,989]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 62.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:35,990]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 62.0 (TID 63, localhost, PROCESS_LOCAL, 1165 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:35,990]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 63.0 (TID 62) in 18 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:35,990]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 63.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:35,991]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 62.0 (TID 63) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:35,991]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 63 (treeAggregate at GradientDescent.scala:189) finished in 0.702 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:35,992]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 52 finished: treeAggregate at GradientDescent.scala:189, took 0.728751 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:35,993]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3207050, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:35,993]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_105 stored as values in memory (estimated size 88.0 B, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:35,995]  INFO {org.apache.spark.storage.ShuffleBlockFetcherIterator} -  Getting 1 non-empty blocks out of 1 blocks {org.apache.spark.storage.ShuffleBlockFetcherIterator}
[2016-04-29 15:19:35,995]  INFO {org.apache.spark.storage.ShuffleBlockFetcherIterator} -  Started 0 remote fetches in 3 ms {org.apache.spark.storage.ShuffleBlockFetcherIterator}
[2016-04-29 15:19:36,001]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3207138, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:36,002]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_105_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:36,005]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_105_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:36,006]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 62.0 (TID 63). 1016 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:36,006]  INFO {org.apache.spark.SparkContext} -  Created broadcast 105 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:36,011]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 62.0 (TID 63) in 21 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:36,011]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 62 (collectAsMap at KMeans.scala:251) finished in 0.021 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:36,011]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 62.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:36,012]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 51 finished: collectAsMap at KMeans.scala:251, took 0.777883 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:36,013]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(296) called with curMem=3207221, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:36,014]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_106 stored as values in memory (estimated size 296.0 B, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:36,018]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:36,018]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(183) called with curMem=3207517, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:36,019]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_106_piece0 stored as bytes in memory (estimated size 183.0 B, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:36,019]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 53 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:36,020]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 64(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:36,020]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:36,021]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_106_piece0 in memory on localhost:56403 (size: 183.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:36,021]  INFO {org.apache.spark.SparkContext} -  Created broadcast 106 from broadcast at KMeans.scala:225 {org.apache.spark.SparkContext}
[2016-04-29 15:19:36,022]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:36,024]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 64 (MapPartitionsRDD[118] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:36,025]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3207700, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:36,025]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_107 stored as values in memory (estimated size 8.5 KB, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:36,029]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4433) called with curMem=3216452, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:36,030]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_107_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:36,032]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_107_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:36,042]  INFO {org.apache.spark.SparkContext} -  Starting job: collectAsMap at KMeans.scala:251 {org.apache.spark.SparkContext}
[2016-04-29 15:19:36,043]  INFO {org.apache.spark.SparkContext} -  Created broadcast 107 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:36,043]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 64 (MapPartitionsRDD[118] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:36,044]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 64.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:36,045]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 64.0 (TID 64, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:36,045]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 64.0 (TID 64) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:36,046]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Registering RDD 119 (mapPartitions at KMeans.scala:228) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:36,046]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 54 (collectAsMap at KMeans.scala:251) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:36,047]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 66(collectAsMap at KMeans.scala:251) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:36,047]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List(ShuffleMapStage 65) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:36,047]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List(ShuffleMapStage 65) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:36,050]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:36,053]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ShuffleMapStage 65 (MapPartitionsRDD[119] at mapPartitions at KMeans.scala:228), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:36,055]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8264) called with curMem=3220885, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:36,055]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_108 stored as values in memory (estimated size 8.1 KB, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:36,059]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4419) called with curMem=3229149, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:36,060]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_108_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:36,061]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_108_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:36,062]  INFO {org.apache.spark.SparkContext} -  Created broadcast 108 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:36,062]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ShuffleMapStage 65 (MapPartitionsRDD[119] at mapPartitions at KMeans.scala:228) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:36,063]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 65.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:36,064]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 64.0 (TID 64). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:36,067]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 65.0 (TID 65, localhost, PROCESS_LOCAL, 1942 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:36,067]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 65.0 (TID 65) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:36,070]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 64.0 (TID 64) in 26 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:36,070]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 64.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:36,071]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 64 (treeAggregate at GradientDescent.scala:189) finished in 0.026 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:36,071]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 53 finished: treeAggregate at GradientDescent.scala:189, took 0.053300 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:36,072]  INFO {org.apache.spark.rdd.HadoopRDD} -  Input split: file:/home/ml/wso2ml-1.1.0/datasets/banking.-1234.1461942923269:0+4882918 {org.apache.spark.rdd.HadoopRDD}
[2016-04-29 15:19:36,072]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3233568, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:36,073]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_109 stored as values in memory (estimated size 88.0 B, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:36,077]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3233656, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:36,077]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_109_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:36,079]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_109_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:36,080]  INFO {org.apache.spark.SparkContext} -  Created broadcast 109 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:36,084]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_16_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:36,094]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:36,095]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 55 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:36,097]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 67(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:36,097]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:36,100]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:36,101]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 67 (MapPartitionsRDD[122] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:36,102]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3233739, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:36,103]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_110 stored as values in memory (estimated size 8.5 KB, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:36,108]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4429) called with curMem=3242491, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:36,109]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_110_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:36,110]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_110_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:36,111]  INFO {org.apache.spark.SparkContext} -  Created broadcast 110 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:36,111]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 67 (MapPartitionsRDD[122] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:36,112]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 67.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:36,770]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 65.0 (TID 65). 1991 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:36,771]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 67.0 (TID 66, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:36,772]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 67.0 (TID 66) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:36,777]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:36,779]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ShuffleMapStage 65 (mapPartitions at KMeans.scala:228) finished in 0.715 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:36,779]  INFO {org.apache.spark.scheduler.DAGScheduler} -  looking for newly runnable stages {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:36,780]  INFO {org.apache.spark.scheduler.DAGScheduler} -  running: Set(ResultStage 67) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:36,780]  INFO {org.apache.spark.scheduler.DAGScheduler} -  waiting: Set(ResultStage 66) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:36,780]  INFO {org.apache.spark.scheduler.DAGScheduler} -  failed: Set() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:36,780]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 65.0 (TID 65) in 709 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:36,780]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 65.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:36,781]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents for ResultStage 66: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:36,781]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 66 (ShuffledRDD[120] at reduceByKey at KMeans.scala:251), which is now runnable {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:36,782]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(2752) called with curMem=3246920, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:36,782]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_111 stored as values in memory (estimated size 2.7 KB, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:36,785]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 67.0 (TID 66). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:36,786]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(1567) called with curMem=3249672, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:36,787]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_111_piece0 stored as bytes in memory (estimated size 1567.0 B, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:36,790]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_111_piece0 in memory on localhost:56403 (size: 1567.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:36,791]  INFO {org.apache.spark.SparkContext} -  Created broadcast 111 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:36,793]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 66 (ShuffledRDD[120] at reduceByKey at KMeans.scala:251) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:36,792]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 67.0 (TID 66) in 21 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:36,793]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 66.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:36,793]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 67.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:36,795]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 67 (treeAggregate at GradientDescent.scala:189) finished in 0.681 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:36,795]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 66.0 (TID 67, localhost, PROCESS_LOCAL, 1165 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:36,795]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 55 finished: treeAggregate at GradientDescent.scala:189, took 0.700421 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:36,796]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 66.0 (TID 67) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:36,797]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3251239, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:36,797]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_112 stored as values in memory (estimated size 88.0 B, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:36,801]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3251327, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:36,801]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_112_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:36,801]  INFO {org.apache.spark.storage.ShuffleBlockFetcherIterator} -  Getting 1 non-empty blocks out of 1 blocks {org.apache.spark.storage.ShuffleBlockFetcherIterator}
[2016-04-29 15:19:36,801]  INFO {org.apache.spark.storage.ShuffleBlockFetcherIterator} -  Started 0 remote fetches in 2 ms {org.apache.spark.storage.ShuffleBlockFetcherIterator}
[2016-04-29 15:19:36,803]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_112_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:36,806]  INFO {org.apache.spark.SparkContext} -  Created broadcast 112 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:36,813]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 66.0 (TID 67). 1016 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:36,818]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 66 (collectAsMap at KMeans.scala:251) finished in 0.024 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:36,819]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:36,819]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 66.0 (TID 67) in 23 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:36,819]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 54 finished: collectAsMap at KMeans.scala:251, took 0.776685 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:36,820]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 56 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:36,820]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 68(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:36,821]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:36,821]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 66.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:36,821]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(296) called with curMem=3251410, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:36,822]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_113 stored as values in memory (estimated size 296.0 B, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:36,826]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(183) called with curMem=3251706, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:36,826]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_113_piece0 stored as bytes in memory (estimated size 183.0 B, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:36,827]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:36,827]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 68 (MapPartitionsRDD[124] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:36,830]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_113_piece0 in memory on localhost:56403 (size: 183.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:36,831]  INFO {org.apache.spark.SparkContext} -  Created broadcast 113 from broadcast at KMeans.scala:225 {org.apache.spark.SparkContext}
[2016-04-29 15:19:36,836]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3251889, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:36,836]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_114 stored as values in memory (estimated size 8.5 KB, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:36,846]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4429) called with curMem=3260641, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:36,847]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_114_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:36,850]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_114_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:36,851]  INFO {org.apache.spark.SparkContext} -  Created broadcast 114 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:36,851]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 68 (MapPartitionsRDD[124] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:36,852]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 68.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:36,853]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 68.0 (TID 68, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:36,853]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 68.0 (TID 68) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:36,856]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:36,861]  INFO {org.apache.spark.SparkContext} -  Starting job: collectAsMap at KMeans.scala:251 {org.apache.spark.SparkContext}
[2016-04-29 15:19:36,862]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Registering RDD 125 (mapPartitions at KMeans.scala:228) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:36,862]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 57 (collectAsMap at KMeans.scala:251) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:36,862]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 70(collectAsMap at KMeans.scala:251) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:36,863]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List(ShuffleMapStage 69) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:36,863]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List(ShuffleMapStage 69) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:36,862]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 68.0 (TID 68). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:36,871]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 68.0 (TID 68) in 18 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:36,871]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 68.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:36,874]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ShuffleMapStage 69 (MapPartitionsRDD[125] at mapPartitions at KMeans.scala:228), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:36,875]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8264) called with curMem=3265070, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:36,876]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_115 stored as values in memory (estimated size 8.1 KB, free 979.9 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:36,879]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4419) called with curMem=3273334, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:36,880]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_115_piece0 stored as bytes in memory (estimated size 4.3 KB, free 979.9 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:36,881]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_115_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:36,881]  INFO {org.apache.spark.SparkContext} -  Created broadcast 115 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:36,882]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ShuffleMapStage 69 (MapPartitionsRDD[125] at mapPartitions at KMeans.scala:228) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:36,882]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 69.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:36,883]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 68 (treeAggregate at GradientDescent.scala:189) finished in 0.030 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:36,883]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 56 finished: treeAggregate at GradientDescent.scala:189, took 0.063964 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:36,883]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 69.0 (TID 69, localhost, PROCESS_LOCAL, 1942 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:36,884]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 69.0 (TID 69) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:36,884]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3277753, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:36,885]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_116 stored as values in memory (estimated size 88.0 B, free 979.9 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:36,887]  INFO {org.apache.spark.rdd.HadoopRDD} -  Input split: file:/home/ml/wso2ml-1.1.0/datasets/banking.-1234.1461942923269:0+4882918 {org.apache.spark.rdd.HadoopRDD}
[2016-04-29 15:19:36,894]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3277841, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:36,894]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_116_piece0 stored as bytes in memory (estimated size 83.0 B, free 979.9 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:36,896]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_116_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:36,897]  INFO {org.apache.spark.SparkContext} -  Created broadcast 116 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:36,897]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_16_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:36,912]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:36,913]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 58 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:36,913]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 71(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:36,913]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:36,916]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:36,917]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 71 (MapPartitionsRDD[128] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:36,918]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3277924, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:36,919]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_117 stored as values in memory (estimated size 8.5 KB, free 979.9 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:36,924]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4427) called with curMem=3286676, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:36,924]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_117_piece0 stored as bytes in memory (estimated size 4.3 KB, free 979.9 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:36,926]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_117_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:36,927]  INFO {org.apache.spark.SparkContext} -  Created broadcast 117 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:36,927]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 71 (MapPartitionsRDD[128] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:36,928]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 71.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:37,155]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_114_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:37,160]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_112_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:37,163]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_111_piece0 on localhost:56403 in memory (size: 1567.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:37,167]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_110_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:37,171]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_109_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:37,175]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_108_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:37,177]  INFO {org.apache.spark.ContextCleaner} -  Cleaned shuffle 11 {org.apache.spark.ContextCleaner}
[2016-04-29 15:19:37,184]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_107_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:37,188]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_106_piece0 on localhost:56403 in memory (size: 183.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:37,189]  INFO {org.apache.spark.ContextCleaner} -  Cleaned accumulator 11 {org.apache.spark.ContextCleaner}
[2016-04-29 15:19:37,192]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_105_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:37,196]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_104_piece0 on localhost:56403 in memory (size: 1570.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:37,200]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_103_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:37,205]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_102_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:37,212]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_101_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:37,213]  INFO {org.apache.spark.ContextCleaner} -  Cleaned shuffle 10 {org.apache.spark.ContextCleaner}
[2016-04-29 15:19:37,220]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_100_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:37,223]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_99_piece0 on localhost:56403 in memory (size: 183.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:37,224]  INFO {org.apache.spark.ContextCleaner} -  Cleaned accumulator 10 {org.apache.spark.ContextCleaner}
[2016-04-29 15:19:37,227]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_98_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:37,232]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_97_piece0 on localhost:56403 in memory (size: 1570.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:37,638]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 69.0 (TID 69). 1991 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:37,639]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 71.0 (TID 70, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:37,642]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 69.0 (TID 69) in 759 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:37,643]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ShuffleMapStage 69 (mapPartitions at KMeans.scala:228) finished in 0.761 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:37,643]  INFO {org.apache.spark.scheduler.DAGScheduler} -  looking for newly runnable stages {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:37,643]  INFO {org.apache.spark.scheduler.DAGScheduler} -  running: Set(ResultStage 71) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:37,643]  INFO {org.apache.spark.scheduler.DAGScheduler} -  waiting: Set(ResultStage 70) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:37,643]  INFO {org.apache.spark.scheduler.DAGScheduler} -  failed: Set() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:37,643]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 71.0 (TID 70) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:37,643]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 69.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:37,644]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents for ResultStage 70: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:37,645]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 70 (ShuffledRDD[126] at reduceByKey at KMeans.scala:251), which is now runnable {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:37,646]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(2752) called with curMem=3185052, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:37,647]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_118 stored as values in memory (estimated size 2.7 KB, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:37,647]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:37,650]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(1570) called with curMem=3187804, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:37,651]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_118_piece0 stored as bytes in memory (estimated size 1570.0 B, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:37,652]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_118_piece0 in memory on localhost:56403 (size: 1570.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:37,652]  INFO {org.apache.spark.SparkContext} -  Created broadcast 118 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:37,653]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 70 (ShuffledRDD[126] at reduceByKey at KMeans.scala:251) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:37,653]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 70.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:37,654]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 71.0 (TID 70). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:37,655]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 70.0 (TID 71, localhost, PROCESS_LOCAL, 1165 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:37,658]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 70.0 (TID 71) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:37,659]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 71.0 (TID 70) in 19 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:37,659]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 71 (treeAggregate at GradientDescent.scala:189) finished in 0.730 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:37,659]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 71.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:37,660]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 58 finished: treeAggregate at GradientDescent.scala:189, took 0.747863 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:37,661]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3189374, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:37,661]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_119 stored as values in memory (estimated size 88.0 B, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:37,663]  INFO {org.apache.spark.storage.ShuffleBlockFetcherIterator} -  Getting 1 non-empty blocks out of 1 blocks {org.apache.spark.storage.ShuffleBlockFetcherIterator}
[2016-04-29 15:19:37,664]  INFO {org.apache.spark.storage.ShuffleBlockFetcherIterator} -  Started 0 remote fetches in 3 ms {org.apache.spark.storage.ShuffleBlockFetcherIterator}
[2016-04-29 15:19:37,666]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3189462, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:37,667]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_119_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:37,669]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_119_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.2 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:37,669]  INFO {org.apache.spark.SparkContext} -  Created broadcast 119 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:37,675]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 70.0 (TID 71). 1016 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:37,679]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 70.0 (TID 71) in 24 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:37,679]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 70 (collectAsMap at KMeans.scala:251) finished in 0.024 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:37,680]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 70.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:37,680]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 57 finished: collectAsMap at KMeans.scala:251, took 0.819077 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:37,682]  INFO {org.apache.spark.mllib.clustering.KMeans} -  Run 0 finished in 12 iterations {org.apache.spark.mllib.clustering.KMeans}
[2016-04-29 15:19:37,682]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:37,683]  INFO {org.apache.spark.mllib.clustering.KMeans} -  Iterations took 11.512 seconds. {org.apache.spark.mllib.clustering.KMeans}
[2016-04-29 15:19:37,684]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 59 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:37,684]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 72(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:37,684]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:37,685]  INFO {org.apache.spark.mllib.clustering.KMeans} -  KMeans converged in 12 iterations. {org.apache.spark.mllib.clustering.KMeans}
[2016-04-29 15:19:37,688]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:37,689]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 72 (MapPartitionsRDD[130] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:37,691]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3189545, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:37,691]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_120 stored as values in memory (estimated size 8.5 KB, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:37,693]  INFO {org.apache.spark.mllib.clustering.KMeans} -  The cost for the best run is 281855.17952096683. {org.apache.spark.mllib.clustering.KMeans}
[2016-04-29 15:19:37,696]  INFO {org.apache.spark.rdd.MapPartitionsRDD} -  Removing RDD 16 from persistence list {org.apache.spark.rdd.MapPartitionsRDD}
[2016-04-29 15:19:37,697]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4431) called with curMem=3198297, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:37,698]  INFO {org.apache.spark.storage.BlockManager} -  Removing RDD 16 {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:37,699]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_120_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:37,702]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_120_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:37,702]  INFO {org.apache.spark.SparkContext} -  Created broadcast 120 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:37,702]  WARN {org.apache.spark.mllib.clustering.KMeans} -  The input data was not directly cached, which may hurt performance if its parent RDDs are also uncached. {org.apache.spark.mllib.clustering.KMeans}
[2016-04-29 15:19:37,703]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 72 (MapPartitionsRDD[130] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:37,703]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 72.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:37,704]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 72.0 (TID 72, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:37,704]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(296) called with curMem=2922440, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:37,705]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 72.0 (TID 72) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:37,706]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_121 stored as values in memory (estimated size 296.0 B, free 980.3 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:37,708]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:37,712]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(230) called with curMem=2922736, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:37,712]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_121_piece0 stored as bytes in memory (estimated size 230.0 B, free 980.3 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:37,716]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 72.0 (TID 72). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:37,716]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_121_piece0 in memory on localhost:56403 (size: 230.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:37,717]  INFO {org.apache.spark.SparkContext} -  Created broadcast 121 from broadcast at KMeansModel.scala:55 {org.apache.spark.SparkContext}
[2016-04-29 15:19:37,721]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 72.0 (TID 72) in 17 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:37,721]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 72 (treeAggregate at GradientDescent.scala:189) finished in 0.016 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:37,721]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 72.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:37,722]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 59 finished: treeAggregate at GradientDescent.scala:189, took 0.038975 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:37,723]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=2922966, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:37,723]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_122 stored as values in memory (estimated size 88.0 B, free 980.3 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:37,727]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=2923054, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:37,728]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_122_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.3 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:37,729]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_122_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:37,730]  INFO {org.apache.spark.SparkContext} -  Created broadcast 122 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:37,734]  INFO {org.apache.spark.SparkContext} -  Starting job: collect at MLModelHandler.java:928 {org.apache.spark.SparkContext}
[2016-04-29 15:19:37,735]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 60 (collect at MLModelHandler.java:928) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:37,735]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 73(collect at MLModelHandler.java:928) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:37,735]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:37,739]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:37,742]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 73 (ZippedPartitionsRDD2[132] at zip at MLModelHandler.java:928), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:37,742]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:37,743]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(6176) called with curMem=2923137, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:37,743]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_123 stored as values in memory (estimated size 6.0 KB, free 980.3 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:37,747]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(3419) called with curMem=2929313, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:37,748]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_123_piece0 stored as bytes in memory (estimated size 3.3 KB, free 980.3 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:37,749]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_123_piece0 in memory on localhost:56403 (size: 3.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:37,750]  INFO {org.apache.spark.SparkContext} -  Created broadcast 123 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:37,750]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 73 (ZippedPartitionsRDD2[132] at zip at MLModelHandler.java:928) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:37,750]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 73.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:37,751]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 73.0 (TID 73, localhost, PROCESS_LOCAL, 1953 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:37,751]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 61 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:37,752]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 74(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:37,752]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:37,752]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 73.0 (TID 73) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:37,754]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:37,754]  INFO {org.apache.spark.rdd.HadoopRDD} -  Input split: file:/home/ml/wso2ml-1.1.0/datasets/banking.-1234.1461942923269:0+4882918 {org.apache.spark.rdd.HadoopRDD}
[2016-04-29 15:19:37,755]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 74 (MapPartitionsRDD[134] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:37,756]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=2932732, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:37,757]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_124 stored as values in memory (estimated size 8.5 KB, free 980.3 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:37,761]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4433) called with curMem=2941484, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:37,761]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_124_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.3 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:37,763]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_124_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:37,764]  INFO {org.apache.spark.SparkContext} -  Created broadcast 124 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:37,764]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 74 (MapPartitionsRDD[134] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:37,765]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 74.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:37,765]  INFO {org.apache.spark.rdd.HadoopRDD} -  Input split: file:/home/ml/wso2ml-1.1.0/datasets/banking.-1234.1461942923269:0+4882918 {org.apache.spark.rdd.HadoopRDD}
[2016-04-29 15:19:39,216]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 73.0 (TID 73). 254712 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:39,220]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 74.0 (TID 74, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:39,226]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 74.0 (TID 74) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:39,237]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:39,254]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 74.0 (TID 74). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:39,264]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 74.0 (TID 74) in 44 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:39,264]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 74 (treeAggregate at GradientDescent.scala:189) finished in 1.499 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,265]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 61 finished: treeAggregate at GradientDescent.scala:189, took 1.522572 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,267]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=2945917, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,267]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_125 stored as values in memory (estimated size 88.0 B, free 980.3 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,267]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 74.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:39,273]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=2946005, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,282]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_125_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.3 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,284]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_125_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:39,285]  INFO {org.apache.spark.SparkContext} -  Created broadcast 125 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:39,305]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:39,306]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 62 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,306]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 75(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,306]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,309]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,311]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 75 (MapPartitionsRDD[136] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,312]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=2946088, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,313]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_126 stored as values in memory (estimated size 8.5 KB, free 980.3 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,317]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4433) called with curMem=2954840, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,319]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_126_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,320]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_126_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:39,321]  INFO {org.apache.spark.SparkContext} -  Created broadcast 126 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:39,330]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 75 (MapPartitionsRDD[136] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,330]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 75.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:39,332]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 75.0 (TID 75, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:39,333]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 75.0 (TID 75) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:39,336]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:39,343]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 75.0 (TID 75). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:39,351]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 75.0 (TID 75) in 19 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:39,351]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 75.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:39,351]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 75 (treeAggregate at GradientDescent.scala:189) finished in 0.020 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,352]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 62 finished: treeAggregate at GradientDescent.scala:189, took 0.046751 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,353]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=2959273, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,353]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_127 stored as values in memory (estimated size 88.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,359]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=2959361, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,359]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_127_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,361]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_127_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:39,362]  INFO {org.apache.spark.SparkContext} -  Created broadcast 127 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:39,375]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 73.0 (TID 73) in 1624 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:39,375]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 73.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:39,376]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 73 (collect at MLModelHandler.java:928) finished in 1.625 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,378]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 60 finished: collect at MLModelHandler.java:928, took 1.643585 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,390]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:39,391]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 63 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,391]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 76(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,392]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,394]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,395]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 76 (MapPartitionsRDD[138] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,397]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=2959444, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,397]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_128 stored as values in memory (estimated size 8.5 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,402]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4433) called with curMem=2968196, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,404]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_128_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,417]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_128_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:39,417]  INFO {org.apache.spark.SparkContext} -  Created broadcast 128 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:39,418]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 76 (MapPartitionsRDD[138] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,418]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 76.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:39,419]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 76.0 (TID 76, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:39,420]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 76.0 (TID 76) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:39,422]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:39,429]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 76.0 (TID 76). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:39,434]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 76 (treeAggregate at GradientDescent.scala:189) finished in 0.014 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,435]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 63 finished: treeAggregate at GradientDescent.scala:189, took 0.044682 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,436]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=2972629, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,437]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_129 stored as values in memory (estimated size 88.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,437]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 76.0 (TID 76) in 15 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:39,438]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 76.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:39,442]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=2972717, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,446]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_129_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,448]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_129_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:39,449]  INFO {org.apache.spark.SparkContext} -  Created broadcast 129 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:39,467]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:39,467]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 64 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,469]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 77(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,469]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,471]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,472]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 77 (MapPartitionsRDD[140] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,473]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=2972800, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,473]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_130 stored as values in memory (estimated size 8.5 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,478]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4432) called with curMem=2981552, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,478]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_130_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,481]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_130_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:39,481]  INFO {org.apache.spark.SparkContext} -  Created broadcast 130 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:39,481]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 77 (MapPartitionsRDD[140] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,482]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 77.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:39,483]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 77.0 (TID 77, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:39,484]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 77.0 (TID 77) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:39,487]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:39,496]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 77.0 (TID 77). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:39,500]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 77.0 (TID 77) in 18 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:39,501]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 77.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:39,501]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 77 (treeAggregate at GradientDescent.scala:189) finished in 0.019 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,502]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 64 finished: treeAggregate at GradientDescent.scala:189, took 0.034588 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,503]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=2985984, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,503]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_131 stored as values in memory (estimated size 88.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,507]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=2986072, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,508]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_131_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,524]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_131_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:39,525]  INFO {org.apache.spark.SparkContext} -  Created broadcast 131 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:39,540]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:39,541]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 65 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,541]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 78(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,541]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,543]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,544]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 78 (MapPartitionsRDD[142] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,545]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=2986155, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,545]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_132 stored as values in memory (estimated size 8.5 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,550]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4433) called with curMem=2994907, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,550]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_132_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,566]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_132_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:39,566]  INFO {org.apache.spark.SparkContext} -  Created broadcast 132 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:39,567]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 78 (MapPartitionsRDD[142] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,567]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 78.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:39,568]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 78.0 (TID 78, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:39,569]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 78.0 (TID 78) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:39,571]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:39,583]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 78.0 (TID 78). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:39,587]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 78 (treeAggregate at GradientDescent.scala:189) finished in 0.019 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,588]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 65 finished: treeAggregate at GradientDescent.scala:189, took 0.047865 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,587]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 78.0 (TID 78) in 19 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:39,588]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 78.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:39,589]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=2999340, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,589]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_133 stored as values in memory (estimated size 88.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,595]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=2999428, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,598]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_133_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,602]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_133_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:39,603]  INFO {org.apache.spark.SparkContext} -  Created broadcast 133 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:39,625]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:39,626]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 66 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,626]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 79(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,626]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,629]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,630]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 79 (MapPartitionsRDD[144] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,631]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=2999511, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,632]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_134 stored as values in memory (estimated size 8.5 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,637]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4432) called with curMem=3008263, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,639]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_134_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,641]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_134_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:39,642]  INFO {org.apache.spark.SparkContext} -  Created broadcast 134 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:39,642]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 79 (MapPartitionsRDD[144] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,642]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 79.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:39,643]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 79.0 (TID 79, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:39,644]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 79.0 (TID 79) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:39,646]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:39,651]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 79.0 (TID 79). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:39,655]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 79.0 (TID 79) in 12 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:39,656]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 79.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:39,656]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 79 (treeAggregate at GradientDescent.scala:189) finished in 0.012 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,656]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 66 finished: treeAggregate at GradientDescent.scala:189, took 0.031347 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,658]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3012695, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,658]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_135 stored as values in memory (estimated size 88.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,661]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3012783, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,662]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_135_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,663]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_135_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:39,664]  INFO {org.apache.spark.SparkContext} -  Created broadcast 135 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:39,672]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:39,673]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 67 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,674]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 80(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,674]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,676]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,676]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 80 (MapPartitionsRDD[146] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,677]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3012866, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,678]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_136 stored as values in memory (estimated size 8.5 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,681]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4431) called with curMem=3021618, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,682]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_136_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,683]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_136_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:39,683]  INFO {org.apache.spark.SparkContext} -  Created broadcast 136 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:39,684]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 80 (MapPartitionsRDD[146] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,684]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 80.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:39,685]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 80.0 (TID 80, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:39,685]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 80.0 (TID 80) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:39,688]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:39,693]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 80.0 (TID 80). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:39,697]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 80.0 (TID 80) in 12 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:39,697]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 80.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:39,697]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 80 (treeAggregate at GradientDescent.scala:189) finished in 0.013 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,698]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 67 finished: treeAggregate at GradientDescent.scala:189, took 0.025166 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,699]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3026049, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,699]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_137 stored as values in memory (estimated size 88.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,704]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3026137, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,705]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_137_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,706]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_137_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:39,706]  INFO {org.apache.spark.SparkContext} -  Created broadcast 137 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:39,715]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:39,716]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 68 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,716]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 81(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,717]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,719]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,720]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 81 (MapPartitionsRDD[148] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,721]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3026220, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,721]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_138 stored as values in memory (estimated size 8.5 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,725]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4429) called with curMem=3034972, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,725]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_138_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,727]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_138_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:39,727]  INFO {org.apache.spark.SparkContext} -  Created broadcast 138 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:39,728]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 81 (MapPartitionsRDD[148] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,728]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 81.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:39,729]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 81.0 (TID 81, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:39,729]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 81.0 (TID 81) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:39,732]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:39,737]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 81.0 (TID 81). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:39,740]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 81.0 (TID 81) in 11 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:39,741]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 81.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:39,741]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 81 (treeAggregate at GradientDescent.scala:189) finished in 0.013 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,741]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 68 finished: treeAggregate at GradientDescent.scala:189, took 0.025672 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,742]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3039401, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,742]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_139 stored as values in memory (estimated size 88.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,755]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3039489, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,755]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_139_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,757]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_139_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:39,758]  INFO {org.apache.spark.SparkContext} -  Created broadcast 139 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:39,758]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_138_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:39,765]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_137_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:39,771]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_136_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:39,774]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:39,776]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 69 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,776]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 82(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,776]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,776]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_135_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:39,780]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,781]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 82 (MapPartitionsRDD[150] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,782]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=2999682, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,782]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_140 stored as values in memory (estimated size 8.5 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,783]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_134_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:39,788]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_133_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:39,794]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_132_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:39,796]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4428) called with curMem=2995078, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,798]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_140_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,799]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_131_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:39,802]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_140_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:39,802]  INFO {org.apache.spark.SparkContext} -  Created broadcast 140 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:39,804]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 82 (MapPartitionsRDD[150] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,804]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 82.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:39,805]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 82.0 (TID 82, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:39,806]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 82.0 (TID 82) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:39,808]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:39,809]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_130_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:39,815]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 82.0 (TID 82). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:39,818]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_129_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:39,820]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 82 (treeAggregate at GradientDescent.scala:189) finished in 0.015 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,820]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 82.0 (TID 82) in 15 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:39,822]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 82.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:39,822]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 69 finished: treeAggregate at GradientDescent.scala:189, took 0.046890 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,823]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=2981547, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,823]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_141 stored as values in memory (estimated size 88.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,824]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_128_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:39,827]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=2981635, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,828]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_141_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,831]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_141_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:39,832]  INFO {org.apache.spark.SparkContext} -  Created broadcast 141 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:39,834]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_127_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:39,838]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_126_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:39,844]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_125_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:39,846]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:39,847]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 70 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,847]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 83(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,848]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,849]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_124_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:39,850]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,851]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 83 (MapPartitionsRDD[152] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,855]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=2942835, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,855]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_142 stored as values in memory (estimated size 8.5 KB, free 980.3 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,856]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_123_piece0 on localhost:56403 in memory (size: 3.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:39,861]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4433) called with curMem=2945240, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,862]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_142_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.3 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,863]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_122_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:39,865]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_142_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:39,866]  INFO {org.apache.spark.SparkContext} -  Created broadcast 142 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:39,867]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 83 (MapPartitionsRDD[152] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,867]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 83.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:39,868]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_121_piece0 on localhost:56403 in memory (size: 230.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:39,868]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 83.0 (TID 83, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:39,869]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 83.0 (TID 83) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:39,871]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:39,881]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 83.0 (TID 83). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:39,881]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_120_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:39,884]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 83.0 (TID 83) in 16 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:39,885]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 83.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:39,885]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 83 (treeAggregate at GradientDescent.scala:189) finished in 0.017 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,886]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 70 finished: treeAggregate at GradientDescent.scala:189, took 0.039552 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,887]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=2935964, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,887]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_143 stored as values in memory (estimated size 88.0 B, free 980.3 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,889]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_119_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:39,892]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=2935881, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,893]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_143_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.3 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,895]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_143_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:39,895]  INFO {org.apache.spark.SparkContext} -  Created broadcast 143 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:39,895]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_118_piece0 on localhost:56403 in memory (size: 1570.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:39,906]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:39,909]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 71 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,909]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 84(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,909]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,911]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,912]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 84 (MapPartitionsRDD[154] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,913]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=2931642, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,913]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_144 stored as values in memory (estimated size 8.5 KB, free 980.3 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,917]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4438) called with curMem=2940394, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,917]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_144_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.3 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,919]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_144_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:39,919]  INFO {org.apache.spark.SparkContext} -  Created broadcast 144 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:39,920]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 84 (MapPartitionsRDD[154] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,920]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 84.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:39,921]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 84.0 (TID 84, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:39,921]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 84.0 (TID 84) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:39,924]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:39,929]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 84.0 (TID 84). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:39,936]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 84.0 (TID 84) in 15 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:39,936]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 84.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:39,936]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 84 (treeAggregate at GradientDescent.scala:189) finished in 0.016 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,937]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 71 finished: treeAggregate at GradientDescent.scala:189, took 0.029997 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,938]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=2944832, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,938]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_145 stored as values in memory (estimated size 88.0 B, free 980.3 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,941]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=2944920, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,942]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_145_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.3 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,943]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_145_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:39,944]  INFO {org.apache.spark.SparkContext} -  Created broadcast 145 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:39,953]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:39,954]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 72 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,954]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 85(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,954]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,956]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,957]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 85 (MapPartitionsRDD[156] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,958]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=2945003, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,958]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_146 stored as values in memory (estimated size 8.5 KB, free 980.3 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,961]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4430) called with curMem=2953755, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,962]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_146_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,963]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_146_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:39,964]  INFO {org.apache.spark.SparkContext} -  Created broadcast 146 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:39,964]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 85 (MapPartitionsRDD[156] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,964]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 85.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:39,965]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 85.0 (TID 85, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:39,966]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 85.0 (TID 85) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:39,968]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:39,973]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 85.0 (TID 85). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:39,977]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 85.0 (TID 85) in 12 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:39,977]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 85 (treeAggregate at GradientDescent.scala:189) finished in 0.012 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,977]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 85.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:39,978]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 72 finished: treeAggregate at GradientDescent.scala:189, took 0.024596 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,979]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=2958185, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,979]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_147 stored as values in memory (estimated size 88.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,983]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=2958273, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,984]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_147_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:39,985]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_147_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:39,986]  INFO {org.apache.spark.SparkContext} -  Created broadcast 147 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:39,995]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:39,996]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 73 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,997]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 86(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,997]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:39,999]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,000]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 86 (MapPartitionsRDD[158] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,001]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=2958356, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,001]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_148 stored as values in memory (estimated size 8.5 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,005]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4433) called with curMem=2967108, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,005]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_148_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,007]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_148_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,007]  INFO {org.apache.spark.SparkContext} -  Created broadcast 148 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:40,008]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 86 (MapPartitionsRDD[158] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,008]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 86.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:40,009]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 86.0 (TID 86, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:40,009]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 86.0 (TID 86) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:40,012]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:40,018]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 86.0 (TID 86). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:40,021]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 86.0 (TID 86) in 12 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:40,021]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 86 (treeAggregate at GradientDescent.scala:189) finished in 0.013 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,021]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 86.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:40,022]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 73 finished: treeAggregate at GradientDescent.scala:189, took 0.026470 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,023]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=2971541, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,023]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_149 stored as values in memory (estimated size 88.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,027]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=2971629, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,027]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_149_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,029]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_149_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,030]  INFO {org.apache.spark.SparkContext} -  Created broadcast 149 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:40,041]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:40,042]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 74 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,042]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 87(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,042]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,044]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,045]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 87 (MapPartitionsRDD[160] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,046]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=2971712, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,046]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_150 stored as values in memory (estimated size 8.5 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,049]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4433) called with curMem=2980464, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,050]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_150_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,051]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_150_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,051]  INFO {org.apache.spark.SparkContext} -  Created broadcast 150 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:40,052]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 87 (MapPartitionsRDD[160] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,052]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 87.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:40,053]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 87.0 (TID 87, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:40,053]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 87.0 (TID 87) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:40,056]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:40,061]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 87.0 (TID 87). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:40,065]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 87.0 (TID 87) in 12 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:40,066]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 87.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:40,066]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 87 (treeAggregate at GradientDescent.scala:189) finished in 0.012 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,066]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 74 finished: treeAggregate at GradientDescent.scala:189, took 0.024800 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,067]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=2984897, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,067]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_151 stored as values in memory (estimated size 88.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,074]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=2984985, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,074]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_151_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,076]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_151_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,076]  INFO {org.apache.spark.SparkContext} -  Created broadcast 151 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:40,086]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:40,087]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 75 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,087]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 88(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,087]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,090]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,090]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 88 (MapPartitionsRDD[162] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,091]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=2985068, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,091]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_152 stored as values in memory (estimated size 8.5 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,095]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4433) called with curMem=2993820, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,096]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_152_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,097]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_152_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,098]  INFO {org.apache.spark.SparkContext} -  Created broadcast 152 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:40,098]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 88 (MapPartitionsRDD[162] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,098]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 88.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:40,099]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 88.0 (TID 88, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:40,100]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 88.0 (TID 88) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:40,102]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:40,108]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 88.0 (TID 88). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:40,112]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 88.0 (TID 88) in 13 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:40,112]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 88 (treeAggregate at GradientDescent.scala:189) finished in 0.013 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,112]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 88.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:40,113]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 75 finished: treeAggregate at GradientDescent.scala:189, took 0.026884 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,114]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=2998253, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,114]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_153 stored as values in memory (estimated size 88.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,118]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=2998341, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,118]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_153_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,119]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_153_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,120]  INFO {org.apache.spark.SparkContext} -  Created broadcast 153 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:40,128]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:40,129]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 76 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,129]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 89(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,129]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,132]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,132]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 89 (MapPartitionsRDD[164] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,134]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=2998424, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,134]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_154 stored as values in memory (estimated size 8.5 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,139]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4427) called with curMem=3007176, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,140]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_154_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,141]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_154_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,142]  INFO {org.apache.spark.SparkContext} -  Created broadcast 154 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:40,142]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 89 (MapPartitionsRDD[164] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,142]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 89.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:40,143]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 89.0 (TID 89, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:40,144]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 89.0 (TID 89) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:40,146]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:40,151]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 89.0 (TID 89). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:40,155]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 89.0 (TID 89) in 12 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:40,156]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 89 (treeAggregate at GradientDescent.scala:189) finished in 0.012 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,156]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 76 finished: treeAggregate at GradientDescent.scala:189, took 0.027652 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,156]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 89.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:40,157]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3011603, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,157]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_155 stored as values in memory (estimated size 88.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,161]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3011691, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,161]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_155_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,162]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_155_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,163]  INFO {org.apache.spark.SparkContext} -  Created broadcast 155 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:40,171]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:40,172]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 77 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,172]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 90(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,173]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,174]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,175]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 90 (MapPartitionsRDD[166] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,176]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3011774, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,177]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_156 stored as values in memory (estimated size 8.5 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,181]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4431) called with curMem=3020526, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,181]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_156_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,182]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_156_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,183]  INFO {org.apache.spark.SparkContext} -  Created broadcast 156 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:40,183]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 90 (MapPartitionsRDD[166] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,183]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 90.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:40,184]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 90.0 (TID 90, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:40,185]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 90.0 (TID 90) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:40,187]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:40,192]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 90.0 (TID 90). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:40,196]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 90.0 (TID 90) in 12 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:40,197]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 90.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:40,196]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 90 (treeAggregate at GradientDescent.scala:189) finished in 0.012 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,197]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 77 finished: treeAggregate at GradientDescent.scala:189, took 0.025738 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,198]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3024957, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,199]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_157 stored as values in memory (estimated size 88.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,202]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3025045, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,203]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_157_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,204]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_157_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,205]  INFO {org.apache.spark.SparkContext} -  Created broadcast 157 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:40,215]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:40,216]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 78 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,216]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 91(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,216]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,218]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,219]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 91 (MapPartitionsRDD[168] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,220]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3025128, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,220]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_158 stored as values in memory (estimated size 8.5 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,225]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4435) called with curMem=3033880, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,225]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_158_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,226]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_158_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,227]  INFO {org.apache.spark.SparkContext} -  Created broadcast 158 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:40,227]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 91 (MapPartitionsRDD[168] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,227]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 91.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:40,228]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 91.0 (TID 91, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:40,229]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 91.0 (TID 91) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:40,231]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:40,236]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 91.0 (TID 91). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:40,240]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 91.0 (TID 91) in 12 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:40,240]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 91.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:40,240]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 91 (treeAggregate at GradientDescent.scala:189) finished in 0.012 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,241]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 78 finished: treeAggregate at GradientDescent.scala:189, took 0.026005 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,242]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3038315, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,243]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_159 stored as values in memory (estimated size 88.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,246]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3038403, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,246]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_159_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,248]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_159_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,248]  INFO {org.apache.spark.SparkContext} -  Created broadcast 159 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:40,257]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:40,258]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 79 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,258]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 92(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,258]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,260]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,261]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 92 (MapPartitionsRDD[170] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,262]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3038486, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,262]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_160 stored as values in memory (estimated size 8.5 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,266]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4429) called with curMem=3047238, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,266]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_160_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,268]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_160_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,269]  INFO {org.apache.spark.SparkContext} -  Created broadcast 160 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:40,269]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 92 (MapPartitionsRDD[170] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,269]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 92.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:40,270]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 92.0 (TID 92, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:40,270]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 92.0 (TID 92) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:40,273]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:40,278]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 92.0 (TID 92). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:40,282]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 92 (treeAggregate at GradientDescent.scala:189) finished in 0.012 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,282]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 92.0 (TID 92) in 12 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:40,283]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 92.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:40,283]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 79 finished: treeAggregate at GradientDescent.scala:189, took 0.025865 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,284]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3051667, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,284]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_161 stored as values in memory (estimated size 88.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,287]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3051755, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,288]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_161_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,289]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_161_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,290]  INFO {org.apache.spark.SparkContext} -  Created broadcast 161 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:40,299]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:40,303]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 80 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,303]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 93(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,303]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,305]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,306]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 93 (MapPartitionsRDD[172] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,307]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3051838, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,307]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_162 stored as values in memory (estimated size 8.5 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,311]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4429) called with curMem=3060590, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,311]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_162_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,313]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_162_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,313]  INFO {org.apache.spark.SparkContext} -  Created broadcast 162 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:40,313]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 93 (MapPartitionsRDD[172] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,314]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 93.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:40,315]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 93.0 (TID 93, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:40,315]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 93.0 (TID 93) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:40,317]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:40,323]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 93.0 (TID 93). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:40,328]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 93.0 (TID 93) in 13 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:40,328]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 93.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:40,328]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 93 (treeAggregate at GradientDescent.scala:189) finished in 0.014 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,329]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 80 finished: treeAggregate at GradientDescent.scala:189, took 0.028994 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,329]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3065019, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,330]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_163 stored as values in memory (estimated size 88.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,333]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3065107, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,334]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_163_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,335]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_163_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,335]  INFO {org.apache.spark.SparkContext} -  Created broadcast 163 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:40,345]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:40,347]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 81 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,347]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 94(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,347]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,354]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,355]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 94 (MapPartitionsRDD[174] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,357]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3065190, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,357]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_164 stored as values in memory (estimated size 8.5 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,362]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4433) called with curMem=3073942, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,363]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_164_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,365]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_164_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,366]  INFO {org.apache.spark.SparkContext} -  Created broadcast 164 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:40,367]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 94 (MapPartitionsRDD[174] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,367]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 94.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:40,368]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 94.0 (TID 94, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:40,369]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 94.0 (TID 94) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:40,371]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:40,377]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 94.0 (TID 94). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:40,381]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 94.0 (TID 94) in 13 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:40,382]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 94.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:40,382]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 94 (treeAggregate at GradientDescent.scala:189) finished in 0.013 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,383]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 81 finished: treeAggregate at GradientDescent.scala:189, took 0.038144 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,386]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3078375, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,387]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_165 stored as values in memory (estimated size 88.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,393]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3078463, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,394]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_165_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,395]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_165_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,396]  INFO {org.apache.spark.SparkContext} -  Created broadcast 165 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:40,404]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:40,405]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 82 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,405]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 95(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,406]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,407]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,408]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 95 (MapPartitionsRDD[176] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,409]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3078546, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,409]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_166 stored as values in memory (estimated size 8.5 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,413]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4432) called with curMem=3087298, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,414]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_166_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,415]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_166_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,416]  INFO {org.apache.spark.SparkContext} -  Created broadcast 166 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:40,416]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 95 (MapPartitionsRDD[176] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,416]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 95.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:40,417]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 95.0 (TID 95, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:40,418]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 95.0 (TID 95) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:40,420]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:40,425]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 95.0 (TID 95). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:40,429]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 95.0 (TID 95) in 12 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:40,430]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 95.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:40,430]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 95 (treeAggregate at GradientDescent.scala:189) finished in 0.013 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,430]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 82 finished: treeAggregate at GradientDescent.scala:189, took 0.025627 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,431]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3091730, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,431]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_167 stored as values in memory (estimated size 88.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,439]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3091818, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,440]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_167_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,441]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_167_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,442]  INFO {org.apache.spark.SparkContext} -  Created broadcast 167 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:40,453]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:40,454]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 83 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,454]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 96(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,454]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,468]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,469]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 96 (MapPartitionsRDD[178] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,471]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3091901, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,471]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_168 stored as values in memory (estimated size 8.5 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,477]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4429) called with curMem=3100653, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,477]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_168_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,479]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_168_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,480]  INFO {org.apache.spark.SparkContext} -  Created broadcast 168 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:40,480]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 96 (MapPartitionsRDD[178] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,481]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 96.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:40,482]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 96.0 (TID 96, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:40,482]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 96.0 (TID 96) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:40,485]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:40,490]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 96.0 (TID 96). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:40,494]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 96.0 (TID 96) in 12 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:40,494]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 96 (treeAggregate at GradientDescent.scala:189) finished in 0.013 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,495]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 96.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:40,496]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 83 finished: treeAggregate at GradientDescent.scala:189, took 0.042543 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,497]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3105082, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,497]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_169 stored as values in memory (estimated size 88.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,500]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3105170, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,501]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_169_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,502]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_169_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,503]  INFO {org.apache.spark.SparkContext} -  Created broadcast 169 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:40,511]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:40,512]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 84 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,513]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 97(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,513]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,522]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,522]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 97 (MapPartitionsRDD[180] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,523]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3105253, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,523]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_170 stored as values in memory (estimated size 8.5 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,527]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4433) called with curMem=3114005, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,527]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_170_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,529]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_170_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,529]  INFO {org.apache.spark.SparkContext} -  Created broadcast 170 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:40,530]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 97 (MapPartitionsRDD[180] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,530]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 97.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:40,531]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 97.0 (TID 97, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:40,531]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 97.0 (TID 97) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:40,533]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:40,539]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 97.0 (TID 97). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:40,542]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 97.0 (TID 97) in 12 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:40,543]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 97 (treeAggregate at GradientDescent.scala:189) finished in 0.013 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,543]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 97.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:40,544]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 84 finished: treeAggregate at GradientDescent.scala:189, took 0.032099 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,544]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3118438, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,545]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_171 stored as values in memory (estimated size 88.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,550]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3118526, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,551]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_171_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,552]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_171_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,553]  INFO {org.apache.spark.SparkContext} -  Created broadcast 171 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:40,562]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:40,563]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 85 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,564]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 98(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,564]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,565]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,566]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 98 (MapPartitionsRDD[182] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,567]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3118609, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,567]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_172 stored as values in memory (estimated size 8.5 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,571]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4426) called with curMem=3127361, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,572]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_172_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,573]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_172_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,574]  INFO {org.apache.spark.SparkContext} -  Created broadcast 172 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:40,574]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 98 (MapPartitionsRDD[182] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,574]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 98.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:40,576]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 98.0 (TID 98, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:40,576]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 98.0 (TID 98) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:40,578]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:40,583]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 98.0 (TID 98). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:40,587]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 98.0 (TID 98) in 11 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:40,587]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 98 (treeAggregate at GradientDescent.scala:189) finished in 0.011 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,588]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 98.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:40,589]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 85 finished: treeAggregate at GradientDescent.scala:189, took 0.025799 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,589]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3131787, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,590]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_173 stored as values in memory (estimated size 88.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,594]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3131875, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,594]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_173_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,596]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_173_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,597]  INFO {org.apache.spark.SparkContext} -  Created broadcast 173 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:40,607]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:40,608]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 86 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,608]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 99(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,608]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,611]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,611]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 99 (MapPartitionsRDD[184] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,612]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3131958, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,613]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_174 stored as values in memory (estimated size 8.5 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,617]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4429) called with curMem=3140710, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,617]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_174_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,619]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_174_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,620]  INFO {org.apache.spark.SparkContext} -  Created broadcast 174 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:40,620]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 99 (MapPartitionsRDD[184] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,620]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 99.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:40,621]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 99.0 (TID 99, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:40,622]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 99.0 (TID 99) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:40,624]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:40,629]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 99.0 (TID 99). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:40,632]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 99 (treeAggregate at GradientDescent.scala:189) finished in 0.011 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,632]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 99.0 (TID 99) in 11 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:40,633]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 86 finished: treeAggregate at GradientDescent.scala:189, took 0.026122 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,633]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 99.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:40,635]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3145139, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,635]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_175 stored as values in memory (estimated size 88.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,640]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3145227, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,641]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_175_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,643]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_175_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,643]  INFO {org.apache.spark.SparkContext} -  Created broadcast 175 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:40,653]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:40,655]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 87 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,655]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 100(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,655]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,657]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,658]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 100 (MapPartitionsRDD[186] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,659]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3145310, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,659]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_176 stored as values in memory (estimated size 8.5 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,664]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4433) called with curMem=3154062, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,665]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_176_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,667]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_176_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,667]  INFO {org.apache.spark.SparkContext} -  Created broadcast 176 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:40,668]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 100 (MapPartitionsRDD[186] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,668]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 100.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:40,669]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 100.0 (TID 100, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:40,669]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 100.0 (TID 100) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:40,671]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:40,676]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 100.0 (TID 100). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:40,681]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 100.0 (TID 100) in 11 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:40,681]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 100.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:40,682]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 100 (treeAggregate at GradientDescent.scala:189) finished in 0.014 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,683]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 87 finished: treeAggregate at GradientDescent.scala:189, took 0.029451 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,684]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3158495, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,684]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_177 stored as values in memory (estimated size 88.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,689]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3158583, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,689]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_177_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,691]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_177_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,691]  INFO {org.apache.spark.SparkContext} -  Created broadcast 177 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:40,703]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:40,705]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 88 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,705]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 101(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,705]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,708]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,711]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 101 (MapPartitionsRDD[188] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,712]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3158666, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,712]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_178 stored as values in memory (estimated size 8.5 KB, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,716]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4429) called with curMem=3167418, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,717]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_178_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,719]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_178_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,719]  INFO {org.apache.spark.SparkContext} -  Created broadcast 178 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:40,720]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 101 (MapPartitionsRDD[188] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,720]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 101.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:40,721]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 101.0 (TID 101, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:40,722]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 101.0 (TID 101) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:40,725]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:40,731]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 101.0 (TID 101). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:40,736]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 101.0 (TID 101) in 15 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:40,737]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 101.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:40,737]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 101 (treeAggregate at GradientDescent.scala:189) finished in 0.005 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,738]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 88 finished: treeAggregate at GradientDescent.scala:189, took 0.033889 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,739]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3171847, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,739]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_179 stored as values in memory (estimated size 88.0 B, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,756]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3167506, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,756]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_179_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.0 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,757]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_178_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,765]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_177_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,766]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_179_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,767]  INFO {org.apache.spark.SparkContext} -  Created broadcast 179 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:40,773]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_176_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,780]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_175_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,788]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_174_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,795]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_173_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,795]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:40,796]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 89 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,796]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 102(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,796]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,799]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,800]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 102 (MapPartitionsRDD[190] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,803]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3127532, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,803]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_180 stored as values in memory (estimated size 8.5 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,804]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_172_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,812]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_171_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,813]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4433) called with curMem=3127361, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,815]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_180_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,822]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_170_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,829]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_180_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,829]  INFO {org.apache.spark.SparkContext} -  Created broadcast 180 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:40,830]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 102 (MapPartitionsRDD[190] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,830]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 102.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:40,830]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_169_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,831]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 102.0 (TID 102, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:40,832]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 102.0 (TID 102) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:40,835]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:40,841]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_168_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,849]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_167_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,850]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 102.0 (TID 102). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:40,858]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 102 (treeAggregate at GradientDescent.scala:189) finished in 0.026 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,859]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 89 finished: treeAggregate at GradientDescent.scala:189, took 0.064039 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,860]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3100654, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,861]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_181 stored as values in memory (estimated size 88.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,861]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 102.0 (TID 102) in 26 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:40,862]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_166_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,866]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 102.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:40,867]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3091990, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,869]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_181_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,874]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_181_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,875]  INFO {org.apache.spark.SparkContext} -  Created broadcast 181 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:40,876]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_165_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,882]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_164_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,889]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_163_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,896]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_162_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,901]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:40,902]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 90 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,902]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 103(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,902]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,904]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_161_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,905]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,906]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 103 (MapPartitionsRDD[192] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,907]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3065194, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,907]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_182 stored as values in memory (estimated size 8.5 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,916]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_160_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,917]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4429) called with curMem=3060765, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,923]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_182_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,925]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_159_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,927]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_182_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,928]  INFO {org.apache.spark.SparkContext} -  Created broadcast 182 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:40,930]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 103 (MapPartitionsRDD[192] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,931]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 103.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:40,932]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_158_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,935]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 103.0 (TID 103, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:40,936]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 103.0 (TID 103) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:40,938]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_157_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,939]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:40,944]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_156_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,952]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_155_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,958]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_154_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,952]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 103.0 (TID 103). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:40,964]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 103 (treeAggregate at GradientDescent.scala:189) finished in 0.029 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,965]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 90 finished: treeAggregate at GradientDescent.scala:189, took 0.064508 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:40,966]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3025049, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,967]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_153_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,967]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_183 stored as values in memory (estimated size 88.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,967]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 103.0 (TID 103) in 28 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:40,967]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 103.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:40,973]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3016297, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,973]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_183_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:40,975]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_183_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,976]  INFO {org.apache.spark.SparkContext} -  Created broadcast 183 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:40,978]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_152_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,984]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_151_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,993]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_150_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:40,997]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_149_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,004]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_148_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,010]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:41,011]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 91 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,012]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 104(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,012]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,012]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_147_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,017]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,018]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 104 (MapPartitionsRDD[194] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,019]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=2980634, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,020]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_184 stored as values in memory (estimated size 8.5 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,021]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_146_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,027]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_145_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,033]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_144_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,038]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_143_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,038]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4429) called with curMem=2967190, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,039]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_184_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,043]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_184_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,044]  INFO {org.apache.spark.SparkContext} -  Created broadcast 184 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:41,044]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 104 (MapPartitionsRDD[194] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,045]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_142_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,046]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 104.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:41,048]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 104.0 (TID 104, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:41,049]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 104.0 (TID 104) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:41,053]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:41,053]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_141_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,058]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_140_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,064]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 104.0 (TID 104). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:41,064]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_139_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,070]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 104 (treeAggregate at GradientDescent.scala:189) finished in 0.021 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,071]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 104.0 (TID 104) in 22 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:41,071]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 91 finished: treeAggregate at GradientDescent.scala:189, took 0.060707 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,072]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=2944824, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,072]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_185 stored as values in memory (estimated size 88.0 B, free 980.3 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,071]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 104.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:41,076]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=2944912, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,077]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_185_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.3 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,079]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_185_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,079]  INFO {org.apache.spark.SparkContext} -  Created broadcast 185 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:41,089]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:41,091]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 92 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,091]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 105(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,092]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,095]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,096]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 105 (MapPartitionsRDD[196] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,097]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=2944995, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,097]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_186 stored as values in memory (estimated size 8.5 KB, free 980.3 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,101]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4429) called with curMem=2953747, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,102]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_186_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,104]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_186_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,104]  INFO {org.apache.spark.SparkContext} -  Created broadcast 186 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:41,105]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 105 (MapPartitionsRDD[196] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,105]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 105.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:41,106]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 105.0 (TID 105, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:41,106]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 105.0 (TID 105) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:41,108]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:41,114]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 105.0 (TID 105). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:41,118]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 105.0 (TID 105) in 12 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:41,119]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 105.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:41,119]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 105 (treeAggregate at GradientDescent.scala:189) finished in 0.013 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,120]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 92 finished: treeAggregate at GradientDescent.scala:189, took 0.029529 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,123]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=2958176, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,124]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_187 stored as values in memory (estimated size 88.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,128]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=2958264, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,132]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_187_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,135]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_187_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,136]  INFO {org.apache.spark.SparkContext} -  Created broadcast 187 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:41,157]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:41,158]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 93 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,158]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 106(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,158]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,160]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,161]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 106 (MapPartitionsRDD[198] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,163]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=2958347, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,164]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_188 stored as values in memory (estimated size 8.5 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,170]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4429) called with curMem=2967099, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,178]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_188_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,180]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_188_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,181]  INFO {org.apache.spark.SparkContext} -  Created broadcast 188 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:41,181]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 106 (MapPartitionsRDD[198] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,181]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 106.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:41,183]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 106.0 (TID 106, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:41,183]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 106.0 (TID 106) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:41,185]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:41,194]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 106.0 (TID 106). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:41,202]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 106 (treeAggregate at GradientDescent.scala:189) finished in 0.020 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,203]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 93 finished: treeAggregate at GradientDescent.scala:189, took 0.045357 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,204]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=2971528, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,204]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_189 stored as values in memory (estimated size 88.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,204]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 106.0 (TID 106) in 20 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:41,205]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 106.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:41,209]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=2971616, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,211]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_189_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,213]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_189_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,214]  INFO {org.apache.spark.SparkContext} -  Created broadcast 189 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:41,237]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:41,238]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 94 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,238]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 107(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,238]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,240]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,242]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 107 (MapPartitionsRDD[200] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,243]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=2971699, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,244]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_190 stored as values in memory (estimated size 8.5 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,248]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4429) called with curMem=2980451, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,258]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_190_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,260]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_190_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,261]  INFO {org.apache.spark.SparkContext} -  Created broadcast 190 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:41,262]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 107 (MapPartitionsRDD[200] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,262]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 107.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:41,264]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 107.0 (TID 107, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:41,264]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 107.0 (TID 107) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:41,267]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:41,280]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 107.0 (TID 107). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:41,288]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 107 (treeAggregate at GradientDescent.scala:189) finished in 0.025 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,288]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 94 finished: treeAggregate at GradientDescent.scala:189, took 0.051580 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,290]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=2984880, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,291]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_191 stored as values in memory (estimated size 88.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,291]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 107.0 (TID 107) in 24 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:41,292]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 107.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:41,294]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=2984968, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,295]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_191_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,297]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_191_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,297]  INFO {org.apache.spark.SparkContext} -  Created broadcast 191 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:41,307]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:41,308]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 95 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,308]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 108(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,308]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,310]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,311]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 108 (MapPartitionsRDD[202] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,312]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=2985051, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,312]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_192 stored as values in memory (estimated size 8.5 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,315]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4432) called with curMem=2993803, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,315]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_192_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,317]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_192_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,317]  INFO {org.apache.spark.SparkContext} -  Created broadcast 192 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:41,317]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 108 (MapPartitionsRDD[202] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,318]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 108.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:41,318]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 108.0 (TID 108, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:41,319]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 108.0 (TID 108) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:41,321]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:41,326]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 108.0 (TID 108). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:41,329]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 108.0 (TID 108) in 11 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:41,329]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 108 (treeAggregate at GradientDescent.scala:189) finished in 0.011 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,329]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 108.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:41,330]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 95 finished: treeAggregate at GradientDescent.scala:189, took 0.023108 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,331]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=2998235, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,331]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_193 stored as values in memory (estimated size 88.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,334]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=2998323, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,335]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_193_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,336]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_193_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,337]  INFO {org.apache.spark.SparkContext} -  Created broadcast 193 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:41,346]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:41,347]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 96 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,347]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 109(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,347]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,349]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,349]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 109 (MapPartitionsRDD[204] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,351]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=2998406, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,351]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_194 stored as values in memory (estimated size 8.5 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,355]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4433) called with curMem=3007158, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,355]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_194_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,356]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_194_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,357]  INFO {org.apache.spark.SparkContext} -  Created broadcast 194 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:41,358]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 109 (MapPartitionsRDD[204] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,358]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 109.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:41,359]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 109.0 (TID 109, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:41,359]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 109.0 (TID 109) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:41,361]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:41,366]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 109.0 (TID 109). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:41,371]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 109.0 (TID 109) in 12 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:41,371]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 109 (treeAggregate at GradientDescent.scala:189) finished in 0.013 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,371]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 109.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:41,372]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 96 finished: treeAggregate at GradientDescent.scala:189, took 0.025811 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,373]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3011591, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,374]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_195 stored as values in memory (estimated size 88.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,378]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3011679, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,378]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_195_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,380]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_195_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,381]  INFO {org.apache.spark.SparkContext} -  Created broadcast 195 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:41,392]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:41,393]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 97 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,394]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 110(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,395]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,397]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,397]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 110 (MapPartitionsRDD[206] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,398]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3011762, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,399]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_196 stored as values in memory (estimated size 8.5 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,407]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4427) called with curMem=3020514, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,407]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_196_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,409]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_196_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,409]  INFO {org.apache.spark.SparkContext} -  Created broadcast 196 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:41,410]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 110 (MapPartitionsRDD[206] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,410]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 110.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:41,411]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 110.0 (TID 110, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:41,411]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 110.0 (TID 110) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:41,413]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:41,419]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 110.0 (TID 110). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:41,422]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 110.0 (TID 110) in 12 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:41,422]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 110 (treeAggregate at GradientDescent.scala:189) finished in 0.012 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,422]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 110.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:41,423]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 97 finished: treeAggregate at GradientDescent.scala:189, took 0.029841 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,424]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3024941, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,424]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_197 stored as values in memory (estimated size 88.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,427]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3025029, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,428]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_197_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,429]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_197_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,430]  INFO {org.apache.spark.SparkContext} -  Created broadcast 197 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:41,439]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:41,440]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 98 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,440]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 111(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,441]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,444]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,444]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 111 (MapPartitionsRDD[208] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,447]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3025112, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,447]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_198 stored as values in memory (estimated size 8.5 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,450]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4429) called with curMem=3033864, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,451]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_198_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,452]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_198_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,453]  INFO {org.apache.spark.SparkContext} -  Created broadcast 198 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:41,453]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 111 (MapPartitionsRDD[208] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,453]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 111.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:41,454]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 111.0 (TID 111, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:41,454]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 111.0 (TID 111) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:41,457]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:41,464]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 111.0 (TID 111). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:41,469]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 111.0 (TID 111) in 15 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:41,469]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 111.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:41,469]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 111 (treeAggregate at GradientDescent.scala:189) finished in 0.016 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,470]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 98 finished: treeAggregate at GradientDescent.scala:189, took 0.030800 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,471]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3038293, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,471]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_199 stored as values in memory (estimated size 88.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,475]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3038381, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,475]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_199_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,477]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_199_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,478]  INFO {org.apache.spark.SparkContext} -  Created broadcast 199 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:41,487]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:41,488]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 99 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,489]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 112(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,489]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,499]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,501]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 112 (MapPartitionsRDD[210] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,502]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3038464, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,503]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_200 stored as values in memory (estimated size 8.5 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,506]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4429) called with curMem=3047216, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,507]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_200_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,509]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_200_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,509]  INFO {org.apache.spark.SparkContext} -  Created broadcast 200 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:41,510]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 112 (MapPartitionsRDD[210] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,510]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 112.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:41,511]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 112.0 (TID 112, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:41,511]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 112.0 (TID 112) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:41,513]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:41,519]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 112.0 (TID 112). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:41,522]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 112.0 (TID 112) in 12 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:41,523]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 112.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:41,523]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 112 (treeAggregate at GradientDescent.scala:189) finished in 0.005 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,524]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 99 finished: treeAggregate at GradientDescent.scala:189, took 0.036008 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,524]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3051645, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,525]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_201 stored as values in memory (estimated size 88.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,528]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3051733, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,528]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_201_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,530]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_201_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,530]  INFO {org.apache.spark.SparkContext} -  Created broadcast 201 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:41,540]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:41,541]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 100 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,541]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 113(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,541]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,543]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,543]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 113 (MapPartitionsRDD[212] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,544]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3051816, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,544]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_202 stored as values in memory (estimated size 8.5 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,547]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4429) called with curMem=3060568, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,548]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_202_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,549]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_202_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,549]  INFO {org.apache.spark.SparkContext} -  Created broadcast 202 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:41,550]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 113 (MapPartitionsRDD[212] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,550]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 113.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:41,551]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 113.0 (TID 113, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:41,551]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 113.0 (TID 113) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:41,553]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:41,559]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 113.0 (TID 113). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:41,562]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 113.0 (TID 113) in 11 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:41,563]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 113.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:41,563]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 113 (treeAggregate at GradientDescent.scala:189) finished in 0.013 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,564]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 100 finished: treeAggregate at GradientDescent.scala:189, took 0.023684 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,564]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3064997, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,565]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_203 stored as values in memory (estimated size 88.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,569]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3065085, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,569]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_203_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,571]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_203_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,572]  INFO {org.apache.spark.SparkContext} -  Created broadcast 203 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:41,582]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:41,583]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 101 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,583]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 114(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,583]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,586]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,586]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 114 (MapPartitionsRDD[214] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,587]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3065168, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,588]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_204 stored as values in memory (estimated size 8.5 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,591]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4429) called with curMem=3073920, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,591]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_204_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,593]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_204_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,593]  INFO {org.apache.spark.SparkContext} -  Created broadcast 204 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:41,593]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 114 (MapPartitionsRDD[214] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,594]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 114.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:41,594]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 114.0 (TID 114, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:41,595]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 114.0 (TID 114) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:41,597]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:41,602]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 114.0 (TID 114). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:41,606]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 114.0 (TID 114) in 12 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:41,606]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 114 (treeAggregate at GradientDescent.scala:189) finished in 0.012 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,606]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 114.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:41,607]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 101 finished: treeAggregate at GradientDescent.scala:189, took 0.024452 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,608]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3078349, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,608]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_205 stored as values in memory (estimated size 88.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,612]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3078437, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,612]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_205_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,614]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_205_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,614]  INFO {org.apache.spark.SparkContext} -  Created broadcast 205 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:41,625]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:41,626]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 102 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,626]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 115(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,626]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,631]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,632]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 115 (MapPartitionsRDD[216] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,634]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3078520, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,634]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_206 stored as values in memory (estimated size 8.5 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,638]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4431) called with curMem=3087272, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,638]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_206_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,640]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_206_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,640]  INFO {org.apache.spark.SparkContext} -  Created broadcast 206 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:41,641]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 115 (MapPartitionsRDD[216] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,641]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 115.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:41,642]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 115.0 (TID 115, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:41,645]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 115.0 (TID 115) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:41,647]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:41,652]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 115.0 (TID 115). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:41,656]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 115.0 (TID 115) in 15 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:41,656]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 115 (treeAggregate at GradientDescent.scala:189) finished in 0.015 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,657]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 115.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:41,658]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 102 finished: treeAggregate at GradientDescent.scala:189, took 0.032693 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,667]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3091703, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,667]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_207 stored as values in memory (estimated size 88.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,671]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3091791, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,672]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_207_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,674]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_207_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,674]  INFO {org.apache.spark.SparkContext} -  Created broadcast 207 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:41,685]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:41,686]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 103 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,686]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 116(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,686]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,688]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,688]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 116 (MapPartitionsRDD[218] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,689]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3091874, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,690]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_208 stored as values in memory (estimated size 8.5 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,693]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4432) called with curMem=3100626, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,695]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_208_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,696]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_208_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,697]  INFO {org.apache.spark.SparkContext} -  Created broadcast 208 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:41,697]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 116 (MapPartitionsRDD[218] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,697]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 116.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:41,698]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 116.0 (TID 116, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:41,699]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 116.0 (TID 116) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:41,701]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:41,706]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 116.0 (TID 116). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:41,709]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 116.0 (TID 116) in 11 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:41,709]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 116.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:41,709]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 116 (treeAggregate at GradientDescent.scala:189) finished in 0.011 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,710]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 103 finished: treeAggregate at GradientDescent.scala:189, took 0.025274 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,711]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3105058, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,712]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_209 stored as values in memory (estimated size 88.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,715]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3105146, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,716]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_209_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,718]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_209_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,718]  INFO {org.apache.spark.SparkContext} -  Created broadcast 209 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:41,729]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:41,730]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 104 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,730]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 117(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,730]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,732]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,732]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 117 (MapPartitionsRDD[220] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,733]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3105229, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,734]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_210 stored as values in memory (estimated size 8.5 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,737]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4428) called with curMem=3113981, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,737]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_210_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,739]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_210_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,739]  INFO {org.apache.spark.SparkContext} -  Created broadcast 210 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:41,739]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 117 (MapPartitionsRDD[220] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,740]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 117.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:41,741]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 117.0 (TID 117, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:41,741]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 117.0 (TID 117) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:41,743]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:41,748]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 117.0 (TID 117). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:41,751]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 117.0 (TID 117) in 11 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:41,751]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 117.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:41,751]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 117 (treeAggregate at GradientDescent.scala:189) finished in 0.011 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,752]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 104 finished: treeAggregate at GradientDescent.scala:189, took 0.022643 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,754]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3118409, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,754]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_211 stored as values in memory (estimated size 88.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,757]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3118497, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,758]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_211_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,760]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_211_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,762]  INFO {org.apache.spark.SparkContext} -  Created broadcast 211 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:41,771]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:41,772]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 105 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,772]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 118(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,772]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,775]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,775]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 118 (MapPartitionsRDD[222] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,776]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3118580, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,777]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_212 stored as values in memory (estimated size 8.5 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,780]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4429) called with curMem=3127332, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,780]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_212_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,782]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_212_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,782]  INFO {org.apache.spark.SparkContext} -  Created broadcast 212 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:41,783]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 118 (MapPartitionsRDD[222] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,783]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 118.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:41,784]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 118.0 (TID 118, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:41,784]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 118.0 (TID 118) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:41,786]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:41,791]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 118.0 (TID 118). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:41,795]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 118.0 (TID 118) in 10 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:41,795]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 118 (treeAggregate at GradientDescent.scala:189) finished in 0.012 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,795]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 105 finished: treeAggregate at GradientDescent.scala:189, took 0.024351 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,795]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 118.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:41,796]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3131761, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,796]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_213 stored as values in memory (estimated size 88.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,800]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3131849, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,801]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_213_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,802]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_213_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,803]  INFO {org.apache.spark.SparkContext} -  Created broadcast 213 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:41,813]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:41,814]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 106 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,814]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 119(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,814]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,817]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,817]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 119 (MapPartitionsRDD[224] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,819]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3131932, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,819]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_214 stored as values in memory (estimated size 8.5 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,823]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4433) called with curMem=3140684, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,823]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_214_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,825]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_214_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,825]  INFO {org.apache.spark.SparkContext} -  Created broadcast 214 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:41,825]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 119 (MapPartitionsRDD[224] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,825]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 119.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:41,826]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 119.0 (TID 119, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:41,827]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 119.0 (TID 119) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:41,829]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:41,833]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 119.0 (TID 119). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:41,837]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 119.0 (TID 119) in 11 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:41,837]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 119 (treeAggregate at GradientDescent.scala:189) finished in 0.011 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,838]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 106 finished: treeAggregate at GradientDescent.scala:189, took 0.024405 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,837]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 119.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:41,839]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3145117, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,839]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_215 stored as values in memory (estimated size 88.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,842]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3145205, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,843]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_215_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,844]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_215_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,845]  INFO {org.apache.spark.SparkContext} -  Created broadcast 215 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:41,854]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:41,857]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 107 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,857]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 120(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,857]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,859]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,860]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 120 (MapPartitionsRDD[226] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,861]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3145288, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,861]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_216 stored as values in memory (estimated size 8.5 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,865]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4431) called with curMem=3154040, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,865]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_216_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,867]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_216_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,869]  INFO {org.apache.spark.SparkContext} -  Created broadcast 216 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:41,870]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 120 (MapPartitionsRDD[226] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,870]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 120.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:41,871]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 120.0 (TID 120, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:41,871]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 120.0 (TID 120) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:41,873]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:41,879]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 120.0 (TID 120). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:41,881]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 120.0 (TID 120) in 10 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:41,882]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 120 (treeAggregate at GradientDescent.scala:189) finished in 0.012 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,882]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 107 finished: treeAggregate at GradientDescent.scala:189, took 0.028148 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,882]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 120.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:41,887]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3158471, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,887]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_217 stored as values in memory (estimated size 88.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,901]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3145376, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,901]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_217_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,902]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_216_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,903]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_217_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,904]  INFO {org.apache.spark.SparkContext} -  Created broadcast 217 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:41,907]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_215_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,911]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_214_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,919]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_213_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,922]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_212_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,928]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_211_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,932]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:41,933]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 108 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,933]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 121(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,933]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_210_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,933]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,936]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,936]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 121 (MapPartitionsRDD[228] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,938]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3105229, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,938]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_218 stored as values in memory (estimated size 8.5 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,942]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4433) called with curMem=3113981, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,942]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_209_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,942]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_218_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,945]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_218_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,945]  INFO {org.apache.spark.SparkContext} -  Created broadcast 218 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:41,946]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 121 (MapPartitionsRDD[228] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,946]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 121.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:41,947]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_208_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,947]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 121.0 (TID 121, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:41,947]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 121.0 (TID 121) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:41,950]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:41,954]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_207_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,959]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_206_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,960]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 121.0 (TID 121). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:41,964]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 121.0 (TID 121) in 17 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:41,965]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_205_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,965]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 121 (treeAggregate at GradientDescent.scala:189) finished in 0.018 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,970]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 121.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:41,974]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 108 finished: treeAggregate at GradientDescent.scala:189, took 0.041398 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,975]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3087276, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,975]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_219 stored as values in memory (estimated size 88.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,976]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_204_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,979]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3078612, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,980]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_219_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:41,982]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_219_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,983]  INFO {org.apache.spark.SparkContext} -  Created broadcast 219 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:41,983]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_203_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,988]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_202_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,993]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_201_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:41,994]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:41,995]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 109 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,995]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 122(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,995]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,998]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:41,998]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 122 (MapPartitionsRDD[230] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,000]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3051991, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,000]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_220 stored as values in memory (estimated size 8.5 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,001]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_200_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,004]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_199_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,007]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4435) called with curMem=3060572, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,008]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_220_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,010]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_220_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,011]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_198_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,015]  INFO {org.apache.spark.SparkContext} -  Created broadcast 220 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:42,016]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 122 (MapPartitionsRDD[230] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,017]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 122.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:42,018]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 122.0 (TID 122, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:42,018]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 122.0 (TID 122) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:42,018]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_197_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,021]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:42,026]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 122.0 (TID 122). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:42,029]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 122.0 (TID 122) in 11 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:42,029]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 122 (treeAggregate at GradientDescent.scala:189) finished in 0.011 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,029]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 122.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:42,030]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 109 finished: treeAggregate at GradientDescent.scala:189, took 0.035541 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,031]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3047228, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,032]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_221 stored as values in memory (estimated size 88.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,032]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_196_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,036]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3038476, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,036]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_221_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,038]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_221_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,038]  INFO {org.apache.spark.SparkContext} -  Created broadcast 221 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:42,039]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_195_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,042]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_194_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,048]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_193_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,053]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_192_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,057]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_191_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,061]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:42,062]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_190_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,063]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 110 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,063]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 123(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,063]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,066]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,066]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 123 (MapPartitionsRDD[232] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,067]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=2998413, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,068]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_222 stored as values in memory (estimated size 8.5 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,069]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_189_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,072]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4429) called with curMem=3002736, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,073]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_222_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,073]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_188_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,075]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_222_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,075]  INFO {org.apache.spark.SparkContext} -  Created broadcast 222 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:42,076]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 123 (MapPartitionsRDD[232] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,076]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 123.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:42,077]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 123.0 (TID 123, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:42,078]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 123.0 (TID 123) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:42,080]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:42,080]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_187_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,084]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_186_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,085]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 123.0 (TID 123). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:42,089]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 123.0 (TID 123) in 12 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:42,090]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 123.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:42,090]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 123 (treeAggregate at GradientDescent.scala:189) finished in 0.014 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,091]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 110 finished: treeAggregate at GradientDescent.scala:189, took 0.029036 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,092]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=2984978, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,092]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_223 stored as values in memory (estimated size 88.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,094]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_185_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,098]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=2980549, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,098]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_184_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,098]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_223_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,100]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_223_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,101]  INFO {org.apache.spark.SparkContext} -  Created broadcast 223 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:42,104]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_183_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,110]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_182_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,118]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:42,119]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 111 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,119]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 124(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,119]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,119]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_181_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,122]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,122]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 124 (MapPartitionsRDD[234] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,123]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=2949605, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,126]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_224 stored as values in memory (estimated size 8.5 KB, free 980.3 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,127]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_180_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,135]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4433) called with curMem=2953753, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,135]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_179_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,139]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_224_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,141]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_224_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,142]  INFO {org.apache.spark.SparkContext} -  Created broadcast 224 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:42,142]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 124 (MapPartitionsRDD[234] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,142]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 124.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:42,143]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 124.0 (TID 124, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:42,143]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 124.0 (TID 124) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:42,145]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:42,151]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 124.0 (TID 124). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:42,154]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 124.0 (TID 124) in 11 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:42,154]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 124 (treeAggregate at GradientDescent.scala:189) finished in 0.012 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,155]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 124.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:42,155]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 111 finished: treeAggregate at GradientDescent.scala:189, took 0.037031 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,156]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=2958186, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,156]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_225 stored as values in memory (estimated size 88.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,159]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=2958274, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,160]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_225_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,161]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_225_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,161]  INFO {org.apache.spark.SparkContext} -  Created broadcast 225 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:42,175]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:42,176]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 112 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,176]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 125(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,176]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,178]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,179]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 125 (MapPartitionsRDD[236] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,179]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=2958357, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,180]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_226 stored as values in memory (estimated size 8.5 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,184]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4431) called with curMem=2967109, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,185]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_226_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,187]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_226_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,188]  INFO {org.apache.spark.SparkContext} -  Created broadcast 226 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:42,188]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 125 (MapPartitionsRDD[236] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,188]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 125.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:42,189]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 125.0 (TID 125, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:42,189]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 125.0 (TID 125) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:42,192]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:42,197]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 125.0 (TID 125). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:42,201]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 125.0 (TID 125) in 12 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:42,201]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 125.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:42,201]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 125 (treeAggregate at GradientDescent.scala:189) finished in 0.013 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,202]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 112 finished: treeAggregate at GradientDescent.scala:189, took 0.026593 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,203]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=2971540, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,203]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_227 stored as values in memory (estimated size 88.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,208]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=2971628, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,208]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_227_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,209]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_227_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,210]  INFO {org.apache.spark.SparkContext} -  Created broadcast 227 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:42,221]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:42,222]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 113 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,223]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 126(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,223]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,225]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,226]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 126 (MapPartitionsRDD[238] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,227]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=2971711, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,227]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_228 stored as values in memory (estimated size 8.5 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,230]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4433) called with curMem=2980463, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,231]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_228_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,232]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_228_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,233]  INFO {org.apache.spark.SparkContext} -  Created broadcast 228 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:42,233]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 126 (MapPartitionsRDD[238] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,234]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 126.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:42,235]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 126.0 (TID 126, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:42,235]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 126.0 (TID 126) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:42,237]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:42,244]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 126.0 (TID 126). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:42,247]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 126.0 (TID 126) in 12 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:42,248]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 126.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:42,248]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 126 (treeAggregate at GradientDescent.scala:189) finished in 0.013 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,248]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 113 finished: treeAggregate at GradientDescent.scala:189, took 0.026920 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,249]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=2984896, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,249]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_229 stored as values in memory (estimated size 88.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,253]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=2984984, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,253]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_229_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,255]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_229_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,256]  INFO {org.apache.spark.SparkContext} -  Created broadcast 229 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:42,266]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:42,267]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 114 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,267]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 127(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,267]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,269]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,269]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 127 (MapPartitionsRDD[240] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,270]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=2985067, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,270]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_230 stored as values in memory (estimated size 8.5 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,274]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4434) called with curMem=2993819, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,274]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_230_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,276]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_230_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,277]  INFO {org.apache.spark.SparkContext} -  Created broadcast 230 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:42,277]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 127 (MapPartitionsRDD[240] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,277]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 127.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:42,278]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 127.0 (TID 127, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:42,279]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 127.0 (TID 127) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:42,280]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:42,287]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 127.0 (TID 127). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:42,291]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 127.0 (TID 127) in 13 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:42,291]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 127.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:42,291]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 127 (treeAggregate at GradientDescent.scala:189) finished in 0.013 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,292]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 114 finished: treeAggregate at GradientDescent.scala:189, took 0.026211 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,293]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=2998253, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,293]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_231 stored as values in memory (estimated size 88.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,296]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=2998341, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,296]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_231_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,298]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_231_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,298]  INFO {org.apache.spark.SparkContext} -  Created broadcast 231 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:42,307]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:42,308]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 115 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,308]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 128(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,308]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,310]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,311]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 128 (MapPartitionsRDD[242] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,313]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=2998424, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,313]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_232 stored as values in memory (estimated size 8.5 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,316]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4429) called with curMem=3007176, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,316]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_232_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,318]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_232_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,319]  INFO {org.apache.spark.SparkContext} -  Created broadcast 232 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:42,319]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 128 (MapPartitionsRDD[242] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,319]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 128.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:42,320]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 128.0 (TID 128, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:42,320]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 128.0 (TID 128) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:42,322]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:42,327]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 128.0 (TID 128). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:42,330]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 128.0 (TID 128) in 10 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:42,330]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 128.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:42,330]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 128 (treeAggregate at GradientDescent.scala:189) finished in 0.010 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,331]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 115 finished: treeAggregate at GradientDescent.scala:189, took 0.024119 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,332]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3011605, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,332]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_233 stored as values in memory (estimated size 88.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,337]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3011693, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,337]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_233_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,339]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_233_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,339]  INFO {org.apache.spark.SparkContext} -  Created broadcast 233 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:42,350]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:42,351]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 116 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,351]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 129(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,351]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,354]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,354]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 129 (MapPartitionsRDD[244] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,355]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3011776, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,356]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_234 stored as values in memory (estimated size 8.5 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,359]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4433) called with curMem=3020528, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,359]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_234_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,361]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_234_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,361]  INFO {org.apache.spark.SparkContext} -  Created broadcast 234 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:42,362]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 129 (MapPartitionsRDD[244] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,363]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 129.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:42,363]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 129.0 (TID 129, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:42,364]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 129.0 (TID 129) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:42,366]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:42,370]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 129.0 (TID 129). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:42,373]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 129.0 (TID 129) in 10 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:42,373]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 129 (treeAggregate at GradientDescent.scala:189) finished in 0.010 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,373]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 129.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:42,375]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 116 finished: treeAggregate at GradientDescent.scala:189, took 0.024833 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,376]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3024961, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,376]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_235 stored as values in memory (estimated size 88.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,379]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3025049, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,380]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_235_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,382]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_235_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,383]  INFO {org.apache.spark.SparkContext} -  Created broadcast 235 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:42,397]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:42,398]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 117 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,398]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 130(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,398]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,401]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,402]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 130 (MapPartitionsRDD[246] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,403]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3025132, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,403]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_236 stored as values in memory (estimated size 8.5 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,407]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4433) called with curMem=3033884, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,408]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_236_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,409]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_236_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,410]  INFO {org.apache.spark.SparkContext} -  Created broadcast 236 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:42,411]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 130 (MapPartitionsRDD[246] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,411]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 130.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:42,412]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 130.0 (TID 130, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:42,413]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 130.0 (TID 130) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:42,415]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:42,421]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 130.0 (TID 130). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:42,425]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 130.0 (TID 130) in 13 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:42,425]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 130 (treeAggregate at GradientDescent.scala:189) finished in 0.013 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,426]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 130.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:42,427]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 117 finished: treeAggregate at GradientDescent.scala:189, took 0.029797 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,428]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3038317, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,428]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_237 stored as values in memory (estimated size 88.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,431]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3038405, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,432]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_237_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,433]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_237_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,434]  INFO {org.apache.spark.SparkContext} -  Created broadcast 237 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:42,442]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:42,443]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 118 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,443]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 131(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,443]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,445]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,445]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 131 (MapPartitionsRDD[248] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,446]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3038488, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,447]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_238 stored as values in memory (estimated size 8.5 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,450]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4432) called with curMem=3047240, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,450]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_238_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,452]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_238_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,452]  INFO {org.apache.spark.SparkContext} -  Created broadcast 238 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:42,452]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 131 (MapPartitionsRDD[248] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,453]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 131.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:42,454]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 131.0 (TID 131, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:42,454]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 131.0 (TID 131) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:42,456]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:42,460]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 131.0 (TID 131). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:42,465]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 131.0 (TID 131) in 12 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:42,465]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 131.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:42,465]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 131 (treeAggregate at GradientDescent.scala:189) finished in 0.012 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,466]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 118 finished: treeAggregate at GradientDescent.scala:189, took 0.023585 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,467]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3051672, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,467]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_239 stored as values in memory (estimated size 88.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,471]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3051760, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,471]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_239_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,473]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_239_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,473]  INFO {org.apache.spark.SparkContext} -  Created broadcast 239 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:42,482]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:42,483]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 119 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,483]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 132(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,483]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,486]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,486]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 132 (MapPartitionsRDD[250] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,489]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3051843, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,489]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_240 stored as values in memory (estimated size 8.5 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,493]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4433) called with curMem=3060595, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,494]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_240_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,495]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_240_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,496]  INFO {org.apache.spark.SparkContext} -  Created broadcast 240 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:42,496]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 132 (MapPartitionsRDD[250] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,497]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 132.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:42,498]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 132.0 (TID 132, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:42,498]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 132.0 (TID 132) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:42,500]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:42,506]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 132.0 (TID 132). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:42,509]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 132.0 (TID 132) in 12 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:42,509]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 132.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:42,509]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 132 (treeAggregate at GradientDescent.scala:189) finished in 0.011 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,510]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 119 finished: treeAggregate at GradientDescent.scala:189, took 0.027484 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,511]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3065028, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,511]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_241 stored as values in memory (estimated size 88.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,515]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3065116, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,515]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_241_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,517]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_241_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,518]  INFO {org.apache.spark.SparkContext} -  Created broadcast 241 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:42,527]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:42,528]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 120 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,528]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 133(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,528]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,530]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,530]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 133 (MapPartitionsRDD[252] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,531]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3065199, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,531]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_242 stored as values in memory (estimated size 8.5 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,534]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4432) called with curMem=3073951, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,535]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_242_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,536]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_242_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,537]  INFO {org.apache.spark.SparkContext} -  Created broadcast 242 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:42,537]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 133 (MapPartitionsRDD[252] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,537]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 133.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:42,538]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 133.0 (TID 133, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:42,538]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 133.0 (TID 133) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:42,540]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:42,545]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 133.0 (TID 133). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:42,549]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 133.0 (TID 133) in 11 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:42,549]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 133.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:42,549]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 133 (treeAggregate at GradientDescent.scala:189) finished in 0.011 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,549]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 120 finished: treeAggregate at GradientDescent.scala:189, took 0.022653 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,550]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3078383, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,550]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_243 stored as values in memory (estimated size 88.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,554]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3078471, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,554]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_243_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,556]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_243_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,556]  INFO {org.apache.spark.SparkContext} -  Created broadcast 243 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:42,565]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:42,566]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 121 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,566]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 134(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,566]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,569]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,569]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 134 (MapPartitionsRDD[254] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,570]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3078554, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,570]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_244 stored as values in memory (estimated size 8.5 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,574]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4431) called with curMem=3087306, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,575]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_244_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,576]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_244_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,577]  INFO {org.apache.spark.SparkContext} -  Created broadcast 244 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:42,577]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 134 (MapPartitionsRDD[254] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,577]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 134.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:42,578]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 134.0 (TID 134, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:42,579]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 134.0 (TID 134) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:42,581]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:42,586]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 134.0 (TID 134). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:42,589]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 134.0 (TID 134) in 11 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:42,589]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 134 (treeAggregate at GradientDescent.scala:189) finished in 0.012 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,590]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 121 finished: treeAggregate at GradientDescent.scala:189, took 0.024830 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,590]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 134.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:42,591]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3091737, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,591]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_245 stored as values in memory (estimated size 88.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,595]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3091825, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,596]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_245_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,598]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_245_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,598]  INFO {org.apache.spark.SparkContext} -  Created broadcast 245 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:42,609]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:42,610]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 122 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,610]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 135(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,610]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,613]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,613]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 135 (MapPartitionsRDD[256] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,614]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3091908, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,615]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_246 stored as values in memory (estimated size 8.5 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,619]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4429) called with curMem=3100660, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,619]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_246_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,621]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_246_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,621]  INFO {org.apache.spark.SparkContext} -  Created broadcast 246 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:42,622]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 135 (MapPartitionsRDD[256] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,622]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 135.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:42,623]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 135.0 (TID 135, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:42,623]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 135.0 (TID 135) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:42,625]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:42,629]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 135.0 (TID 135). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:42,632]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 135.0 (TID 135) in 9 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:42,632]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 135 (treeAggregate at GradientDescent.scala:189) finished in 0.010 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,632]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 135.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:42,633]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 122 finished: treeAggregate at GradientDescent.scala:189, took 0.023953 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,634]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3105089, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,634]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_247 stored as values in memory (estimated size 88.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,637]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3105177, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,637]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_247_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,639]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_247_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,639]  INFO {org.apache.spark.SparkContext} -  Created broadcast 247 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:42,649]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:42,650]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 123 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,650]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 136(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,650]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,652]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,652]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 136 (MapPartitionsRDD[258] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,653]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3105260, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,653]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_248 stored as values in memory (estimated size 8.5 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,657]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4430) called with curMem=3114012, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,657]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_248_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,659]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_248_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,659]  INFO {org.apache.spark.SparkContext} -  Created broadcast 248 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:42,660]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 136 (MapPartitionsRDD[258] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,660]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 136.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:42,661]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 136.0 (TID 136, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:42,661]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 136.0 (TID 136) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:42,663]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:42,668]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 136.0 (TID 136). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:42,673]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 136.0 (TID 136) in 12 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:42,673]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 136 (treeAggregate at GradientDescent.scala:189) finished in 0.013 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,677]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 123 finished: treeAggregate at GradientDescent.scala:189, took 0.027769 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,677]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 136.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:42,678]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3118442, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,678]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_249 stored as values in memory (estimated size 88.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,682]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3118530, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,682]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_249_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,684]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_249_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,684]  INFO {org.apache.spark.SparkContext} -  Created broadcast 249 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:42,694]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:42,695]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 124 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,696]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 137(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,696]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,698]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,698]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 137 (MapPartitionsRDD[260] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,699]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3118613, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,699]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_250 stored as values in memory (estimated size 8.5 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,703]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4433) called with curMem=3127365, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,704]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_250_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,705]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_250_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,706]  INFO {org.apache.spark.SparkContext} -  Created broadcast 250 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:42,706]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 137 (MapPartitionsRDD[260] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,706]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 137.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:42,707]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 137.0 (TID 137, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:42,708]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 137.0 (TID 137) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:42,710]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:42,714]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 137.0 (TID 137). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:42,717]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 137.0 (TID 137) in 10 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:42,717]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 137 (treeAggregate at GradientDescent.scala:189) finished in 0.010 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,718]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 137.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:42,718]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 124 finished: treeAggregate at GradientDescent.scala:189, took 0.023218 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,719]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3131798, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,719]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_251 stored as values in memory (estimated size 88.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,723]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3131886, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,723]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_251_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,725]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_251_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,725]  INFO {org.apache.spark.SparkContext} -  Created broadcast 251 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:42,737]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:42,738]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 125 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,738]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 138(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,738]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,740]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,741]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 138 (MapPartitionsRDD[262] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,742]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3131969, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,742]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_252 stored as values in memory (estimated size 8.5 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,745]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4430) called with curMem=3140721, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,745]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_252_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,747]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_252_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,747]  INFO {org.apache.spark.SparkContext} -  Created broadcast 252 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:42,748]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 138 (MapPartitionsRDD[262] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,748]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 138.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:42,750]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 138.0 (TID 138, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:42,751]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 138.0 (TID 138) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:42,753]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:42,757]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 138.0 (TID 138). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:42,761]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 138.0 (TID 138) in 10 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:42,761]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 138 (treeAggregate at GradientDescent.scala:189) finished in 0.013 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,762]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 125 finished: treeAggregate at GradientDescent.scala:189, took 0.024450 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,761]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 138.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:42,762]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3145151, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,763]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_253 stored as values in memory (estimated size 88.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,766]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3145239, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,766]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_253_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,768]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_253_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,769]  INFO {org.apache.spark.SparkContext} -  Created broadcast 253 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:42,779]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:42,780]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 126 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,781]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 139(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,781]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,783]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,783]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 139 (MapPartitionsRDD[264] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,784]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3145322, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,785]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_254 stored as values in memory (estimated size 8.5 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,798]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4434) called with curMem=3153991, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,798]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_254_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,798]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_227_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,800]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_254_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,801]  INFO {org.apache.spark.SparkContext} -  Created broadcast 254 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:42,802]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 139 (MapPartitionsRDD[264] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,803]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 139.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:42,804]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 139.0 (TID 139, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:42,804]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 139.0 (TID 139) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:42,806]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:42,806]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_226_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,812]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 139.0 (TID 139). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:42,814]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_225_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,816]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 139.0 (TID 139) in 13 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:42,816]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 139.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:42,817]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 139 (treeAggregate at GradientDescent.scala:189) finished in 0.014 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,822]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 126 finished: treeAggregate at GradientDescent.scala:189, took 0.042931 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,823]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3140550, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,824]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_255 stored as values in memory (estimated size 88.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,825]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_224_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,828]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3131886, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,828]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_255_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,830]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_255_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,830]  INFO {org.apache.spark.SparkContext} -  Created broadcast 255 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:42,832]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_223_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,836]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_222_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,841]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_221_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,844]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:42,845]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 127 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,846]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 140(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,846]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,846]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_220_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,849]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,850]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_219_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,850]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 140 (MapPartitionsRDD[266] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,852]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3105088, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,852]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_256 stored as values in memory (estimated size 8.5 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,854]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_218_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,856]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4434) called with curMem=3100567, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,857]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_256_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,858]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_256_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,859]  INFO {org.apache.spark.SparkContext} -  Created broadcast 256 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:42,859]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_217_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,859]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 140 (MapPartitionsRDD[266] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,860]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 140.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:42,862]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 140.0 (TID 140, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:42,862]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 140.0 (TID 140) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:42,863]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_252_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,865]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:42,868]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_251_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,872]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_250_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,873]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 140.0 (TID 140). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:42,878]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_249_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,882]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 140.0 (TID 140) in 21 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:42,884]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_248_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,882]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 140 (treeAggregate at GradientDescent.scala:189) finished in 0.021 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,891]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 140.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:42,892]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 127 finished: treeAggregate at GradientDescent.scala:189, took 0.047308 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,893]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3065027, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,893]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_257 stored as values in memory (estimated size 88.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,898]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3064944, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,898]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_257_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.1 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,898]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_247_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,900]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_257_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,901]  INFO {org.apache.spark.SparkContext} -  Created broadcast 257 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:42,902]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_246_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,907]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_245_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.4 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,912]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_244_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,917]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_243_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,917]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:42,918]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 128 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,918]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 141(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,919]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,921]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,922]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 141 (MapPartitionsRDD[268] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,923]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3033889, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,923]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_258 stored as values in memory (estimated size 8.5 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,924]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_242_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,928]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4433) called with curMem=3033801, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,928]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_258_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,929]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_258_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,930]  INFO {org.apache.spark.SparkContext} -  Created broadcast 258 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:42,930]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_241_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,931]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 141 (MapPartitionsRDD[268] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,931]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 141.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:42,932]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 141.0 (TID 141, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:42,932]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 141.0 (TID 141) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:42,934]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:42,935]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_240_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,938]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_239_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,939]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 141.0 (TID 141). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:42,944]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 141.0 (TID 141) in 12 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:42,944]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 141.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:42,944]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 141 (treeAggregate at GradientDescent.scala:189) finished in 0.013 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,946]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 128 finished: treeAggregate at GradientDescent.scala:189, took 0.028015 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,946]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3020363, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,946]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_238_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,947]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_259 stored as values in memory (estimated size 88.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,950]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3011528, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,951]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_259_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,952]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_237_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,953]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_259_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,953]  INFO {org.apache.spark.SparkContext} -  Created broadcast 259 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:42,957]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_236_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,963]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_235_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,966]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:42,967]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 129 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,967]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 142(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,967]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,969]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,970]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 142 (MapPartitionsRDD[270] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,971]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=2985070, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,971]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_260 stored as values in memory (estimated size 8.5 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,973]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_234_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,976]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4435) called with curMem=2993734, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,977]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_260_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:42,978]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_260_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,979]  INFO {org.apache.spark.SparkContext} -  Created broadcast 260 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:42,979]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 142 (MapPartitionsRDD[270] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,980]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 142.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:42,980]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_233_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,980]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 142.0 (TID 142, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:42,981]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 142.0 (TID 142) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:42,984]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_232_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,984]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:42,990]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_231_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,991]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 142.0 (TID 142). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:42,995]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_230_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:42,998]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 142 (treeAggregate at GradientDescent.scala:189) finished in 0.018 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,998]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 142.0 (TID 142) in 17 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:42,998]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 129 finished: treeAggregate at GradientDescent.scala:189, took 0.032257 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:42,998]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 142.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:42,999]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=2971460, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:43,000]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_261 stored as values in memory (estimated size 88.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:43,002]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_229_piece0 on localhost:56403 in memory (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:43,005]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=2958280, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:43,005]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_261_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:43,007]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_228_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:43,007]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_261_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:43,008]  INFO {org.apache.spark.SparkContext} -  Created broadcast 261 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:43,015]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:43,016]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 130 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:43,016]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 143(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:43,017]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:43,020]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:43,020]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 143 (MapPartitionsRDD[272] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:43,021]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=2958363, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:43,021]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_262 stored as values in memory (estimated size 8.5 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:43,025]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4435) called with curMem=2967115, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:43,026]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_262_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:43,027]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_262_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:43,028]  INFO {org.apache.spark.SparkContext} -  Created broadcast 262 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:43,028]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 143 (MapPartitionsRDD[272] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:43,028]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 143.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:43,029]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 143.0 (TID 143, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:43,029]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 143.0 (TID 143) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:43,031]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:43,036]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 143.0 (TID 143). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:43,039]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 143.0 (TID 143) in 10 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:43,039]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 143 (treeAggregate at GradientDescent.scala:189) finished in 0.010 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:43,039]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 143.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:43,040]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 130 finished: treeAggregate at GradientDescent.scala:189, took 0.024557 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:43,041]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=2971550, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:43,041]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_263 stored as values in memory (estimated size 88.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:43,044]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=2971638, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:43,045]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_263_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:43,046]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_263_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:43,046]  INFO {org.apache.spark.SparkContext} -  Created broadcast 263 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:43,055]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:43,056]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 131 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:43,056]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 144(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:43,056]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:43,058]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:43,059]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 144 (MapPartitionsRDD[274] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:43,060]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=2971721, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:43,061]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_264 stored as values in memory (estimated size 8.5 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:43,064]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4434) called with curMem=2980473, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:43,064]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_264_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:43,065]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_264_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:43,066]  INFO {org.apache.spark.SparkContext} -  Created broadcast 264 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:43,066]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 144 (MapPartitionsRDD[274] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:43,066]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 144.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:43,067]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 144.0 (TID 144, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:43,067]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 144.0 (TID 144) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:43,069]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:43,074]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 144.0 (TID 144). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:43,077]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 144.0 (TID 144) in 9 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:43,077]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 144 (treeAggregate at GradientDescent.scala:189) finished in 0.010 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:43,077]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 144.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:43,078]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 131 finished: treeAggregate at GradientDescent.scala:189, took 0.022016 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:43,078]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=2984907, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:43,078]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_265 stored as values in memory (estimated size 88.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:43,082]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=2984995, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:43,083]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_265_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:43,084]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_265_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:43,084]  INFO {org.apache.spark.SparkContext} -  Created broadcast 265 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:43,094]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:43,095]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 132 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:43,095]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 145(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:43,095]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:43,096]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:43,097]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 145 (MapPartitionsRDD[276] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:43,098]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=2985078, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:43,098]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_266 stored as values in memory (estimated size 8.5 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:43,101]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4431) called with curMem=2993830, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:43,102]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_266_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:43,103]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_266_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:43,103]  INFO {org.apache.spark.SparkContext} -  Created broadcast 266 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:43,104]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 145 (MapPartitionsRDD[276] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:43,104]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 145.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:43,105]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 145.0 (TID 145, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:43,105]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 145.0 (TID 145) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:43,107]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:43,111]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 145.0 (TID 145). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:43,114]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 145.0 (TID 145) in 10 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:43,115]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 145.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:43,115]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 145 (treeAggregate at GradientDescent.scala:189) finished in 0.011 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:43,115]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 132 finished: treeAggregate at GradientDescent.scala:189, took 0.021369 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:43,116]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=2998261, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:43,116]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_267 stored as values in memory (estimated size 88.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:43,119]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=2998349, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:43,119]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_267_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:43,121]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_267_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:43,121]  INFO {org.apache.spark.SparkContext} -  Created broadcast 267 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:43,132]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:43,133]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 133 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:43,133]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 146(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:43,133]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:43,135]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:43,135]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 146 (MapPartitionsRDD[278] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:43,136]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=2998432, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:43,136]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_268 stored as values in memory (estimated size 8.5 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:43,140]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4430) called with curMem=3007184, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:43,140]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_268_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:43,141]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_268_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:43,142]  INFO {org.apache.spark.SparkContext} -  Created broadcast 268 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:43,142]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 146 (MapPartitionsRDD[278] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:43,142]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 146.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:43,143]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 146.0 (TID 146, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:43,144]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 146.0 (TID 146) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:43,146]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:43,150]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 146.0 (TID 146). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:43,153]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 146.0 (TID 146) in 10 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:43,154]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 146.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:43,154]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 146 (treeAggregate at GradientDescent.scala:189) finished in 0.011 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:43,154]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 133 finished: treeAggregate at GradientDescent.scala:189, took 0.021978 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:43,155]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3011614, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:43,155]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_269 stored as values in memory (estimated size 88.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:43,158]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3011702, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:43,159]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_269_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:43,160]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_269_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:43,161]  INFO {org.apache.spark.SparkContext} -  Created broadcast 269 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:43,169]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:43,170]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 134 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:43,170]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 147(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:43,170]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:43,172]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:43,172]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 147 (MapPartitionsRDD[280] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:43,173]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3011785, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:43,173]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_270 stored as values in memory (estimated size 8.5 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:43,177]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4434) called with curMem=3020537, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:43,177]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_270_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:43,178]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_270_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:43,179]  INFO {org.apache.spark.SparkContext} -  Created broadcast 270 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:43,179]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 147 (MapPartitionsRDD[280] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:43,180]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 147.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:43,180]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 147.0 (TID 147, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:43,181]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 147.0 (TID 147) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:43,183]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:43,187]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 147.0 (TID 147). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:43,191]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 147.0 (TID 147) in 11 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:43,191]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 147.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:43,191]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 147 (treeAggregate at GradientDescent.scala:189) finished in 0.011 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:43,192]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 134 finished: treeAggregate at GradientDescent.scala:189, took 0.022221 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:43,193]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(88) called with curMem=3024971, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:43,193]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_271 stored as values in memory (estimated size 88.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:43,196]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(83) called with curMem=3025059, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:43,197]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_271_piece0 stored as bytes in memory (estimated size 83.0 B, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:43,198]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_271_piece0 in memory on localhost:56403 (size: 83.0 B, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:43,199]  INFO {org.apache.spark.SparkContext} -  Created broadcast 271 from broadcast at GradientDescent.scala:185 {org.apache.spark.SparkContext}
[2016-04-29 15:19:43,207]  INFO {org.apache.spark.SparkContext} -  Starting job: treeAggregate at GradientDescent.scala:189 {org.apache.spark.SparkContext}
[2016-04-29 15:19:43,208]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 135 (treeAggregate at GradientDescent.scala:189) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:43,208]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 148(treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:43,208]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:43,210]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:43,210]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 148 (MapPartitionsRDD[282] at treeAggregate at GradientDescent.scala:189), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:43,211]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(8752) called with curMem=3025142, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:43,212]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_272 stored as values in memory (estimated size 8.5 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:43,215]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(4436) called with curMem=3033894, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:43,215]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_272_piece0 stored as bytes in memory (estimated size 4.3 KB, free 980.2 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:43,216]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_272_piece0 in memory on localhost:56403 (size: 4.3 KB, free: 980.5 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:43,217]  INFO {org.apache.spark.SparkContext} -  Created broadcast 272 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:43,217]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 148 (MapPartitionsRDD[282] at treeAggregate at GradientDescent.scala:189) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:43,217]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 148.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:43,218]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 148.0 (TID 148, localhost, PROCESS_LOCAL, 1545 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:43,219]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 148.0 (TID 148) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:43,220]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_53_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:43,225]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 148.0 (TID 148). 1839 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:43,230]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 148.0 (TID 148) in 12 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:43,230]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 148.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:43,234]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 148 (treeAggregate at GradientDescent.scala:189) finished in 0.016 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:43,235]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 135 finished: treeAggregate at GradientDescent.scala:189, took 0.027737 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:43,238]  INFO {org.apache.spark.mllib.optimization.GradientDescent} -  GradientDescent.runMiniBatchSGD finished. Last 10 stochastic losses 1.7855277311090172E246, 3.264978724825273E248, 5.90059275554476E250, 1.0540604982552249E253, 1.8614098124023569E255, 3.249944076087786E257, 5.610699534603269E259, 9.57886724691084E261, 1.6173913139295252E264, 2.7012619215768823E266 {org.apache.spark.mllib.optimization.GradientDescent}
[2016-04-29 15:19:43,239]  INFO {org.apache.spark.rdd.MapPartitionsRDD} -  Removing RDD 53 from persistence list {org.apache.spark.rdd.MapPartitionsRDD}
[2016-04-29 15:19:43,240]  INFO {org.apache.spark.storage.BlockManager} -  Removing RDD 53 {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:43,252]  INFO {org.apache.spark.SparkContext} -  Starting job: take at SparkModelUtils.java:151 {org.apache.spark.SparkContext}
[2016-04-29 15:19:43,254]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 136 (take at SparkModelUtils.java:151) with 1 output partitions (allowLocal=true) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:43,254]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 149(take at SparkModelUtils.java:151) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:43,254]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:43,260]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:43,261]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 149 (MapPartitionsRDD[283] at map at LinearRegression.java:69), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:43,262]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(6856) called with curMem=397802, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:43,262]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_273 stored as values in memory (estimated size 6.7 KB, free 982.7 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:43,266]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(3643) called with curMem=404658, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:43,266]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_273_piece0 stored as bytes in memory (estimated size 3.6 KB, free 982.7 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:43,268]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_273_piece0 in memory on localhost:56403 (size: 3.6 KB, free: 983.0 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:43,268]  INFO {org.apache.spark.SparkContext} -  Created broadcast 273 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:43,269]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 149 (MapPartitionsRDD[283] at map at LinearRegression.java:69) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:43,269]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 149.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:43,271]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 149.0 (TID 149, localhost, PROCESS_LOCAL, 1436 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:43,271]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 149.0 (TID 149) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:43,277]  INFO {org.apache.spark.CacheManager} -  Partition rdd_283_0 not found, computing it {org.apache.spark.CacheManager}
[2016-04-29 15:19:43,278]  INFO {org.apache.spark.CacheManager} -  Partition rdd_54_0 not found, computing it {org.apache.spark.CacheManager}
[2016-04-29 15:19:43,278]  INFO {org.apache.spark.rdd.HadoopRDD} -  Input split: file:/home/ml/wso2ml-1.1.0/datasets/banking.-1234.1461942923269:0+4882918 {org.apache.spark.rdd.HadoopRDD}
[2016-04-29 15:19:45,299]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_272_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 983.0 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:45,302]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_271_piece0 on localhost:56403 in memory (size: 83.0 B, free: 983.0 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:45,307]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_270_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 983.0 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:45,310]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_269_piece0 on localhost:56403 in memory (size: 83.0 B, free: 983.0 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:45,314]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_268_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 983.0 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:45,317]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_267_piece0 on localhost:56403 in memory (size: 83.0 B, free: 983.0 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:45,320]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_266_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 983.0 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:45,324]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_265_piece0 on localhost:56403 in memory (size: 83.0 B, free: 983.0 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:45,329]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_264_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 983.0 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:45,333]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_263_piece0 on localhost:56403 in memory (size: 83.0 B, free: 983.0 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:45,339]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_262_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 983.0 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:45,344]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_261_piece0 on localhost:56403 in memory (size: 83.0 B, free: 983.0 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:45,347]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_260_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 983.0 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:45,351]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_259_piece0 on localhost:56403 in memory (size: 83.0 B, free: 983.0 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:45,356]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_258_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 983.0 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:45,360]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_257_piece0 on localhost:56403 in memory (size: 83.0 B, free: 983.0 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:45,364]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_256_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 983.0 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:45,369]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_255_piece0 on localhost:56403 in memory (size: 83.0 B, free: 983.0 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:45,375]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_254_piece0 on localhost:56403 in memory (size: 4.3 KB, free: 983.0 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:45,893]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(1141064) called with curMem=274906, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:45,894]  INFO {org.apache.spark.storage.MemoryStore} -  Block rdd_54_0 stored as values in memory (estimated size 1114.3 KB, free 981.7 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:45,894]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added rdd_54_0 in memory on localhost:56403 (size: 1114.3 KB, free: 981.9 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:45,990]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(942664) called with curMem=1415970, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:45,990]  INFO {org.apache.spark.storage.MemoryStore} -  Block rdd_283_0 stored as values in memory (estimated size 920.6 KB, free 980.8 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:45,991]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added rdd_283_0 in memory on localhost:56403 (size: 920.6 KB, free: 981.0 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:46,026]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 149.0 (TID 149). 203385 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:46,047]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 149.0 (TID 149) in 2777 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:46,047]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 149 (take at SparkModelUtils.java:151) finished in 2.770 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:46,054]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 149.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:46,055]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 136 finished: take at SparkModelUtils.java:151, took 2.801955 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:46,490]  INFO {org.apache.spark.SparkContext} -  Starting job: take at SparkModelUtils.java:159 {org.apache.spark.SparkContext}
[2016-04-29 15:19:46,491]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 137 (take at SparkModelUtils.java:159) with 1 output partitions (allowLocal=true) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:46,491]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 150(take at SparkModelUtils.java:159) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:46,491]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:46,492]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:46,493]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 150 (MapPartitionsRDD[54] at randomSplit at SupervisedSparkModelBuilder.java:136), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:46,494]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(6144) called with curMem=2358634, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:46,494]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_274 stored as values in memory (estimated size 6.0 KB, free 980.8 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:46,498]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(3294) called with curMem=2364778, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:46,498]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_274_piece0 stored as bytes in memory (estimated size 3.2 KB, free 980.8 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:46,504]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_274_piece0 in memory on localhost:56403 (size: 3.2 KB, free: 981.0 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:46,504]  INFO {org.apache.spark.SparkContext} -  Created broadcast 274 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:46,504]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 150 (MapPartitionsRDD[54] at randomSplit at SupervisedSparkModelBuilder.java:136) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:46,505]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 150.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:46,507]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 150.0 (TID 150, localhost, PROCESS_LOCAL, 1436 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:46,508]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 150.0 (TID 150) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:46,509]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_54_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:46,551]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 150.0 (TID 150). 484202 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:46,592]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 150.0 (TID 150) in 84 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:46,592]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 150 (take at SparkModelUtils.java:159) finished in 0.086 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:46,594]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 137 finished: take at SparkModelUtils.java:159, took 0.103153 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:46,593]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 150.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:46,633]  INFO {org.apache.spark.SparkContext} -  Starting job: count at SparkModelUtils.java:177 {org.apache.spark.SparkContext}
[2016-04-29 15:19:46,635]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 138 (count at SparkModelUtils.java:177) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:46,635]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 151(count at SparkModelUtils.java:177) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:46,635]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:46,636]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:46,636]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 151 (ParallelCollectionRDD[284] at parallelize at SparkModelUtils.java:174), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:46,640]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(1320) called with curMem=2368072, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:46,644]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_275 stored as values in memory (estimated size 1320.0 B, free 980.8 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:46,648]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(875) called with curMem=2369392, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:46,648]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_275_piece0 stored as bytes in memory (estimated size 875.0 B, free 980.8 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:46,651]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_275_piece0 in memory on localhost:56403 (size: 875.0 B, free: 981.0 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:46,652]  INFO {org.apache.spark.SparkContext} -  Created broadcast 275 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:46,654]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 151 (ParallelCollectionRDD[284] at parallelize at SparkModelUtils.java:174) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:46,655]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 151.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:46,760]  WARN {org.apache.spark.scheduler.TaskSetManager} -  Stage 151 contains a task of very large size (550 KB). The maximum recommended task size is 100 KB. {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:46,761]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 151.0 (TID 151, localhost, PROCESS_LOCAL, 564152 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:46,761]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 151.0 (TID 151) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:46,787]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 151.0 (TID 151). 580 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:46,791]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 151 (count at SparkModelUtils.java:177) finished in 0.136 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:46,792]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 138 finished: count at SparkModelUtils.java:177, took 0.157926 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:46,793]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 151.0 (TID 151) in 135 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:46,793]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 151.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:46,797]  INFO {org.apache.spark.SparkContext} -  Starting job: collect at SparkModelUtils.java:181 {org.apache.spark.SparkContext}
[2016-04-29 15:19:46,797]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 139 (collect at SparkModelUtils.java:181) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:46,798]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 152(collect at SparkModelUtils.java:181) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:46,798]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:46,798]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:46,799]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 152 (ParallelCollectionRDD[284] at parallelize at SparkModelUtils.java:174), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:46,800]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(1496) called with curMem=2370267, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:46,800]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_276 stored as values in memory (estimated size 1496.0 B, free 980.8 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:46,803]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(928) called with curMem=2371763, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:46,803]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_276_piece0 stored as bytes in memory (estimated size 928.0 B, free 980.8 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:46,804]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_276_piece0 in memory on localhost:56403 (size: 928.0 B, free: 981.0 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:46,805]  INFO {org.apache.spark.SparkContext} -  Created broadcast 276 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:46,805]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 152 (ParallelCollectionRDD[284] at parallelize at SparkModelUtils.java:174) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:46,805]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 152.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:46,818]  WARN {org.apache.spark.scheduler.TaskSetManager} -  Stage 152 contains a task of very large size (550 KB). The maximum recommended task size is 100 KB. {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:46,819]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 152.0 (TID 152, localhost, PROCESS_LOCAL, 564152 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:46,819]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 152.0 (TID 152) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:46,839]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 152.0 (TID 152). 563447 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:46,845]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 152.0 (TID 152) in 39 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:46,845]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 152.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:46,847]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 152 (collect at SparkModelUtils.java:181) finished in 0.041 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:46,847]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 139 finished: collect at SparkModelUtils.java:181, took 0.050243 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:46,848]  INFO {org.apache.spark.rdd.ParallelCollectionRDD} -  Removing RDD 284 from persistence list {org.apache.spark.rdd.ParallelCollectionRDD}
[2016-04-29 15:19:46,849]  INFO {org.apache.spark.storage.BlockManager} -  Removing RDD 284 {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:46,866]  INFO {org.apache.spark.SparkContext} -  Starting job: mean at SparkModelUtils.java:188 {org.apache.spark.SparkContext}
[2016-04-29 15:19:46,867]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 140 (mean at SparkModelUtils.java:188) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:46,867]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 153(mean at SparkModelUtils.java:188) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:46,867]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:46,869]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:46,869]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 153 (MapPartitionsRDD[287] at mean at SparkModelUtils.java:188), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:46,871]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(7288) called with curMem=2372691, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:46,872]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_277 stored as values in memory (estimated size 7.1 KB, free 980.8 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:46,875]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(3785) called with curMem=2379979, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:46,875]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_277_piece0 stored as bytes in memory (estimated size 3.7 KB, free 980.8 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:46,877]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_277_piece0 in memory on localhost:56403 (size: 3.7 KB, free: 981.0 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:46,877]  INFO {org.apache.spark.SparkContext} -  Created broadcast 277 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:46,877]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 153 (MapPartitionsRDD[287] at mean at SparkModelUtils.java:188) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:46,878]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 153.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:46,879]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 153.0 (TID 153, localhost, PROCESS_LOCAL, 1436 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:46,879]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 153.0 (TID 153) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:46,881]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_283_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:46,907]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 153.0 (TID 153). 1821 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:46,911]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 153 (mean at SparkModelUtils.java:188) finished in 0.032 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:46,912]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 140 finished: mean at SparkModelUtils.java:188, took 0.045784 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:46,911]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 153.0 (TID 153) in 32 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:46,913]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 153.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:46,913]  INFO {org.apache.spark.rdd.MapPartitionsRDD} -  Removing RDD 54 from persistence list {org.apache.spark.rdd.MapPartitionsRDD}
[2016-04-29 15:19:46,914]  INFO {org.apache.spark.storage.BlockManager} -  Removing RDD 54 {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:46,924]  INFO {org.apache.spark.SparkContext} -  Starting job: collect at SupervisedSparkModelBuilder.java:906 {org.apache.spark.SparkContext}
[2016-04-29 15:19:46,925]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 141 (collect at SupervisedSparkModelBuilder.java:906) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:46,925]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 154(collect at SupervisedSparkModelBuilder.java:906) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:46,925]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:46,926]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:46,926]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 154 (MapPartitionsRDD[283] at map at LinearRegression.java:69), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:46,927]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(6840) called with curMem=1242700, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:46,927]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_278 stored as values in memory (estimated size 6.7 KB, free 981.9 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:46,930]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(3610) called with curMem=1249540, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:46,930]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_278_piece0 stored as bytes in memory (estimated size 3.5 KB, free 981.9 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:46,932]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_278_piece0 in memory on localhost:56403 (size: 3.5 KB, free: 982.1 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:46,932]  INFO {org.apache.spark.SparkContext} -  Created broadcast 278 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:46,932]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 154 (MapPartitionsRDD[283] at map at LinearRegression.java:69) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:46,933]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 154.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:46,933]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 154.0 (TID 154, localhost, PROCESS_LOCAL, 1436 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:46,934]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 154.0 (TID 154) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:46,935]  INFO {org.apache.spark.storage.BlockManager} -  Found block rdd_283_0 locally {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:46,942]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 154.0 (TID 154). 252210 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:46,954]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 154.0 (TID 154) in 21 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:46,954]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 154.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:46,954]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 154 (collect at SupervisedSparkModelBuilder.java:906) finished in 0.021 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:46,955]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 141 finished: collect at SupervisedSparkModelBuilder.java:906, took 0.030955 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:46,959]  INFO {org.apache.spark.rdd.ParallelCollectionRDD} -  Removing RDD 288 from persistence list {org.apache.spark.rdd.ParallelCollectionRDD}
[2016-04-29 15:19:46,961]  INFO {org.apache.spark.storage.BlockManager} -  Removing RDD 288 {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:46,963]  INFO {org.apache.spark.rdd.MapPartitionsRDD} -  Removing RDD 283 from persistence list {org.apache.spark.rdd.MapPartitionsRDD}
[2016-04-29 15:19:46,963]  INFO {org.apache.spark.storage.BlockManager} -  Removing RDD 283 {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:46,980]  INFO {org.apache.spark.SparkContext} -  Starting job: aggregate at RegressionMetrics.scala:50 {org.apache.spark.SparkContext}
[2016-04-29 15:19:46,981]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Got job 142 (aggregate at RegressionMetrics.scala:50) with 1 output partitions (allowLocal=false) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:46,981]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Final stage: ResultStage 155(aggregate at RegressionMetrics.scala:50) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:46,981]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Parents of final stage: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:46,982]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Missing parents: List() {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:46,982]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting ResultStage 155 (MapPartitionsRDD[289] at map at RegressionMetrics.scala:48), which has no missing parents {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:46,983]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(2840) called with curMem=310486, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:46,983]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_279 stored as values in memory (estimated size 2.8 KB, free 982.8 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:46,986]  INFO {org.apache.spark.storage.MemoryStore} -  ensureFreeSpace(1647) called with curMem=313326, maxMem=1030823608 {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:46,987]  INFO {org.apache.spark.storage.MemoryStore} -  Block broadcast_279_piece0 stored as bytes in memory (estimated size 1647.0 B, free 982.8 MB) {org.apache.spark.storage.MemoryStore}
[2016-04-29 15:19:46,988]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Added broadcast_279_piece0 in memory on localhost:56403 (size: 1647.0 B, free: 983.0 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:46,988]  INFO {org.apache.spark.SparkContext} -  Created broadcast 279 from broadcast at DAGScheduler.scala:874 {org.apache.spark.SparkContext}
[2016-04-29 15:19:46,989]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Submitting 1 missing tasks from ResultStage 155 (MapPartitionsRDD[289] at map at RegressionMetrics.scala:48) {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:46,989]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Adding task set 155.0 with 1 tasks {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:47,017]  WARN {org.apache.spark.scheduler.TaskSetManager} -  Stage 155 contains a task of very large size (245 KB). The maximum recommended task size is 100 KB. {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:47,017]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Starting task 0.0 in stage 155.0 (TID 155, localhost, PROCESS_LOCAL, 251743 bytes) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:47,019]  INFO {org.apache.spark.executor.Executor} -  Running task 0.0 in stage 155.0 (TID 155) {org.apache.spark.executor.Executor}
[2016-04-29 15:19:47,156]  INFO {org.apache.spark.executor.Executor} -  Finished task 0.0 in stage 155.0 (TID 155). 765 bytes result sent to driver {org.apache.spark.executor.Executor}
[2016-04-29 15:19:47,159]  INFO {org.apache.spark.scheduler.DAGScheduler} -  ResultStage 155 (aggregate at RegressionMetrics.scala:50) finished in 0.170 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:47,160]  INFO {org.apache.spark.scheduler.DAGScheduler} -  Job 142 finished: aggregate at RegressionMetrics.scala:50, took 0.179686 s {org.apache.spark.scheduler.DAGScheduler}
[2016-04-29 15:19:47,161]  INFO {org.apache.spark.scheduler.TaskSetManager} -  Finished task 0.0 in stage 155.0 (TID 155) in 169 ms on localhost (1/1) {org.apache.spark.scheduler.TaskSetManager}
[2016-04-29 15:19:47,162]  INFO {org.apache.spark.scheduler.TaskSchedulerImpl} -  Removed TaskSet 155.0, whose tasks have all completed, from pool  {org.apache.spark.scheduler.TaskSchedulerImpl}
[2016-04-29 15:19:48,013]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_276_piece0 on localhost:56403 in memory (size: 928.0 B, free: 983.0 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:48,018]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_275_piece0 on localhost:56403 in memory (size: 875.0 B, free: 983.0 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:48,024]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_274_piece0 on localhost:56403 in memory (size: 3.2 KB, free: 983.0 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:48,035]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_279_piece0 on localhost:56403 in memory (size: 1647.0 B, free: 983.0 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:48,042]  INFO {org.apache.spark.storage.BlockManager} -  Removing RDD 288 {org.apache.spark.storage.BlockManager}
[2016-04-29 15:19:48,046]  INFO {org.apache.spark.ContextCleaner} -  Cleaned RDD 288 {org.apache.spark.ContextCleaner}
[2016-04-29 15:19:48,050]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_278_piece0 on localhost:56403 in memory (size: 3.5 KB, free: 983.0 MB) {org.apache.spark.storage.BlockManagerInfo}
[2016-04-29 15:19:48,056]  INFO {org.apache.spark.storage.BlockManagerInfo} -  Removed broadcast_277_piece0 on localhost:56403 in memory (size: 3.7 KB, free: 983.0 MB) {org.apache.spark.storage.BlockManagerInfo}
